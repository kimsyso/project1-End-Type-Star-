{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Model Learning\n",
        "전처리된 data를 가지고 모델에 넣어 학습시키는 부분이다.\n",
        "\n",
        "학습 모델로는 회귀 모델을 사용하였으며, 최적의 값을 구하기 위해 optuna 기능을 추가하여 최적의 parameter를 구했다.\n",
        "\n",
        "각 model에 대한 optuna를 진행한 이후, voting기능을 사용하여 예상 최적 값을 구하고 이를 시각화 시킨다."
      ],
      "metadata": {
        "id": "sd8OsrsRmvqK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Library upload"
      ],
      "metadata": {
        "id": "SdJq6oVJs4A0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 회귀 모델 중 하나인 CatBoost model을 사용하기 위해 pip 을 통해 설치\n",
        "!pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4ZpbLVZgwVO",
        "outputId": "9b48e457-d4d5-41ea-b1ee-7231a6c28b02"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.5-cp310-cp310-manylinux2014_x86_64.whl (98.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.25.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.0.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.11.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.3.0)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.2.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# optuna 기능을 사용하기 위한 설치 code\n",
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCjw-73DoJu7",
        "outputId": "6ec54eed-22a4-434d-ece3-5dbe72d1b0d4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.30)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
            "Installing collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.5 alembic-1.13.1 colorlog-6.8.2 optuna-3.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WAOzZmuBTLOL"
      },
      "outputs": [],
      "source": [
        "# model 학습 및 시각화하는데 필요한 library upload\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, VotingRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from catboost import CatBoostRegressor\n",
        "import optuna\n",
        "from optuna import trial\n",
        "from optuna.samplers import TPESampler\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Train-Valid Split"
      ],
      "metadata": {
        "id": "poBAoooOs-4P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train, vaild split\n",
        "train = pd.read_csv('/content/train_data.csv')\n",
        "test = pd.read_csv('/content/test_data.csv')\n",
        "\n",
        "x = train[['Temp(K)', 'Mass(sun=1)','Spec_Encoded','MMK_Encoded']]\n",
        "y = train['end_Type_Encoded']\n",
        "x_test = test[['Temp(K)', 'Mass(sun=1)', 'Spec_Encoded','MMK_Encoded']]\n",
        "y_test = test[['end_Type_Encoded']]\n",
        "X_train, X_valid, Y_train, Y_valid = train_test_split(x, y, test_size=0.3, shuffle=True, random_state=42) # train:valid = 7:3 의 비율로 split\n",
        "\n",
        "# 크기 확인\n",
        "print(x.shape, y.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "8ka9rolaejtm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1304a0a-2885-45e6-a5dd-1856e4cd4c14"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4532, 4) (4532,)\n",
            "(832, 4) (832, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Model 학습\n",
        "\n",
        "optuna는 python기반 hyper-parameter 최적화를 자동으로 해주는 프레임 워크이다.\n",
        "\n",
        "\n",
        "study와 trial을 통해 trial함수에서 목적함수를 시행할 횟수를 정하면 study에서 그 횟수만큼 반복하여 최적화 과정을 진행한다.\n",
        "\n",
        "\n",
        "\n",
        "이런 과정을 반복하면서 최적의 하이터파라미터 조합을 찾는것이다."
      ],
      "metadata": {
        "id": "9y-OEKStsBiE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# decision tree regressor\n",
        "DT_model = DecisionTreeRegressor(max_depth=186, min_samples_split=8, min_samples_leaf=2)\n",
        "DT_model.fit(X_train, Y_train)\n",
        "\n",
        "pred = DT_model.predict(x_test)\n",
        "pred\n",
        "\n",
        "# 평가지표(mae, mse, R)\n",
        "mae = mean_absolute_error(y_test, pred)\n",
        "mse = mean_squared_error(y_test, pred)\n",
        "r2 = r2_score(y_test, pred)\n",
        "\n",
        "print(f'Mean Absolute Error: {mae}')\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "print(f'R2 Score: {r2}')"
      ],
      "metadata": {
        "id": "HJmfigpDjPyX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b42e316f-4a4e-481a-abbd-7230ac3ac3ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error: 1.1683092948717948\n",
            "Mean Squared Error: 3.4107144764957265\n",
            "R2 Score: -1.78011068471629\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# optuna 적용\n",
        "# Objective 함수\n",
        "def objectiveDT(trial):\n",
        "    try:\n",
        "        param = {\n",
        "            'max_depth': trial.suggest_int('max_depth', 50, 200),\n",
        "            'random_state': 42,\n",
        "            'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
        "            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20)\n",
        "        }\n",
        "\n",
        "        model = DecisionTreeRegressor(**param)\n",
        "        model.fit(X_train, Y_train)\n",
        "        pred = model.predict(x_test)\n",
        "\n",
        "        mae = mean_absolute_error(y_test, pred)\n",
        "        return mae\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f'Error in trial {trial.number}: {e}')\n",
        "        return float('inf')\n",
        "\n",
        "sampler = TPESampler(seed=42)\n",
        "study = optuna.create_study(\n",
        "    study_name='dtm_parameter_opt',\n",
        "    direction='minimize',\n",
        "    sampler=sampler\n",
        ")\n",
        "\n",
        "# 최적화 실행 및 예외 처리\n",
        "try:\n",
        "    study.optimize(objectiveDT, n_trials=100)\n",
        "except Exception as e:\n",
        "    print(f'Optimization failed: {e}')\n",
        "\n",
        "# 최적화 완료 여부 확인\n",
        "if len(study.trials) == 0:\n",
        "    print(\"No trials were completed.\")\n",
        "else:\n",
        "    best_params = study.best_params\n",
        "    print('Best Parameters:', best_params)\n",
        "\n",
        "    # 최적의 하이퍼파라미터로 모델 학습\n",
        "    best_model = DecisionTreeRegressor(**best_params, random_state=42)\n",
        "    best_model.fit(X_train, Y_train)\n",
        "    pred = best_model.predict(x_test)\n",
        "\n",
        "    # 평가지표(mae, mse, R2)\n",
        "    mae = mean_absolute_error(y_test, pred)\n",
        "    mse = mean_squared_error(y_test, pred)\n",
        "    r2 = r2_score(y_test, pred)\n",
        "\n",
        "    print(f'Mean Absolute Error: {mae}')\n",
        "    print(f'Mean Squared Error: {mse}')\n",
        "    print(f'R2 Score: {r2}')"
      ],
      "metadata": {
        "id": "gEbW5HVO3xqx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16afef40-b614-48df-aacf-8a537638a25a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-06-08 17:57:42,097] A new study created in memory with name: dtm_parameter_opt\n",
            "[I 2024-06-08 17:57:42,116] Trial 0 finished with value: 1.280105535316133 and parameters: {'max_depth': 106, 'min_samples_split': 20, 'min_samples_leaf': 15}. Best is trial 0 with value: 1.280105535316133.\n",
            "[I 2024-06-08 17:57:42,132] Trial 1 finished with value: 1.18984375 and parameters: {'max_depth': 140, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 1 with value: 1.18984375.\n",
            "[I 2024-06-08 17:57:42,151] Trial 2 finished with value: 1.2809481544096928 and parameters: {'max_depth': 58, 'min_samples_split': 18, 'min_samples_leaf': 13}. Best is trial 1 with value: 1.18984375.\n",
            "[I 2024-06-08 17:57:42,170] Trial 3 finished with value: 1.2950898848573391 and parameters: {'max_depth': 156, 'min_samples_split': 2, 'min_samples_leaf': 20}. Best is trial 1 with value: 1.18984375.\n",
            "[I 2024-06-08 17:57:42,191] Trial 4 finished with value: 1.18984375 and parameters: {'max_depth': 175, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 1 with value: 1.18984375.\n",
            "[I 2024-06-08 17:57:42,208] Trial 5 finished with value: 1.3068546037296034 and parameters: {'max_depth': 77, 'min_samples_split': 7, 'min_samples_leaf': 11}. Best is trial 1 with value: 1.18984375.\n",
            "[I 2024-06-08 17:57:42,224] Trial 6 finished with value: 1.2809481544096928 and parameters: {'max_depth': 115, 'min_samples_split': 7, 'min_samples_leaf': 13}. Best is trial 1 with value: 1.18984375.\n",
            "[I 2024-06-08 17:57:42,245] Trial 7 finished with value: 1.2369891826923076 and parameters: {'max_depth': 71, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 1 with value: 1.18984375.\n",
            "[I 2024-06-08 17:57:42,260] Trial 8 finished with value: 1.1908052884615385 and parameters: {'max_depth': 118, 'min_samples_split': 16, 'min_samples_leaf': 4}. Best is trial 1 with value: 1.18984375.\n",
            "[I 2024-06-08 17:57:42,278] Trial 9 finished with value: 1.2844951923076924 and parameters: {'max_depth': 127, 'min_samples_split': 13, 'min_samples_leaf': 1}. Best is trial 1 with value: 1.18984375.\n",
            "[I 2024-06-08 17:57:42,314] Trial 10 finished with value: 1.2256138392857143 and parameters: {'max_depth': 194, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 1 with value: 1.18984375.\n",
            "[I 2024-06-08 17:57:42,352] Trial 11 finished with value: 1.2974759615384615 and parameters: {'max_depth': 175, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 1 with value: 1.18984375.\n",
            "[I 2024-06-08 17:57:42,393] Trial 12 finished with value: 1.2305288461538462 and parameters: {'max_depth': 152, 'min_samples_split': 12, 'min_samples_leaf': 6}. Best is trial 1 with value: 1.18984375.\n",
            "[I 2024-06-08 17:57:42,431] Trial 13 finished with value: 1.18984375 and parameters: {'max_depth': 147, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 1 with value: 1.18984375.\n",
            "[I 2024-06-08 17:57:42,469] Trial 14 finished with value: 1.18984375 and parameters: {'max_depth': 194, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 1 with value: 1.18984375.\n",
            "[I 2024-06-08 17:57:42,509] Trial 15 finished with value: 1.246821581196581 and parameters: {'max_depth': 172, 'min_samples_split': 10, 'min_samples_leaf': 9}. Best is trial 1 with value: 1.18984375.\n",
            "[I 2024-06-08 17:57:42,547] Trial 16 finished with value: 1.2822916666666668 and parameters: {'max_depth': 141, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 1 with value: 1.18984375.\n",
            "[I 2024-06-08 17:57:42,582] Trial 17 finished with value: 1.2305288461538462 and parameters: {'max_depth': 94, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 1 with value: 1.18984375.\n",
            "[I 2024-06-08 17:57:42,619] Trial 18 finished with value: 1.3064029720279722 and parameters: {'max_depth': 169, 'min_samples_split': 9, 'min_samples_leaf': 10}. Best is trial 1 with value: 1.18984375.\n",
            "[I 2024-06-08 17:57:42,654] Trial 19 finished with value: 1.291614161605938 and parameters: {'max_depth': 133, 'min_samples_split': 14, 'min_samples_leaf': 19}. Best is trial 1 with value: 1.18984375.\n",
            "[I 2024-06-08 17:57:42,694] Trial 20 finished with value: 1.1637019230769232 and parameters: {'max_depth': 182, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 20 with value: 1.1637019230769232.\n",
            "[I 2024-06-08 17:57:42,736] Trial 21 finished with value: 1.1637019230769232 and parameters: {'max_depth': 185, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 20 with value: 1.1637019230769232.\n",
            "[I 2024-06-08 17:57:42,774] Trial 22 finished with value: 1.1706730769230769 and parameters: {'max_depth': 199, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 20 with value: 1.1637019230769232.\n",
            "[I 2024-06-08 17:57:42,816] Trial 23 finished with value: 1.3088942307692308 and parameters: {'max_depth': 200, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 20 with value: 1.1637019230769232.\n",
            "[I 2024-06-08 17:57:42,851] Trial 24 finished with value: 1.155088141025641 and parameters: {'max_depth': 186, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:42,887] Trial 25 finished with value: 1.2305288461538462 and parameters: {'max_depth': 183, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:42,924] Trial 26 finished with value: 1.1683092948717948 and parameters: {'max_depth': 164, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:42,960] Trial 27 finished with value: 1.3798076923076923 and parameters: {'max_depth': 185, 'min_samples_split': 11, 'min_samples_leaf': 3}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:42,994] Trial 28 finished with value: 1.2797842353724709 and parameters: {'max_depth': 184, 'min_samples_split': 8, 'min_samples_leaf': 17}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:43,032] Trial 29 finished with value: 1.3425480769230769 and parameters: {'max_depth': 158, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:43,083] Trial 30 finished with value: 1.2369891826923076 and parameters: {'max_depth': 185, 'min_samples_split': 6, 'min_samples_leaf': 8}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:43,126] Trial 31 finished with value: 1.1683092948717948 and parameters: {'max_depth': 164, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:43,164] Trial 32 finished with value: 1.1683092948717948 and parameters: {'max_depth': 161, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:43,202] Trial 33 finished with value: 1.3798076923076923 and parameters: {'max_depth': 179, 'min_samples_split': 11, 'min_samples_leaf': 3}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:43,240] Trial 34 finished with value: 1.2844951923076924 and parameters: {'max_depth': 191, 'min_samples_split': 20, 'min_samples_leaf': 1}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:43,277] Trial 35 finished with value: 1.3425480769230769 and parameters: {'max_depth': 165, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:43,315] Trial 36 finished with value: 1.2822916666666668 and parameters: {'max_depth': 148, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:43,353] Trial 37 finished with value: 1.281261446886447 and parameters: {'max_depth': 174, 'min_samples_split': 7, 'min_samples_leaf': 14}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:43,396] Trial 38 finished with value: 1.3425480769230769 and parameters: {'max_depth': 190, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:43,437] Trial 39 finished with value: 1.1683092948717948 and parameters: {'max_depth': 99, 'min_samples_split': 15, 'min_samples_leaf': 2}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:43,480] Trial 40 finished with value: 1.307051282051282 and parameters: {'max_depth': 139, 'min_samples_split': 6, 'min_samples_leaf': 12}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:43,521] Trial 41 finished with value: 1.1683092948717948 and parameters: {'max_depth': 165, 'min_samples_split': 11, 'min_samples_leaf': 2}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:43,559] Trial 42 finished with value: 1.1683092948717948 and parameters: {'max_depth': 159, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:43,596] Trial 43 finished with value: 1.2796875 and parameters: {'max_depth': 178, 'min_samples_split': 12, 'min_samples_leaf': 1}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:43,634] Trial 44 finished with value: 1.18984375 and parameters: {'max_depth': 167, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:43,675] Trial 45 finished with value: 1.1596955128205129 and parameters: {'max_depth': 154, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:43,714] Trial 46 finished with value: 1.1596955128205129 and parameters: {'max_depth': 59, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:43,750] Trial 47 finished with value: 1.2256138392857143 and parameters: {'max_depth': 125, 'min_samples_split': 3, 'min_samples_leaf': 7}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:43,786] Trial 48 finished with value: 1.3425480769230769 and parameters: {'max_depth': 54, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:43,820] Trial 49 finished with value: 1.2822916666666668 and parameters: {'max_depth': 66, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:43,857] Trial 50 finished with value: 1.18984375 and parameters: {'max_depth': 91, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:43,894] Trial 51 finished with value: 1.2822916666666668 and parameters: {'max_depth': 83, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:43,930] Trial 52 finished with value: 1.2796875 and parameters: {'max_depth': 154, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:43,966] Trial 53 finished with value: 1.18984375 and parameters: {'max_depth': 109, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:44,001] Trial 54 finished with value: 1.1706730769230769 and parameters: {'max_depth': 179, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:44,041] Trial 55 finished with value: 1.2822916666666668 and parameters: {'max_depth': 172, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:44,077] Trial 56 finished with value: 1.2844951923076924 and parameters: {'max_depth': 194, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:44,123] Trial 57 finished with value: 1.2256138392857143 and parameters: {'max_depth': 141, 'min_samples_split': 3, 'min_samples_leaf': 7}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:44,157] Trial 58 finished with value: 1.18984375 and parameters: {'max_depth': 189, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:44,191] Trial 59 finished with value: 1.2793042532648509 and parameters: {'max_depth': 150, 'min_samples_split': 12, 'min_samples_leaf': 16}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:44,226] Trial 60 finished with value: 1.2305288461538462 and parameters: {'max_depth': 196, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:44,263] Trial 61 finished with value: 1.1683092948717948 and parameters: {'max_depth': 170, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:44,298] Trial 62 finished with value: 1.1683092948717948 and parameters: {'max_depth': 164, 'min_samples_split': 13, 'min_samples_leaf': 2}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:44,340] Trial 63 finished with value: 1.2796875 and parameters: {'max_depth': 179, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:44,379] Trial 64 finished with value: 1.1596955128205129 and parameters: {'max_depth': 155, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:44,415] Trial 65 finished with value: 1.3425480769230769 and parameters: {'max_depth': 129, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:44,452] Trial 66 finished with value: 1.2822916666666668 and parameters: {'max_depth': 186, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:44,488] Trial 67 finished with value: 1.18984375 and parameters: {'max_depth': 157, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:44,532] Trial 68 finished with value: 1.2844951923076924 and parameters: {'max_depth': 144, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:44,568] Trial 69 finished with value: 1.2822916666666668 and parameters: {'max_depth': 118, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:44,604] Trial 70 finished with value: 1.2305288461538462 and parameters: {'max_depth': 133, 'min_samples_split': 7, 'min_samples_leaf': 6}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:44,641] Trial 71 finished with value: 1.1683092948717948 and parameters: {'max_depth': 176, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:44,679] Trial 72 finished with value: 1.1683092948717948 and parameters: {'max_depth': 162, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:44,716] Trial 73 finished with value: 1.1596955128205129 and parameters: {'max_depth': 154, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:44,756] Trial 74 finished with value: 1.2822916666666668 and parameters: {'max_depth': 154, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:44,800] Trial 75 finished with value: 1.3064029720279722 and parameters: {'max_depth': 182, 'min_samples_split': 8, 'min_samples_leaf': 10}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:44,841] Trial 76 finished with value: 1.3425480769230769 and parameters: {'max_depth': 146, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:44,882] Trial 77 finished with value: 1.18984375 and parameters: {'max_depth': 169, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:44,923] Trial 78 finished with value: 1.2844951923076924 and parameters: {'max_depth': 152, 'min_samples_split': 18, 'min_samples_leaf': 1}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:44,964] Trial 79 finished with value: 1.3798076923076923 and parameters: {'max_depth': 136, 'min_samples_split': 11, 'min_samples_leaf': 3}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:45,011] Trial 80 finished with value: 1.2796104945858235 and parameters: {'max_depth': 65, 'min_samples_split': 6, 'min_samples_leaf': 18}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:45,053] Trial 81 finished with value: 1.1683092948717948 and parameters: {'max_depth': 160, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:45,097] Trial 82 finished with value: 1.3572716346153846 and parameters: {'max_depth': 175, 'min_samples_split': 11, 'min_samples_leaf': 4}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:45,154] Trial 83 finished with value: 1.2796875 and parameters: {'max_depth': 157, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:45,200] Trial 84 finished with value: 1.155088141025641 and parameters: {'max_depth': 187, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:45,253] Trial 85 finished with value: 1.1596955128205129 and parameters: {'max_depth': 188, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:45,301] Trial 86 finished with value: 1.3425480769230769 and parameters: {'max_depth': 198, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:45,346] Trial 87 finished with value: 1.2822916666666668 and parameters: {'max_depth': 191, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:45,394] Trial 88 finished with value: 1.1596955128205129 and parameters: {'max_depth': 188, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:45,439] Trial 89 finished with value: 1.18984375 and parameters: {'max_depth': 187, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:45,482] Trial 90 finished with value: 1.2950898848573391 and parameters: {'max_depth': 193, 'min_samples_split': 8, 'min_samples_leaf': 20}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:45,529] Trial 91 finished with value: 1.2822916666666668 and parameters: {'max_depth': 183, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:45,574] Trial 92 finished with value: 1.1637019230769232 and parameters: {'max_depth': 188, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:45,619] Trial 93 finished with value: 1.1596955128205129 and parameters: {'max_depth': 199, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:45,668] Trial 94 finished with value: 1.18984375 and parameters: {'max_depth': 200, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:45,715] Trial 95 finished with value: 1.1596955128205129 and parameters: {'max_depth': 196, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:45,759] Trial 96 finished with value: 1.1596955128205129 and parameters: {'max_depth': 196, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:45,801] Trial 97 finished with value: 1.3425480769230769 and parameters: {'max_depth': 193, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:45,840] Trial 98 finished with value: 1.18984375 and parameters: {'max_depth': 196, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 24 with value: 1.155088141025641.\n",
            "[I 2024-06-08 17:57:45,882] Trial 99 finished with value: 1.307051282051282 and parameters: {'max_depth': 190, 'min_samples_split': 8, 'min_samples_leaf': 12}. Best is trial 24 with value: 1.155088141025641.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'max_depth': 186, 'min_samples_split': 8, 'min_samples_leaf': 2}\n",
            "Mean Absolute Error: 1.155088141025641\n",
            "Mean Squared Error: 3.3446087072649573\n",
            "R2 Score: -1.7262271489860659\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# random forest regressor\n",
        "RF_model = RandomForestRegressor(max_depth=50, random_state=200)\n",
        "RF_model.fit(X_train, Y_train)\n",
        "\n",
        "pred1 = RF_model.predict(x_test)\n",
        "pred1\n",
        "\n",
        "# 평가지표(mae, mse, R)\n",
        "mae = mean_absolute_error(y_test, pred1)\n",
        "mse = mean_squared_error(y_test, pred1)\n",
        "r2 = r2_score(y_test, pred1)\n",
        "\n",
        "print(f'Mean Absolute Error: {mae}')\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "print(f'R2 Score: {r2}')"
      ],
      "metadata": {
        "id": "aE0QLk_pROOq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "3bd3bd8a-06d5-4f3b-8d49-23b0283af540"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(max_depth=50, random_state=200)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=50, random_state=200)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=50, random_state=200)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# optuna 적용\n",
        "# Objective 함수\n",
        "def objectiveRF(trial):\n",
        "    try:\n",
        "        param = {\n",
        "            'max_depth': trial.suggest_int('max_depth', 50, 200),\n",
        "            'random_state': 42,\n",
        "            'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
        "            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20)\n",
        "        }\n",
        "\n",
        "        model = RandomForestRegressor(**param)\n",
        "        model.fit(X_train, Y_train)\n",
        "        pred = model.predict(x_test)\n",
        "\n",
        "        mae = mean_absolute_error(y_test, pred)\n",
        "        return mae\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f'Error in trial {trial.number}: {e}')\n",
        "        return float('inf')\n",
        "\n",
        "sampler = TPESampler(seed=42)\n",
        "study = optuna.create_study(\n",
        "    study_name='dtm_parameter_opt',\n",
        "    direction='minimize',\n",
        "    sampler=sampler\n",
        ")\n",
        "\n",
        "# 최적화 실행 및 예외 처리\n",
        "try:\n",
        "    study.optimize(objectiveRF, n_trials=100)\n",
        "except Exception as e:\n",
        "    print(f'Optimization failed: {e}')\n",
        "\n",
        "# 최적화 완료 여부 확인\n",
        "if len(study.trials) == 0:\n",
        "    print(\"No trials were completed.\")\n",
        "else:\n",
        "    best_params = study.best_params\n",
        "    print('Best Parameters:', best_params)\n",
        "\n",
        "    # 최적의 하이퍼파라미터로 모델 학습\n",
        "    best_model = RandomForestRegressor(**best_params, random_state=42)\n",
        "    best_model.fit(X_train, Y_train)\n",
        "    pred1 = best_model.predict(x_test)\n",
        "\n",
        "    # 평가지표(mae, mse, R2)\n",
        "    mae = mean_absolute_error(y_test, pred1)\n",
        "    mse = mean_squared_error(y_test, pred1)\n",
        "    r2 = r2_score(y_test, pred1)\n",
        "\n",
        "    print(f'Mean Absolute Error: {mae}')\n",
        "    print(f'Mean Squared Error: {mse}')\n",
        "    print(f'R2 Score: {r2}')"
      ],
      "metadata": {
        "id": "sG1mtfia9hXH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "897635c8-d7d4-41d2-b794-9de030ada213"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-06-08 17:21:21,226] A new study created in memory with name: dtm_parameter_opt\n",
            "[I 2024-06-08 17:21:21,688] Trial 0 finished with value: 1.2877221705796542 and parameters: {'max_depth': 106, 'min_samples_split': 20, 'min_samples_leaf': 15}. Best is trial 0 with value: 1.2877221705796542.\n",
            "[I 2024-06-08 17:21:22,136] Trial 1 finished with value: 1.250652340047773 and parameters: {'max_depth': 140, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 1 with value: 1.250652340047773.\n",
            "[I 2024-06-08 17:21:22,584] Trial 2 finished with value: 1.2855207461187608 and parameters: {'max_depth': 58, 'min_samples_split': 18, 'min_samples_leaf': 13}. Best is trial 1 with value: 1.250652340047773.\n",
            "[I 2024-06-08 17:21:23,003] Trial 3 finished with value: 1.2902695971251934 and parameters: {'max_depth': 156, 'min_samples_split': 2, 'min_samples_leaf': 20}. Best is trial 1 with value: 1.250652340047773.\n",
            "[I 2024-06-08 17:21:23,458] Trial 4 finished with value: 1.250652340047773 and parameters: {'max_depth': 175, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 1 with value: 1.250652340047773.\n",
            "[I 2024-06-08 17:21:23,915] Trial 5 finished with value: 1.2847485132656722 and parameters: {'max_depth': 77, 'min_samples_split': 7, 'min_samples_leaf': 11}. Best is trial 1 with value: 1.250652340047773.\n",
            "[I 2024-06-08 17:21:24,556] Trial 6 finished with value: 1.2855207461187608 and parameters: {'max_depth': 115, 'min_samples_split': 7, 'min_samples_leaf': 13}. Best is trial 1 with value: 1.250652340047773.\n",
            "[I 2024-06-08 17:21:25,189] Trial 7 finished with value: 1.2816113693752789 and parameters: {'max_depth': 71, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 1 with value: 1.250652340047773.\n",
            "[I 2024-06-08 17:21:25,843] Trial 8 finished with value: 1.253616526099724 and parameters: {'max_depth': 118, 'min_samples_split': 16, 'min_samples_leaf': 4}. Best is trial 1 with value: 1.250652340047773.\n",
            "[I 2024-06-08 17:21:26,521] Trial 9 finished with value: 1.2829888220356052 and parameters: {'max_depth': 127, 'min_samples_split': 13, 'min_samples_leaf': 1}. Best is trial 1 with value: 1.250652340047773.\n",
            "[I 2024-06-08 17:21:27,187] Trial 10 finished with value: 1.277486559898206 and parameters: {'max_depth': 194, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 1 with value: 1.250652340047773.\n",
            "[I 2024-06-08 17:21:27,722] Trial 11 finished with value: 1.2817363495879117 and parameters: {'max_depth': 175, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 1 with value: 1.250652340047773.\n",
            "[I 2024-06-08 17:21:28,180] Trial 12 finished with value: 1.2713332124141485 and parameters: {'max_depth': 152, 'min_samples_split': 12, 'min_samples_leaf': 6}. Best is trial 1 with value: 1.250652340047773.\n",
            "[I 2024-06-08 17:21:28,648] Trial 13 finished with value: 1.2538596841192995 and parameters: {'max_depth': 147, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 1 with value: 1.250652340047773.\n",
            "[I 2024-06-08 17:21:29,105] Trial 14 finished with value: 1.250652340047773 and parameters: {'max_depth': 194, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 1 with value: 1.250652340047773.\n",
            "[I 2024-06-08 17:21:29,550] Trial 15 finished with value: 1.2863496588703565 and parameters: {'max_depth': 172, 'min_samples_split': 10, 'min_samples_leaf': 9}. Best is trial 1 with value: 1.250652340047773.\n",
            "[I 2024-06-08 17:21:30,014] Trial 16 finished with value: 1.2511312212093462 and parameters: {'max_depth': 141, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 1 with value: 1.250652340047773.\n",
            "[I 2024-06-08 17:21:30,465] Trial 17 finished with value: 1.2713332124141485 and parameters: {'max_depth': 94, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 1 with value: 1.250652340047773.\n",
            "[I 2024-06-08 17:21:30,919] Trial 18 finished with value: 1.2873310630094963 and parameters: {'max_depth': 169, 'min_samples_split': 9, 'min_samples_leaf': 10}. Best is trial 1 with value: 1.250652340047773.\n",
            "[I 2024-06-08 17:21:31,337] Trial 19 finished with value: 1.2896419422724283 and parameters: {'max_depth': 133, 'min_samples_split': 14, 'min_samples_leaf': 19}. Best is trial 1 with value: 1.250652340047773.\n",
            "[I 2024-06-08 17:21:31,810] Trial 20 finished with value: 1.2330031175421798 and parameters: {'max_depth': 182, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 20 with value: 1.2330031175421798.\n",
            "[I 2024-06-08 17:21:32,314] Trial 21 finished with value: 1.2330031175421798 and parameters: {'max_depth': 185, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 20 with value: 1.2330031175421798.\n",
            "[I 2024-06-08 17:21:32,823] Trial 22 finished with value: 1.2445256410256411 and parameters: {'max_depth': 199, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 20 with value: 1.2330031175421798.\n",
            "[I 2024-06-08 17:21:33,293] Trial 23 finished with value: 1.2924879807692309 and parameters: {'max_depth': 200, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 20 with value: 1.2330031175421798.\n",
            "[I 2024-06-08 17:21:33,767] Trial 24 finished with value: 1.22176114770646 and parameters: {'max_depth': 186, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 24 with value: 1.22176114770646.\n",
            "[I 2024-06-08 17:21:34,243] Trial 25 finished with value: 1.2713332124141485 and parameters: {'max_depth': 183, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 24 with value: 1.22176114770646.\n",
            "[I 2024-06-08 17:21:34,743] Trial 26 finished with value: 1.227749224867013 and parameters: {'max_depth': 164, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 24 with value: 1.22176114770646.\n",
            "[I 2024-06-08 17:21:35,249] Trial 27 finished with value: 1.2440878504903288 and parameters: {'max_depth': 160, 'min_samples_split': 11, 'min_samples_leaf': 3}. Best is trial 24 with value: 1.22176114770646.\n",
            "[I 2024-06-08 17:21:35,709] Trial 28 finished with value: 1.2884581320313797 and parameters: {'max_depth': 185, 'min_samples_split': 10, 'min_samples_leaf': 17}. Best is trial 24 with value: 1.22176114770646.\n",
            "[I 2024-06-08 17:21:36,190] Trial 29 finished with value: 1.26295737530983 and parameters: {'max_depth': 168, 'min_samples_split': 15, 'min_samples_leaf': 5}. Best is trial 24 with value: 1.22176114770646.\n",
            "[I 2024-06-08 17:21:36,631] Trial 30 finished with value: 1.2816113693752789 and parameters: {'max_depth': 160, 'min_samples_split': 12, 'min_samples_leaf': 8}. Best is trial 24 with value: 1.22176114770646.\n",
            "[I 2024-06-08 17:21:37,103] Trial 31 finished with value: 1.22176114770646 and parameters: {'max_depth': 186, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 24 with value: 1.22176114770646.\n",
            "[I 2024-06-08 17:21:37,706] Trial 32 finished with value: 1.2277669423925432 and parameters: {'max_depth': 185, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 24 with value: 1.22176114770646.\n",
            "[I 2024-06-08 17:21:38,382] Trial 33 finished with value: 1.2510681970273319 and parameters: {'max_depth': 189, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 24 with value: 1.22176114770646.\n",
            "[I 2024-06-08 17:21:39,086] Trial 34 finished with value: 1.2874175960861447 and parameters: {'max_depth': 164, 'min_samples_split': 20, 'min_samples_leaf': 1}. Best is trial 24 with value: 1.22176114770646.\n",
            "[I 2024-06-08 17:21:39,792] Trial 35 finished with value: 1.2659613702380441 and parameters: {'max_depth': 176, 'min_samples_split': 11, 'min_samples_leaf': 5}. Best is trial 24 with value: 1.22176114770646.\n",
            "[I 2024-06-08 17:21:40,508] Trial 36 finished with value: 1.2426334015710518 and parameters: {'max_depth': 149, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 24 with value: 1.22176114770646.\n",
            "[I 2024-06-08 17:21:41,058] Trial 37 finished with value: 1.286992191453162 and parameters: {'max_depth': 190, 'min_samples_split': 8, 'min_samples_leaf': 14}. Best is trial 24 with value: 1.22176114770646.\n",
            "[I 2024-06-08 17:21:41,511] Trial 38 finished with value: 1.267298920386387 and parameters: {'max_depth': 179, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 24 with value: 1.22176114770646.\n",
            "[I 2024-06-08 17:21:41,965] Trial 39 finished with value: 1.2237280473933116 and parameters: {'max_depth': 165, 'min_samples_split': 11, 'min_samples_leaf': 2}. Best is trial 24 with value: 1.22176114770646.\n",
            "[I 2024-06-08 17:21:42,425] Trial 40 finished with value: 1.284393702653317 and parameters: {'max_depth': 104, 'min_samples_split': 13, 'min_samples_leaf': 12}. Best is trial 24 with value: 1.22176114770646.\n",
            "[I 2024-06-08 17:21:42,912] Trial 41 finished with value: 1.2237280473933116 and parameters: {'max_depth': 158, 'min_samples_split': 11, 'min_samples_leaf': 2}. Best is trial 24 with value: 1.22176114770646.\n",
            "[I 2024-06-08 17:21:43,385] Trial 42 finished with value: 1.2237280473933116 and parameters: {'max_depth': 155, 'min_samples_split': 11, 'min_samples_leaf': 2}. Best is trial 24 with value: 1.22176114770646.\n",
            "[I 2024-06-08 17:21:43,838] Trial 43 finished with value: 1.253616526099724 and parameters: {'max_depth': 139, 'min_samples_split': 16, 'min_samples_leaf': 4}. Best is trial 24 with value: 1.22176114770646.\n",
            "[I 2024-06-08 17:21:44,309] Trial 44 finished with value: 1.2909391494953293 and parameters: {'max_depth': 156, 'min_samples_split': 12, 'min_samples_leaf': 1}. Best is trial 24 with value: 1.22176114770646.\n",
            "[I 2024-06-08 17:21:44,771] Trial 45 finished with value: 1.2440878504903288 and parameters: {'max_depth': 141, 'min_samples_split': 11, 'min_samples_leaf': 3}. Best is trial 24 with value: 1.22176114770646.\n",
            "[I 2024-06-08 17:21:45,240] Trial 46 finished with value: 1.277486559898206 and parameters: {'max_depth': 59, 'min_samples_split': 13, 'min_samples_leaf': 7}. Best is trial 24 with value: 1.22176114770646.\n",
            "[I 2024-06-08 17:21:45,737] Trial 47 finished with value: 1.250652340047773 and parameters: {'max_depth': 125, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 24 with value: 1.22176114770646.\n",
            "[I 2024-06-08 17:21:46,257] Trial 48 finished with value: 1.283084975689154 and parameters: {'max_depth': 155, 'min_samples_split': 14, 'min_samples_leaf': 1}. Best is trial 24 with value: 1.22176114770646.\n",
            "[I 2024-06-08 17:21:46,737] Trial 49 finished with value: 1.2659613702380441 and parameters: {'max_depth': 173, 'min_samples_split': 11, 'min_samples_leaf': 5}. Best is trial 24 with value: 1.22176114770646.\n",
            "[I 2024-06-08 17:21:47,224] Trial 50 finished with value: 1.22176114770646 and parameters: {'max_depth': 146, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 24 with value: 1.22176114770646.\n",
            "[I 2024-06-08 17:21:47,709] Trial 51 finished with value: 1.22176114770646 and parameters: {'max_depth': 145, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 24 with value: 1.22176114770646.\n",
            "[I 2024-06-08 17:21:48,196] Trial 52 finished with value: 1.23861576464401 and parameters: {'max_depth': 148, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 24 with value: 1.22176114770646.\n",
            "[I 2024-06-08 17:21:48,690] Trial 53 finished with value: 1.2318147017912642 and parameters: {'max_depth': 125, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 24 with value: 1.22176114770646.\n",
            "[I 2024-06-08 17:21:49,187] Trial 54 finished with value: 1.2817363495879117 and parameters: {'max_depth': 133, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 24 with value: 1.22176114770646.\n",
            "[I 2024-06-08 17:21:49,692] Trial 55 finished with value: 1.250652340047773 and parameters: {'max_depth': 167, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 24 with value: 1.22176114770646.\n",
            "[I 2024-06-08 17:21:50,187] Trial 56 finished with value: 1.2392665832431458 and parameters: {'max_depth': 143, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 24 with value: 1.22176114770646.\n",
            "[I 2024-06-08 17:21:50,688] Trial 57 finished with value: 1.2277669423925432 and parameters: {'max_depth': 133, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 24 with value: 1.22176114770646.\n",
            "[I 2024-06-08 17:21:51,331] Trial 58 finished with value: 1.2713332124141485 and parameters: {'max_depth': 177, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 24 with value: 1.22176114770646.\n",
            "[I 2024-06-08 17:21:51,963] Trial 59 finished with value: 1.2895590062985427 and parameters: {'max_depth': 115, 'min_samples_split': 5, 'min_samples_leaf': 16}. Best is trial 24 with value: 1.22176114770646.\n",
            "[I 2024-06-08 17:21:52,680] Trial 60 finished with value: 1.295057742482976 and parameters: {'max_depth': 161, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 24 with value: 1.22176114770646.\n",
            "[I 2024-06-08 17:21:53,406] Trial 61 finished with value: 1.2260785825811633 and parameters: {'max_depth': 153, 'min_samples_split': 12, 'min_samples_leaf': 2}. Best is trial 24 with value: 1.22176114770646.\n",
            "[I 2024-06-08 17:21:54,125] Trial 62 finished with value: 1.2277669423925432 and parameters: {'max_depth': 145, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 24 with value: 1.22176114770646.\n",
            "[I 2024-06-08 17:21:54,691] Trial 63 finished with value: 1.2426334015710518 and parameters: {'max_depth': 195, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 24 with value: 1.22176114770646.\n",
            "[I 2024-06-08 17:21:55,146] Trial 64 finished with value: 1.2318147017912642 and parameters: {'max_depth': 138, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 24 with value: 1.22176114770646.\n",
            "[I 2024-06-08 17:21:55,613] Trial 65 finished with value: 1.259652705614034 and parameters: {'max_depth': 170, 'min_samples_split': 11, 'min_samples_leaf': 4}. Best is trial 24 with value: 1.22176114770646.\n",
            "[I 2024-06-08 17:21:56,080] Trial 66 finished with value: 1.2929961453477077 and parameters: {'max_depth': 157, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 24 with value: 1.22176114770646.\n",
            "[I 2024-06-08 17:21:56,529] Trial 67 finished with value: 1.267298920386387 and parameters: {'max_depth': 164, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 24 with value: 1.22176114770646.\n",
            "[I 2024-06-08 17:21:57,000] Trial 68 finished with value: 1.249309438841902 and parameters: {'max_depth': 151, 'min_samples_split': 13, 'min_samples_leaf': 3}. Best is trial 24 with value: 1.22176114770646.\n",
            "[I 2024-06-08 17:21:57,468] Trial 69 finished with value: 1.2924046866928476 and parameters: {'max_depth': 179, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 24 with value: 1.22176114770646.\n",
            "[I 2024-06-08 17:21:57,954] Trial 70 finished with value: 1.2587278737674965 and parameters: {'max_depth': 135, 'min_samples_split': 12, 'min_samples_leaf': 4}. Best is trial 24 with value: 1.22176114770646.\n",
            "[I 2024-06-08 17:21:58,412] Trial 71 finished with value: 1.2260785825811633 and parameters: {'max_depth': 153, 'min_samples_split': 12, 'min_samples_leaf': 2}. Best is trial 24 with value: 1.22176114770646.\n",
            "[I 2024-06-08 17:21:58,879] Trial 72 finished with value: 1.2182960877279085 and parameters: {'max_depth': 146, 'min_samples_split': 18, 'min_samples_leaf': 2}. Best is trial 72 with value: 1.2182960877279085.\n",
            "[I 2024-06-08 17:21:59,347] Trial 73 finished with value: 1.242336662370165 and parameters: {'max_depth': 129, 'min_samples_split': 18, 'min_samples_leaf': 3}. Best is trial 72 with value: 1.2182960877279085.\n",
            "[I 2024-06-08 17:21:59,780] Trial 74 finished with value: 1.2902695971251934 and parameters: {'max_depth': 189, 'min_samples_split': 14, 'min_samples_leaf': 20}. Best is trial 72 with value: 1.2182960877279085.\n",
            "[I 2024-06-08 17:22:00,212] Trial 75 finished with value: 1.2873310630094963 and parameters: {'max_depth': 145, 'min_samples_split': 19, 'min_samples_leaf': 10}. Best is trial 72 with value: 1.2182960877279085.\n",
            "[I 2024-06-08 17:22:00,678] Trial 76 finished with value: 1.295057742482976 and parameters: {'max_depth': 160, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 72 with value: 1.2182960877279085.\n",
            "[I 2024-06-08 17:22:01,143] Trial 77 finished with value: 1.2470486812364319 and parameters: {'max_depth': 148, 'min_samples_split': 16, 'min_samples_leaf': 3}. Best is trial 72 with value: 1.2182960877279085.\n",
            "[I 2024-06-08 17:22:01,610] Trial 78 finished with value: 1.2230473726020383 and parameters: {'max_depth': 167, 'min_samples_split': 17, 'min_samples_leaf': 2}. Best is trial 72 with value: 1.2182960877279085.\n",
            "[I 2024-06-08 17:22:02,091] Trial 79 finished with value: 1.2182960877279085 and parameters: {'max_depth': 172, 'min_samples_split': 18, 'min_samples_leaf': 2}. Best is trial 72 with value: 1.2182960877279085.\n",
            "[I 2024-06-08 17:22:02,560] Trial 80 finished with value: 1.2489148310472595 and parameters: {'max_depth': 175, 'min_samples_split': 18, 'min_samples_leaf': 4}. Best is trial 72 with value: 1.2182960877279085.\n",
            "[I 2024-06-08 17:22:03,057] Trial 81 finished with value: 1.2230473726020383 and parameters: {'max_depth': 182, 'min_samples_split': 17, 'min_samples_leaf': 2}. Best is trial 72 with value: 1.2182960877279085.\n",
            "[I 2024-06-08 17:22:03,554] Trial 82 finished with value: 1.2903751444316174 and parameters: {'max_depth': 183, 'min_samples_split': 17, 'min_samples_leaf': 1}. Best is trial 72 with value: 1.2182960877279085.\n",
            "[I 2024-06-08 17:22:04,028] Trial 83 finished with value: 1.2230473726020383 and parameters: {'max_depth': 195, 'min_samples_split': 17, 'min_samples_leaf': 2}. Best is trial 72 with value: 1.2182960877279085.\n",
            "[I 2024-06-08 17:22:04,539] Trial 84 finished with value: 1.250674315815893 and parameters: {'max_depth': 197, 'min_samples_split': 17, 'min_samples_leaf': 3}. Best is trial 72 with value: 1.2182960877279085.\n",
            "[I 2024-06-08 17:22:05,253] Trial 85 finished with value: 1.286171448863808 and parameters: {'max_depth': 189, 'min_samples_split': 19, 'min_samples_leaf': 1}. Best is trial 72 with value: 1.2182960877279085.\n",
            "[I 2024-06-08 17:22:05,964] Trial 86 finished with value: 1.2230473726020383 and parameters: {'max_depth': 192, 'min_samples_split': 17, 'min_samples_leaf': 2}. Best is trial 72 with value: 1.2182960877279085.\n",
            "[I 2024-06-08 17:22:06,654] Trial 87 finished with value: 1.2489148310472595 and parameters: {'max_depth': 180, 'min_samples_split': 18, 'min_samples_leaf': 4}. Best is trial 72 with value: 1.2182960877279085.\n",
            "[I 2024-06-08 17:22:07,365] Trial 88 finished with value: 1.229282824646132 and parameters: {'max_depth': 172, 'min_samples_split': 20, 'min_samples_leaf': 3}. Best is trial 72 with value: 1.2182960877279085.\n",
            "[I 2024-06-08 17:22:07,973] Trial 89 finished with value: 1.2078021092241071 and parameters: {'max_depth': 187, 'min_samples_split': 19, 'min_samples_leaf': 2}. Best is trial 89 with value: 1.2078021092241071.\n",
            "[I 2024-06-08 17:22:08,399] Trial 90 finished with value: 1.2895559823859206 and parameters: {'max_depth': 186, 'min_samples_split': 19, 'min_samples_leaf': 18}. Best is trial 89 with value: 1.2078021092241071.\n",
            "[I 2024-06-08 17:22:08,874] Trial 91 finished with value: 1.2182960877279085 and parameters: {'max_depth': 194, 'min_samples_split': 18, 'min_samples_leaf': 2}. Best is trial 89 with value: 1.2078021092241071.\n",
            "[I 2024-06-08 17:22:09,376] Trial 92 finished with value: 1.2182960877279085 and parameters: {'max_depth': 192, 'min_samples_split': 18, 'min_samples_leaf': 2}. Best is trial 89 with value: 1.2078021092241071.\n",
            "[I 2024-06-08 17:22:09,859] Trial 93 finished with value: 1.2322251329129583 and parameters: {'max_depth': 199, 'min_samples_split': 19, 'min_samples_leaf': 3}. Best is trial 89 with value: 1.2078021092241071.\n",
            "[I 2024-06-08 17:22:10,346] Trial 94 finished with value: 1.2905839288137197 and parameters: {'max_depth': 187, 'min_samples_split': 18, 'min_samples_leaf': 1}. Best is trial 89 with value: 1.2078021092241071.\n",
            "[I 2024-06-08 17:22:10,841] Trial 95 finished with value: 1.2064682894259735 and parameters: {'max_depth': 192, 'min_samples_split': 20, 'min_samples_leaf': 2}. Best is trial 95 with value: 1.2064682894259735.\n",
            "[I 2024-06-08 17:22:11,309] Trial 96 finished with value: 1.2874175960861447 and parameters: {'max_depth': 192, 'min_samples_split': 20, 'min_samples_leaf': 1}. Best is trial 95 with value: 1.2064682894259735.\n",
            "[I 2024-06-08 17:22:11,770] Trial 97 finished with value: 1.229282824646132 and parameters: {'max_depth': 199, 'min_samples_split': 20, 'min_samples_leaf': 3}. Best is trial 95 with value: 1.2064682894259735.\n",
            "[I 2024-06-08 17:22:12,211] Trial 98 finished with value: 1.284393702653317 and parameters: {'max_depth': 193, 'min_samples_split': 19, 'min_samples_leaf': 12}. Best is trial 95 with value: 1.2064682894259735.\n",
            "[I 2024-06-08 17:22:12,678] Trial 99 finished with value: 1.253616526099724 and parameters: {'max_depth': 101, 'min_samples_split': 16, 'min_samples_leaf': 4}. Best is trial 95 with value: 1.2064682894259735.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'max_depth': 192, 'min_samples_split': 20, 'min_samples_leaf': 2}\n",
            "Mean Absolute Error: 1.2064682894259735\n",
            "Mean Squared Error: 3.3992807664556177\n",
            "R2 Score: -1.770790942572083\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cat boost regressor\n",
        "CB_model = CatBoostRegressor(iterations=30, learning_rate=0.1, depth=5)\n",
        "CB_model.fit(X_train, Y_train)\n",
        "\n",
        "pred2 = CB_model.predict(X_valid)\n",
        "pred2\n",
        "\n",
        "# 평가지표(mae, mse, R)\n",
        "mae = mean_absolute_error(y_test, pred2)\n",
        "mse = mean_squared_error(y_test, pred2)\n",
        "r2 = r2_score(y_test, pred2)\n",
        "\n",
        "print(f'Mean Absolute Error: {mae}')\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "print(f'R2 Score: {r2}')"
      ],
      "metadata": {
        "id": "ZFs44v4EXdts",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2560d06d-dc6c-4dfe-f425-8ac4df14ce87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 1.0285030\ttotal: 47.2ms\tremaining: 1.37s\n",
            "1:\tlearn: 0.9370886\ttotal: 48.9ms\tremaining: 685ms\n",
            "2:\tlearn: 0.8523821\ttotal: 50.1ms\tremaining: 451ms\n",
            "3:\tlearn: 0.7797423\ttotal: 51.2ms\tremaining: 333ms\n",
            "4:\tlearn: 0.7195142\ttotal: 52.2ms\tremaining: 261ms\n",
            "5:\tlearn: 0.6581905\ttotal: 53.3ms\tremaining: 213ms\n",
            "6:\tlearn: 0.6034773\ttotal: 54.4ms\tremaining: 179ms\n",
            "7:\tlearn: 0.5578139\ttotal: 55.6ms\tremaining: 153ms\n",
            "8:\tlearn: 0.5148038\ttotal: 56.7ms\tremaining: 132ms\n",
            "9:\tlearn: 0.4769335\ttotal: 57.7ms\tremaining: 115ms\n",
            "10:\tlearn: 0.4496522\ttotal: 58.8ms\tremaining: 102ms\n",
            "11:\tlearn: 0.4199206\ttotal: 60ms\tremaining: 90ms\n",
            "12:\tlearn: 0.3940630\ttotal: 61.2ms\tremaining: 80ms\n",
            "13:\tlearn: 0.3711038\ttotal: 62.3ms\tremaining: 71.2ms\n",
            "14:\tlearn: 0.3542600\ttotal: 63.4ms\tremaining: 63.4ms\n",
            "15:\tlearn: 0.3388463\ttotal: 64.6ms\tremaining: 56.5ms\n",
            "16:\tlearn: 0.3240725\ttotal: 65.8ms\tremaining: 50.3ms\n",
            "17:\tlearn: 0.3115877\ttotal: 67ms\tremaining: 44.6ms\n",
            "18:\tlearn: 0.3008926\ttotal: 68.2ms\tremaining: 39.5ms\n",
            "19:\tlearn: 0.2908052\ttotal: 69.3ms\tremaining: 34.6ms\n",
            "20:\tlearn: 0.2825857\ttotal: 70.4ms\tremaining: 30.2ms\n",
            "21:\tlearn: 0.2770669\ttotal: 71.6ms\tremaining: 26ms\n",
            "22:\tlearn: 0.2731201\ttotal: 72.8ms\tremaining: 22.2ms\n",
            "23:\tlearn: 0.2673689\ttotal: 74ms\tremaining: 18.5ms\n",
            "24:\tlearn: 0.2624494\ttotal: 75.3ms\tremaining: 15.1ms\n",
            "25:\tlearn: 0.2582584\ttotal: 76.6ms\tremaining: 11.8ms\n",
            "26:\tlearn: 0.2545388\ttotal: 77.8ms\tremaining: 8.64ms\n",
            "27:\tlearn: 0.2523706\ttotal: 79ms\tremaining: 5.64ms\n",
            "28:\tlearn: 0.2502080\ttotal: 80.2ms\tremaining: 2.76ms\n",
            "29:\tlearn: 0.2477933\ttotal: 81.3ms\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostRegressor at 0x7bbc6e797250>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# optuna 적용\n",
        "# Objective 함수\n",
        "def objectiveCB(trial):\n",
        "        param = {\n",
        "            'iterations': trial.suggest_int('iterations', 100, 1000),\n",
        "            'depth': trial.suggest_int('depth', 4, 10),\n",
        "            'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.3, log=True),\n",
        "            'random_state': 42,\n",
        "            'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1, 20),\n",
        "            'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-3, 10.0, log=True)\n",
        "        }\n",
        "\n",
        "        model = CatBoostRegressor(**param)\n",
        "        model.fit(X_train, Y_train, eval_set=(x_test, y_test), early_stopping_rounds=50, verbose=0)\n",
        "        pred = model.predict(x_test)\n",
        "\n",
        "        mae = mean_absolute_error(y_test, pred)\n",
        "        return mae\n",
        "\n",
        "sampler = TPESampler(seed=42)\n",
        "study = optuna.create_study(\n",
        "    study_name='cb_parameter_opt',\n",
        "    direction='minimize',\n",
        "    sampler=sampler\n",
        ")\n",
        "\n",
        "# 최적화 실행 및 예외 처리\n",
        "try:\n",
        "    study.optimize(objectiveCB, n_trials=100)\n",
        "except Exception as e:\n",
        "    print(f'Optimization failed: {e}')\n",
        "\n",
        "# 최적화 완료 여부 확인\n",
        "if len(study.trials) == 0:\n",
        "    print(\"No trials were completed.\")\n",
        "else:\n",
        "    best_params = study.best_params\n",
        "    print('Best Parameters:', best_params)\n",
        "\n",
        "    # 최적의 하이퍼파라미터로 모델 학습\n",
        "    best_model = CatBoostRegressor(**best_params, random_state=42, verbose=0)\n",
        "    best_model.fit(X_train, Y_train)\n",
        "    pred2 = best_model.predict(x_test)\n",
        "\n",
        "    # 평가지표(mae, mse, R2)\n",
        "    mae = mean_absolute_error(y_test, pred2)\n",
        "    mse = mean_squared_error(y_test, pred2)\n",
        "    r2 = r2_score(y_test, pred2)\n",
        "\n",
        "    print(f'Mean Absolute Error: {mae}')\n",
        "    print(f'Mean Squared Error: {mse}')\n",
        "    print(f'R2 Score: {r2}')"
      ],
      "metadata": {
        "id": "hu6eCVS-9w_N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b504dac7-b4fb-4150-8580-6e5c8511411f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-06-08 17:31:17,083] A new study created in memory with name: cb_parameter_opt\n",
            "[I 2024-06-08 17:31:17,553] Trial 0 finished with value: 1.4502279853225173 and parameters: {'iterations': 437, 'depth': 10, 'learning_rate': 0.06504856968981275, 'min_data_in_leaf': 12, 'l2_leaf_reg': 0.004207988669606638}. Best is trial 0 with value: 1.4502279853225173.\n",
            "[I 2024-06-08 17:31:17,639] Trial 1 finished with value: 1.4781606146197737 and parameters: {'iterations': 240, 'depth': 4, 'learning_rate': 0.13983740016490973, 'min_data_in_leaf': 13, 'l2_leaf_reg': 0.679657809075816}. Best is trial 0 with value: 1.4502279853225173.\n",
            "[I 2024-06-08 17:31:18,057] Trial 2 finished with value: 1.4654711344989564 and parameters: {'iterations': 118, 'depth': 10, 'learning_rate': 0.11536162338241392, 'min_data_in_leaf': 5, 'l2_leaf_reg': 0.005337032762603957}. Best is trial 0 with value: 1.4502279853225173.\n",
            "[I 2024-06-08 17:31:18,166] Trial 3 finished with value: 1.551212024157547 and parameters: {'iterations': 265, 'depth': 6, 'learning_rate': 0.0199473547030745, 'min_data_in_leaf': 9, 'l2_leaf_reg': 0.014618962793704957}. Best is trial 0 with value: 1.4502279853225173.\n",
            "[I 2024-06-08 17:31:18,274] Trial 4 finished with value: 1.5413033988845561 and parameters: {'iterations': 651, 'depth': 4, 'learning_rate': 0.005292705365436975, 'min_data_in_leaf': 8, 'l2_leaf_reg': 0.06672367170464207}. Best is trial 0 with value: 1.4502279853225173.\n",
            "[I 2024-06-08 17:31:18,376] Trial 5 finished with value: 1.5117298534394714 and parameters: {'iterations': 807, 'depth': 5, 'learning_rate': 0.018785426399210624, 'min_data_in_leaf': 12, 'l2_leaf_reg': 0.0015339162591163618}. Best is trial 0 with value: 1.4502279853225173.\n",
            "[I 2024-06-08 17:31:18,611] Trial 6 finished with value: 1.527876224050336 and parameters: {'iterations': 647, 'depth': 5, 'learning_rate': 0.0014492412389916862, 'min_data_in_leaf': 19, 'l2_leaf_reg': 7.2866537374910445}. Best is trial 0 with value: 1.4502279853225173.\n",
            "[I 2024-06-08 17:31:19,021] Trial 7 finished with value: 1.4751588466053998 and parameters: {'iterations': 828, 'depth': 6, 'learning_rate': 0.0017456037635797405, 'min_data_in_leaf': 14, 'l2_leaf_reg': 0.057624872164786026}. Best is trial 0 with value: 1.4502279853225173.\n",
            "[I 2024-06-08 17:31:19,321] Trial 8 finished with value: 1.5616843230404238 and parameters: {'iterations': 209, 'depth': 7, 'learning_rate': 0.0012167028814593455, 'min_data_in_leaf': 19, 'l2_leaf_reg': 0.010842262717330166}. Best is trial 0 with value: 1.4502279853225173.\n",
            "[I 2024-06-08 17:31:19,474] Trial 9 finished with value: 1.552101565711246 and parameters: {'iterations': 696, 'depth': 6, 'learning_rate': 0.01942099825171803, 'min_data_in_leaf': 11, 'l2_leaf_reg': 0.0054880470007660455}. Best is trial 0 with value: 1.4502279853225173.\n",
            "[I 2024-06-08 17:31:20,374] Trial 10 finished with value: 1.4708367430192373 and parameters: {'iterations': 437, 'depth': 10, 'learning_rate': 0.053011269715584376, 'min_data_in_leaf': 1, 'l2_leaf_reg': 0.0011520489947554333}. Best is trial 0 with value: 1.4502279853225173.\n",
            "[I 2024-06-08 17:31:22,065] Trial 11 finished with value: 1.4980282610421374 and parameters: {'iterations': 438, 'depth': 10, 'learning_rate': 0.2485870307209927, 'min_data_in_leaf': 4, 'l2_leaf_reg': 0.3757084358753147}. Best is trial 0 with value: 1.4502279853225173.\n",
            "[I 2024-06-08 17:31:23,298] Trial 12 finished with value: 1.4224731380665263 and parameters: {'iterations': 110, 'depth': 9, 'learning_rate': 0.07381672044425394, 'min_data_in_leaf': 6, 'l2_leaf_reg': 0.004273713494269304}. Best is trial 12 with value: 1.4224731380665263.\n",
            "[I 2024-06-08 17:31:24,337] Trial 13 finished with value: 1.4536014228494725 and parameters: {'iterations': 405, 'depth': 9, 'learning_rate': 0.055576533958701706, 'min_data_in_leaf': 16, 'l2_leaf_reg': 0.02425911784567092}. Best is trial 12 with value: 1.4224731380665263.\n",
            "[I 2024-06-08 17:31:24,873] Trial 14 finished with value: 1.4553956670649069 and parameters: {'iterations': 371, 'depth': 8, 'learning_rate': 0.05260048573838175, 'min_data_in_leaf': 7, 'l2_leaf_reg': 0.0028402106335961817}. Best is trial 12 with value: 1.4224731380665263.\n",
            "[I 2024-06-08 17:31:25,775] Trial 15 finished with value: 1.4810745778174703 and parameters: {'iterations': 970, 'depth': 9, 'learning_rate': 0.007065703402403497, 'min_data_in_leaf': 2, 'l2_leaf_reg': 0.2637432983169996}. Best is trial 12 with value: 1.4224731380665263.\n",
            "[I 2024-06-08 17:31:26,291] Trial 16 finished with value: 1.5319486621408405 and parameters: {'iterations': 102, 'depth': 8, 'learning_rate': 0.10430810808487936, 'min_data_in_leaf': 6, 'l2_leaf_reg': 2.376404722989417}. Best is trial 12 with value: 1.4224731380665263.\n",
            "[I 2024-06-08 17:31:27,138] Trial 17 finished with value: 1.4515423106035308 and parameters: {'iterations': 515, 'depth': 9, 'learning_rate': 0.03457632271077725, 'min_data_in_leaf': 16, 'l2_leaf_reg': 0.031017445744165442}. Best is trial 12 with value: 1.4224731380665263.\n",
            "[I 2024-06-08 17:31:27,641] Trial 18 finished with value: 1.497276878037796 and parameters: {'iterations': 292, 'depth': 8, 'learning_rate': 0.2352969042071728, 'min_data_in_leaf': 10, 'l2_leaf_reg': 0.006215248098281735}. Best is trial 12 with value: 1.4224731380665263.\n",
            "[I 2024-06-08 17:31:28,510] Trial 19 finished with value: 1.4981850054358858 and parameters: {'iterations': 522, 'depth': 9, 'learning_rate': 0.006024830347834524, 'min_data_in_leaf': 3, 'l2_leaf_reg': 0.0025387100845517506}. Best is trial 12 with value: 1.4224731380665263.\n",
            "[I 2024-06-08 17:31:29,566] Trial 20 finished with value: 1.5061531008111992 and parameters: {'iterations': 340, 'depth': 10, 'learning_rate': 0.03511377665670117, 'min_data_in_leaf': 16, 'l2_leaf_reg': 0.1340125232840253}. Best is trial 12 with value: 1.4224731380665263.\n",
            "[I 2024-06-08 17:31:29,933] Trial 21 finished with value: 1.4554445405505616 and parameters: {'iterations': 586, 'depth': 9, 'learning_rate': 0.03326714570825514, 'min_data_in_leaf': 15, 'l2_leaf_reg': 0.011727356356888331}. Best is trial 12 with value: 1.4224731380665263.\n",
            "[I 2024-06-08 17:31:30,212] Trial 22 finished with value: 1.3505707479644105 and parameters: {'iterations': 535, 'depth': 9, 'learning_rate': 0.08352419818132016, 'min_data_in_leaf': 17, 'l2_leaf_reg': 0.022542925727061305}. Best is trial 22 with value: 1.3505707479644105.\n",
            "[I 2024-06-08 17:31:30,428] Trial 23 finished with value: 1.3403982414169073 and parameters: {'iterations': 732, 'depth': 8, 'learning_rate': 0.07664693941888392, 'min_data_in_leaf': 18, 'l2_leaf_reg': 0.025799658157365332}. Best is trial 23 with value: 1.3403982414169073.\n",
            "[I 2024-06-08 17:31:30,571] Trial 24 finished with value: 1.531883177021238 and parameters: {'iterations': 788, 'depth': 7, 'learning_rate': 0.14641248825278536, 'min_data_in_leaf': 20, 'l2_leaf_reg': 0.032209492576637626}. Best is trial 23 with value: 1.3403982414169073.\n",
            "[I 2024-06-08 17:31:30,773] Trial 25 finished with value: 1.535805992611447 and parameters: {'iterations': 913, 'depth': 8, 'learning_rate': 0.08402990775563833, 'min_data_in_leaf': 18, 'l2_leaf_reg': 0.1189517976209084}. Best is trial 23 with value: 1.3403982414169073.\n",
            "[I 2024-06-08 17:31:30,916] Trial 26 finished with value: 1.581264761294335 and parameters: {'iterations': 740, 'depth': 7, 'learning_rate': 0.010576087930636172, 'min_data_in_leaf': 18, 'l2_leaf_reg': 0.016000073338245387}. Best is trial 23 with value: 1.3403982414169073.\n",
            "[I 2024-06-08 17:31:31,171] Trial 27 finished with value: 1.2467553103609903 and parameters: {'iterations': 900, 'depth': 8, 'learning_rate': 0.20166946388244217, 'min_data_in_leaf': 17, 'l2_leaf_reg': 0.043369655401102734}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:31,361] Trial 28 finished with value: 1.4757720377224304 and parameters: {'iterations': 875, 'depth': 8, 'learning_rate': 0.2936101562805519, 'min_data_in_leaf': 17, 'l2_leaf_reg': 0.05281163579063482}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:31,557] Trial 29 finished with value: 1.5287346960452823 and parameters: {'iterations': 963, 'depth': 8, 'learning_rate': 0.16105073280137738, 'min_data_in_leaf': 20, 'l2_leaf_reg': 0.26397137502297785}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:31,710] Trial 30 finished with value: 1.5133061145394464 and parameters: {'iterations': 602, 'depth': 7, 'learning_rate': 0.21695466412467215, 'min_data_in_leaf': 14, 'l2_leaf_reg': 0.7498219215595534}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:31,971] Trial 31 finished with value: 1.4179611351805894 and parameters: {'iterations': 738, 'depth': 9, 'learning_rate': 0.07683879401159682, 'min_data_in_leaf': 17, 'l2_leaf_reg': 0.008739087592252259}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:32,214] Trial 32 finished with value: 1.4343345996528996 and parameters: {'iterations': 752, 'depth': 9, 'learning_rate': 0.09210379204335617, 'min_data_in_leaf': 17, 'l2_leaf_reg': 0.02586617745258297}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:32,394] Trial 33 finished with value: 1.5205472858843403 and parameters: {'iterations': 721, 'depth': 8, 'learning_rate': 0.17510713643888173, 'min_data_in_leaf': 13, 'l2_leaf_reg': 0.00838263628593507}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:32,717] Trial 34 finished with value: 1.541706505933812 and parameters: {'iterations': 860, 'depth': 10, 'learning_rate': 0.12204030035583889, 'min_data_in_leaf': 18, 'l2_leaf_reg': 0.08454453132547161}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:32,984] Trial 35 finished with value: 1.467010744948532 and parameters: {'iterations': 671, 'depth': 9, 'learning_rate': 0.02962207170194326, 'min_data_in_leaf': 15, 'l2_leaf_reg': 0.03782675242035058}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:33,264] Trial 36 finished with value: 1.3238627734960415 and parameters: {'iterations': 489, 'depth': 8, 'learning_rate': 0.06963421528866158, 'min_data_in_leaf': 17, 'l2_leaf_reg': 0.017177317972299357}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:33,610] Trial 37 finished with value: 1.4903015526240078 and parameters: {'iterations': 493, 'depth': 7, 'learning_rate': 0.012740873763891202, 'min_data_in_leaf': 19, 'l2_leaf_reg': 0.0193061502901703}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:34,324] Trial 38 finished with value: 1.5326539002720048 and parameters: {'iterations': 619, 'depth': 8, 'learning_rate': 0.002708239153481832, 'min_data_in_leaf': 13, 'l2_leaf_reg': 0.047044441861767344}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:34,506] Trial 39 finished with value: 1.5185922318845952 and parameters: {'iterations': 478, 'depth': 6, 'learning_rate': 0.11385000552159016, 'min_data_in_leaf': 15, 'l2_leaf_reg': 0.16985197702538513}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:34,872] Trial 40 finished with value: 1.4621900214820143 and parameters: {'iterations': 578, 'depth': 8, 'learning_rate': 0.025908642647493704, 'min_data_in_leaf': 12, 'l2_leaf_reg': 0.07027170547345626}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:35,359] Trial 41 finished with value: 1.4290440985255386 and parameters: {'iterations': 786, 'depth': 9, 'learning_rate': 0.06955910411308605, 'min_data_in_leaf': 17, 'l2_leaf_reg': 0.010354637916835364}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:35,662] Trial 42 finished with value: 1.5560967282909886 and parameters: {'iterations': 547, 'depth': 7, 'learning_rate': 0.050155763969413396, 'min_data_in_leaf': 19, 'l2_leaf_reg': 0.017177645995746067}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:36,038] Trial 43 finished with value: 1.3810027599446668 and parameters: {'iterations': 650, 'depth': 8, 'learning_rate': 0.041941177631787695, 'min_data_in_leaf': 17, 'l2_leaf_reg': 0.0027382683167750787}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:36,449] Trial 44 finished with value: 1.388194652997497 and parameters: {'iterations': 631, 'depth': 8, 'learning_rate': 0.03965947333269964, 'min_data_in_leaf': 20, 'l2_leaf_reg': 0.0024332472077703065}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:36,597] Trial 45 finished with value: 1.572814494321239 and parameters: {'iterations': 679, 'depth': 7, 'learning_rate': 0.023673833170041177, 'min_data_in_leaf': 14, 'l2_leaf_reg': 0.00152155253432505}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:36,831] Trial 46 finished with value: 1.3746911817267802 and parameters: {'iterations': 466, 'depth': 8, 'learning_rate': 0.04430826549794527, 'min_data_in_leaf': 18, 'l2_leaf_reg': 0.0033468552156777796}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:36,960] Trial 47 finished with value: 1.445533504621097 and parameters: {'iterations': 461, 'depth': 4, 'learning_rate': 0.19238459906759978, 'min_data_in_leaf': 18, 'l2_leaf_reg': 0.006615288609869966}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:37,114] Trial 48 finished with value: 1.5493763755526258 and parameters: {'iterations': 368, 'depth': 7, 'learning_rate': 0.06097739121383505, 'min_data_in_leaf': 16, 'l2_leaf_reg': 0.02013501016781049}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:37,245] Trial 49 finished with value: 1.5008962493422382 and parameters: {'iterations': 411, 'depth': 5, 'learning_rate': 0.13390470186701942, 'min_data_in_leaf': 19, 'l2_leaf_reg': 0.00387432779429445}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:37,435] Trial 50 finished with value: 1.5260419917352714 and parameters: {'iterations': 551, 'depth': 8, 'learning_rate': 0.09897614158501908, 'min_data_in_leaf': 9, 'l2_leaf_reg': 0.0010630583371079522}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:37,656] Trial 51 finished with value: 1.4213280192873035 and parameters: {'iterations': 185, 'depth': 8, 'learning_rate': 0.045204022771275734, 'min_data_in_leaf': 17, 'l2_leaf_reg': 0.0038579980076149643}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:37,850] Trial 52 finished with value: 1.545226767101161 and parameters: {'iterations': 544, 'depth': 8, 'learning_rate': 0.06748572782635269, 'min_data_in_leaf': 18, 'l2_leaf_reg': 0.0018781700421441675}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:38,109] Trial 53 finished with value: 1.3800844968821684 and parameters: {'iterations': 832, 'depth': 8, 'learning_rate': 0.0423135562910676, 'min_data_in_leaf': 16, 'l2_leaf_reg': 0.013122346625329887}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:38,421] Trial 54 finished with value: 1.471308433035547 and parameters: {'iterations': 908, 'depth': 9, 'learning_rate': 0.013605426316103748, 'min_data_in_leaf': 15, 'l2_leaf_reg': 0.013316068054063941}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:38,683] Trial 55 finished with value: 1.439080148669082 and parameters: {'iterations': 824, 'depth': 9, 'learning_rate': 0.08825049968815926, 'min_data_in_leaf': 16, 'l2_leaf_reg': 0.04048413639938977}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:39,032] Trial 56 finished with value: 1.4596358224049113 and parameters: {'iterations': 949, 'depth': 10, 'learning_rate': 0.05954550009954114, 'min_data_in_leaf': 19, 'l2_leaf_reg': 0.02404668994622433}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:39,261] Trial 57 finished with value: 1.4703142404003393 and parameters: {'iterations': 876, 'depth': 8, 'learning_rate': 0.023767964442162524, 'min_data_in_leaf': 16, 'l2_leaf_reg': 0.06807181910597973}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:39,410] Trial 58 finished with value: 1.4731978600128068 and parameters: {'iterations': 923, 'depth': 6, 'learning_rate': 0.29768344285807635, 'min_data_in_leaf': 20, 'l2_leaf_reg': 0.0067017281640189795}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:39,568] Trial 59 finished with value: 1.5765544906804219 and parameters: {'iterations': 999, 'depth': 7, 'learning_rate': 0.0178743205796455, 'min_data_in_leaf': 14, 'l2_leaf_reg': 0.012410196326546984}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:39,833] Trial 60 finished with value: 1.5411322635843905 and parameters: {'iterations': 319, 'depth': 9, 'learning_rate': 0.12169287358404401, 'min_data_in_leaf': 18, 'l2_leaf_reg': 0.0049412056476843555}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:40,108] Trial 61 finished with value: 1.3770932829471396 and parameters: {'iterations': 654, 'depth': 8, 'learning_rate': 0.043884618778932565, 'min_data_in_leaf': 17, 'l2_leaf_reg': 0.003153983732591977}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:40,318] Trial 62 finished with value: 1.4173334773452408 and parameters: {'iterations': 706, 'depth': 8, 'learning_rate': 0.04698644857368065, 'min_data_in_leaf': 18, 'l2_leaf_reg': 0.029151777854985482}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:40,528] Trial 63 finished with value: 1.4616352246989417 and parameters: {'iterations': 772, 'depth': 8, 'learning_rate': 0.030516921283655102, 'min_data_in_leaf': 17, 'l2_leaf_reg': 0.008100193888947387}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:40,679] Trial 64 finished with value: 1.5635652333349153 and parameters: {'iterations': 831, 'depth': 7, 'learning_rate': 0.03826102650212989, 'min_data_in_leaf': 15, 'l2_leaf_reg': 0.014988640200665562}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:40,897] Trial 65 finished with value: 1.3938416400642337 and parameters: {'iterations': 444, 'depth': 8, 'learning_rate': 0.05672680016313509, 'min_data_in_leaf': 16, 'l2_leaf_reg': 6.7084822152458745}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:41,200] Trial 66 finished with value: 1.353158868925607 and parameters: {'iterations': 500, 'depth': 9, 'learning_rate': 0.08134883094378592, 'min_data_in_leaf': 19, 'l2_leaf_reg': 0.0014773055761445777}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:41,467] Trial 67 finished with value: 1.4152934926829936 and parameters: {'iterations': 514, 'depth': 9, 'learning_rate': 0.07864101800392462, 'min_data_in_leaf': 20, 'l2_leaf_reg': 0.0033133602080221165}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:41,807] Trial 68 finished with value: 1.5305053734777045 and parameters: {'iterations': 394, 'depth': 10, 'learning_rate': 0.14910880207802063, 'min_data_in_leaf': 19, 'l2_leaf_reg': 0.001597724122579663}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:42,067] Trial 69 finished with value: 1.421754684782102 and parameters: {'iterations': 572, 'depth': 9, 'learning_rate': 0.10282699710486275, 'min_data_in_leaf': 18, 'l2_leaf_reg': 0.0012930125861660747}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:42,306] Trial 70 finished with value: 1.5189327019982426 and parameters: {'iterations': 505, 'depth': 9, 'learning_rate': 0.1790660432363079, 'min_data_in_leaf': 17, 'l2_leaf_reg': 0.0020041456313834873}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:42,500] Trial 71 finished with value: 1.5455131028346214 and parameters: {'iterations': 464, 'depth': 8, 'learning_rate': 0.06739913054863546, 'min_data_in_leaf': 19, 'l2_leaf_reg': 0.04736345202762902}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:42,724] Trial 72 finished with value: 1.3401932715229743 and parameters: {'iterations': 605, 'depth': 8, 'learning_rate': 0.07719145932925504, 'min_data_in_leaf': 16, 'l2_leaf_reg': 0.021382801350602713}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:42,913] Trial 73 finished with value: 1.5351894639367918 and parameters: {'iterations': 603, 'depth': 8, 'learning_rate': 0.08419413553064857, 'min_data_in_leaf': 18, 'l2_leaf_reg': 0.033828754003816956}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:43,169] Trial 74 finished with value: 1.4739446849205904 and parameters: {'iterations': 542, 'depth': 9, 'learning_rate': 0.10620079166664909, 'min_data_in_leaf': 17, 'l2_leaf_reg': 0.020719729221468197}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:43,375] Trial 75 finished with value: 1.4521890992154547 and parameters: {'iterations': 484, 'depth': 8, 'learning_rate': 0.05458511576709856, 'min_data_in_leaf': 19, 'l2_leaf_reg': 0.08647247372085}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:43,529] Trial 76 finished with value: 1.5406066778820768 and parameters: {'iterations': 668, 'depth': 7, 'learning_rate': 0.07508993331427433, 'min_data_in_leaf': 16, 'l2_leaf_reg': 0.005117652319491227}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:43,800] Trial 77 finished with value: 1.3008027915312432 and parameters: {'iterations': 631, 'depth': 9, 'learning_rate': 0.21912299454906808, 'min_data_in_leaf': 15, 'l2_leaf_reg': 0.009468461983808199}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:44,176] Trial 78 finished with value: 1.5061466922816886 and parameters: {'iterations': 622, 'depth': 10, 'learning_rate': 0.2124872321077573, 'min_data_in_leaf': 12, 'l2_leaf_reg': 0.010082310412880323}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:44,459] Trial 79 finished with value: 1.5351630285737994 and parameters: {'iterations': 568, 'depth': 9, 'learning_rate': 0.1385166523208936, 'min_data_in_leaf': 15, 'l2_leaf_reg': 0.05659184750620279}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:44,739] Trial 80 finished with value: 1.5019200364515148 and parameters: {'iterations': 529, 'depth': 9, 'learning_rate': 0.22404354038564983, 'min_data_in_leaf': 11, 'l2_leaf_reg': 0.023928540272721194}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:44,947] Trial 81 finished with value: 1.2899901308898971 and parameters: {'iterations': 597, 'depth': 8, 'learning_rate': 0.251837555726995, 'min_data_in_leaf': 17, 'l2_leaf_reg': 0.003294435411978069}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:45,243] Trial 82 finished with value: 1.488274689842992 and parameters: {'iterations': 604, 'depth': 9, 'learning_rate': 0.2584104239699957, 'min_data_in_leaf': 17, 'l2_leaf_reg': 0.002279872556111003}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:45,435] Trial 83 finished with value: 1.4874951087570514 and parameters: {'iterations': 434, 'depth': 8, 'learning_rate': 0.26114724716660387, 'min_data_in_leaf': 18, 'l2_leaf_reg': 0.016389640105594776}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:45,682] Trial 84 finished with value: 1.5156364744069042 and parameters: {'iterations': 491, 'depth': 9, 'learning_rate': 0.1878185482243826, 'min_data_in_leaf': 19, 'l2_leaf_reg': 0.008065120409736939}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:45,875] Trial 85 finished with value: 1.5265678846451798 and parameters: {'iterations': 694, 'depth': 8, 'learning_rate': 0.16053832388029513, 'min_data_in_leaf': 15, 'l2_leaf_reg': 0.04169338756270419}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:46,238] Trial 86 finished with value: 1.485719358990496 and parameters: {'iterations': 583, 'depth': 10, 'learning_rate': 0.09373189392979651, 'min_data_in_leaf': 14, 'l2_leaf_reg': 0.030286545541330086}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:46,402] Trial 87 finished with value: 1.5395474019051085 and parameters: {'iterations': 641, 'depth': 7, 'learning_rate': 0.12582843866312746, 'min_data_in_leaf': 18, 'l2_leaf_reg': 0.00624759444419594}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:46,777] Trial 88 finished with value: 1.4919749121079064 and parameters: {'iterations': 456, 'depth': 8, 'learning_rate': 0.2489504468081624, 'min_data_in_leaf': 16, 'l2_leaf_reg': 0.00463616140126767}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:47,243] Trial 89 finished with value: 1.5265885181564747 and parameters: {'iterations': 420, 'depth': 9, 'learning_rate': 0.15981574054980477, 'min_data_in_leaf': 20, 'l2_leaf_reg': 0.019973301594450345}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:47,711] Trial 90 finished with value: 1.5112048999449312 and parameters: {'iterations': 389, 'depth': 9, 'learning_rate': 0.199400830545951, 'min_data_in_leaf': 13, 'l2_leaf_reg': 0.010670255615885802}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:48,113] Trial 91 finished with value: 1.43348153449447 and parameters: {'iterations': 685, 'depth': 8, 'learning_rate': 0.06525693257153072, 'min_data_in_leaf': 17, 'l2_leaf_reg': 0.003225518547492919}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:48,473] Trial 92 finished with value: 1.516252068084067 and parameters: {'iterations': 664, 'depth': 8, 'learning_rate': 0.11540497130585482, 'min_data_in_leaf': 17, 'l2_leaf_reg': 0.0014792114397182458}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:48,893] Trial 93 finished with value: 1.407802346725194 and parameters: {'iterations': 718, 'depth': 8, 'learning_rate': 0.05132641350605876, 'min_data_in_leaf': 17, 'l2_leaf_reg': 0.0032023336946619125}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:49,483] Trial 94 finished with value: 1.4085224661406135 and parameters: {'iterations': 562, 'depth': 8, 'learning_rate': 0.035756595908608906, 'min_data_in_leaf': 16, 'l2_leaf_reg': 0.0018963048960039866}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:49,836] Trial 95 finished with value: 1.5359864820305802 and parameters: {'iterations': 599, 'depth': 8, 'learning_rate': 0.08257046062190504, 'min_data_in_leaf': 18, 'l2_leaf_reg': 0.004018021808084315}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:50,100] Trial 96 finished with value: 1.5438660916260172 and parameters: {'iterations': 528, 'depth': 7, 'learning_rate': 0.0022733820844631036, 'min_data_in_leaf': 15, 'l2_leaf_reg': 0.11681649830047348}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:50,321] Trial 97 finished with value: 1.4169182196145487 and parameters: {'iterations': 645, 'depth': 8, 'learning_rate': 0.047119872230438474, 'min_data_in_leaf': 18, 'l2_leaf_reg': 0.001090218576374863}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:50,579] Trial 98 finished with value: 1.4238298696971063 and parameters: {'iterations': 501, 'depth': 9, 'learning_rate': 0.07308135314940817, 'min_data_in_leaf': 19, 'l2_leaf_reg': 0.03567520381323157}. Best is trial 27 with value: 1.2467553103609903.\n",
            "[I 2024-06-08 17:31:50,788] Trial 99 finished with value: 1.4401531042116238 and parameters: {'iterations': 615, 'depth': 8, 'learning_rate': 0.06108159811335699, 'min_data_in_leaf': 16, 'l2_leaf_reg': 0.0023352803011300605}. Best is trial 27 with value: 1.2467553103609903.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'iterations': 900, 'depth': 8, 'learning_rate': 0.20166946388244217, 'min_data_in_leaf': 17, 'l2_leaf_reg': 0.043369655401102734}\n",
            "Mean Absolute Error: 1.3161054336594717\n",
            "Mean Squared Error: 3.4153879317862734\n",
            "R2 Score: -1.7839200692535568\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ada boost regressor\n",
        "AB_model = AdaBoostRegressor(n_estimators=30, learning_rate=0.1, random_state=12)\n",
        "AB_model.fit(X_train, Y_train)\n",
        "\n",
        "pred3 = AB_model.predict(X_valid)\n",
        "pred3\n",
        "\n",
        "# 평가지표(mae, mse, R)\n",
        "mae = mean_absolute_error(y_test, pred3)\n",
        "mse = mean_squared_error(y_test, pred3)\n",
        "r2 = r2_score(y_test, pred3)\n",
        "\n",
        "print(f'Mean Absolute Error: {mae}')\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "print(f'R2 Score: {r2}')"
      ],
      "metadata": {
        "id": "wxiFazrUZPBQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "49be4f85-34e1-4b6c-b0bc-0e626a382ddf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AdaBoostRegressor(learning_rate=0.1, n_estimators=30, random_state=12)"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostRegressor(learning_rate=0.1, n_estimators=30, random_state=12)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostRegressor</label><div class=\"sk-toggleable__content\"><pre>AdaBoostRegressor(learning_rate=0.1, n_estimators=30, random_state=12)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# optuna 적용\n",
        "# Objective 함수\n",
        "def objectiveAB(trial):\n",
        "    param = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 1.0, log=True),\n",
        "        'loss': trial.suggest_categorical('loss', ['linear', 'square', 'exponential']),\n",
        "        'random_state': 42\n",
        "    }\n",
        "\n",
        "    model = AdaBoostRegressor(**param)\n",
        "    model.fit(X_train, Y_train)\n",
        "    pred = model.predict(x_test)\n",
        "\n",
        "    mae = mean_absolute_error(y_test, pred)\n",
        "    return mae\n",
        "\n",
        "sampler = TPESampler(seed=42)\n",
        "study = optuna.create_study(\n",
        "    study_name='ab_parameter_opt',\n",
        "    direction='minimize',\n",
        "    sampler=sampler\n",
        ")\n",
        "\n",
        "# 최적화 실행 및 예외 처리\n",
        "try:\n",
        "    study.optimize(objectiveAB, n_trials=100)\n",
        "except Exception as e:\n",
        "    print(f'Optimization failed: {e}')\n",
        "\n",
        "# 최적화 완료 여부 확인\n",
        "if len(study.trials) == 0:\n",
        "    print(\"No trials were completed.\")\n",
        "else:\n",
        "    best_params = study.best_params\n",
        "    print('Best Parameters:', best_params)\n",
        "\n",
        "    # 최적의 하이퍼파라미터로 모델 학습\n",
        "    best_model = AdaBoostRegressor(**best_params, random_state=42)\n",
        "    best_model.fit(X_train, Y_train)\n",
        "    pred = best_model.predict(x_test)\n",
        "\n",
        "    # 평가지표(mae, mse, R2)\n",
        "    mae = mean_absolute_error(y_test, pred)\n",
        "    mse = mean_squared_error(y_test, pred)\n",
        "    r2 = r2_score(y_test, pred)\n",
        "\n",
        "    print(f'Mean Absolute Error: {mae}')\n",
        "    print(f'Mean Squared Error: {mse}')\n",
        "    print(f'R2 Score: {r2}')"
      ],
      "metadata": {
        "id": "AQJin7-4-lqF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "598e236e-17ff-48ed-df73-6c895efb8282"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-06-08 17:34:20,960] A new study created in memory with name: ab_parameter_opt\n",
            "[I 2024-06-08 17:34:21,131] Trial 0 finished with value: 1.367839697469596 and parameters: {'n_estimators': 218, 'learning_rate': 0.7969454818643931, 'loss': 'linear'}. Best is trial 0 with value: 1.367839697469596.\n",
            "[I 2024-06-08 17:34:21,795] Trial 1 finished with value: 1.315875153215054 and parameters: {'n_estimators': 120, 'learning_rate': 0.01306673923805328, 'loss': 'linear'}. Best is trial 1 with value: 1.315875153215054.\n",
            "[I 2024-06-08 17:34:21,888] Trial 2 finished with value: 1.462768994861863 and parameters: {'n_estimators': 59, 'learning_rate': 0.8706020878304853, 'loss': 'linear'}. Best is trial 1 with value: 1.315875153215054.\n",
            "[I 2024-06-08 17:34:22,438] Trial 3 finished with value: 1.3365293800112765 and parameters: {'n_estimators': 132, 'learning_rate': 0.04059611610484305, 'loss': 'linear'}. Best is trial 1 with value: 1.315875153215054.\n",
            "[I 2024-06-08 17:34:23,839] Trial 4 finished with value: 1.3448857021099525 and parameters: {'n_estimators': 325, 'learning_rate': 0.01901024531987036, 'loss': 'exponential'}. Best is trial 1 with value: 1.315875153215054.\n",
            "[I 2024-06-08 17:34:25,060] Trial 5 finished with value: 1.345186133523131 and parameters: {'n_estimators': 404, 'learning_rate': 0.025081156860452335, 'loss': 'square'}. Best is trial 1 with value: 1.315875153215054.\n",
            "[I 2024-06-08 17:34:27,008] Trial 6 finished with value: 1.3576478186330052 and parameters: {'n_estimators': 324, 'learning_rate': 0.021930485556643693, 'loss': 'exponential'}. Best is trial 1 with value: 1.315875153215054.\n",
            "[I 2024-06-08 17:34:28,123] Trial 7 finished with value: 1.3548591136536778 and parameters: {'n_estimators': 414, 'learning_rate': 0.040665633135147955, 'loss': 'square'}. Best is trial 1 with value: 1.315875153215054.\n",
            "[I 2024-06-08 17:34:28,669] Trial 8 finished with value: 1.3857227292753758 and parameters: {'n_estimators': 105, 'learning_rate': 0.09780337016659407, 'loss': 'square'}. Best is trial 1 with value: 1.315875153215054.\n",
            "[I 2024-06-08 17:34:29,370] Trial 9 finished with value: 1.3511521086340144 and parameters: {'n_estimators': 348, 'learning_rate': 0.0420167205437253, 'loss': 'square'}. Best is trial 1 with value: 1.315875153215054.\n",
            "[I 2024-06-08 17:34:30,306] Trial 10 finished with value: 1.320781977304964 and parameters: {'n_estimators': 211, 'learning_rate': 0.010280029617905608, 'loss': 'linear'}. Best is trial 1 with value: 1.315875153215054.\n",
            "[I 2024-06-08 17:34:31,229] Trial 11 finished with value: 1.3206907916830117 and parameters: {'n_estimators': 206, 'learning_rate': 0.01069188700212349, 'loss': 'linear'}. Best is trial 1 with value: 1.315875153215054.\n",
            "[I 2024-06-08 17:34:32,170] Trial 12 finished with value: 1.3204082329128708 and parameters: {'n_estimators': 206, 'learning_rate': 0.01051435730400179, 'loss': 'linear'}. Best is trial 1 with value: 1.315875153215054.\n",
            "[I 2024-06-08 17:34:32,323] Trial 13 finished with value: 1.3380463493645771 and parameters: {'n_estimators': 151, 'learning_rate': 0.2733762389478874, 'loss': 'linear'}. Best is trial 1 with value: 1.315875153215054.\n",
            "[I 2024-06-08 17:34:32,648] Trial 14 finished with value: 1.3628958876156392 and parameters: {'n_estimators': 258, 'learning_rate': 0.10501286263505404, 'loss': 'linear'}. Best is trial 1 with value: 1.315875153215054.\n",
            "[I 2024-06-08 17:34:32,969] Trial 15 finished with value: 1.3477200998392946 and parameters: {'n_estimators': 70, 'learning_rate': 0.08866922971325704, 'loss': 'linear'}. Best is trial 1 with value: 1.315875153215054.\n",
            "[I 2024-06-08 17:34:33,677] Trial 16 finished with value: 1.3167555110933706 and parameters: {'n_estimators': 163, 'learning_rate': 0.015769501935345438, 'loss': 'exponential'}. Best is trial 1 with value: 1.315875153215054.\n",
            "[I 2024-06-08 17:34:34,271] Trial 17 finished with value: 1.6066378053106738 and parameters: {'n_estimators': 158, 'learning_rate': 0.2035569014975125, 'loss': 'exponential'}. Best is trial 1 with value: 1.315875153215054.\n",
            "[I 2024-06-08 17:34:34,717] Trial 18 finished with value: 1.311147048968072 and parameters: {'n_estimators': 101, 'learning_rate': 0.01873345813826454, 'loss': 'exponential'}. Best is trial 18 with value: 1.311147048968072.\n",
            "[I 2024-06-08 17:34:36,792] Trial 19 finished with value: 1.473155718847488 and parameters: {'n_estimators': 499, 'learning_rate': 0.030743260265507548, 'loss': 'exponential'}. Best is trial 18 with value: 1.311147048968072.\n",
            "[I 2024-06-08 17:34:37,254] Trial 20 finished with value: 1.3627157367612148 and parameters: {'n_estimators': 107, 'learning_rate': 0.06821018330793575, 'loss': 'exponential'}. Best is trial 18 with value: 1.311147048968072.\n",
            "[I 2024-06-08 17:34:37,971] Trial 21 finished with value: 1.3162861867428803 and parameters: {'n_estimators': 158, 'learning_rate': 0.016535963159650276, 'loss': 'exponential'}. Best is trial 18 with value: 1.311147048968072.\n",
            "[I 2024-06-08 17:34:38,239] Trial 22 finished with value: 1.3203322468616112 and parameters: {'n_estimators': 55, 'learning_rate': 0.01617650372932997, 'loss': 'exponential'}. Best is trial 18 with value: 1.311147048968072.\n",
            "[I 2024-06-08 17:34:38,750] Trial 23 finished with value: 1.3145256214695125 and parameters: {'n_estimators': 110, 'learning_rate': 0.015042425874316999, 'loss': 'exponential'}. Best is trial 18 with value: 1.311147048968072.\n",
            "[I 2024-06-08 17:34:39,262] Trial 24 finished with value: 1.3325679285967797 and parameters: {'n_estimators': 82, 'learning_rate': 0.058328699795035674, 'loss': 'exponential'}. Best is trial 18 with value: 1.311147048968072.\n",
            "[I 2024-06-08 17:34:40,017] Trial 25 finished with value: 1.3126578991155415 and parameters: {'n_estimators': 125, 'learning_rate': 0.013773851940677343, 'loss': 'exponential'}. Best is trial 18 with value: 1.311147048968072.\n",
            "[I 2024-06-08 17:34:41,449] Trial 26 finished with value: 1.359257605200817 and parameters: {'n_estimators': 240, 'learning_rate': 0.02851481568382962, 'loss': 'exponential'}. Best is trial 18 with value: 1.311147048968072.\n",
            "[I 2024-06-08 17:34:42,326] Trial 27 finished with value: 1.6423379751179528 and parameters: {'n_estimators': 183, 'learning_rate': 0.21932608435924414, 'loss': 'exponential'}. Best is trial 18 with value: 1.311147048968072.\n",
            "[I 2024-06-08 17:34:43,448] Trial 28 finished with value: 1.351617447393062 and parameters: {'n_estimators': 279, 'learning_rate': 0.022363162419670343, 'loss': 'exponential'}. Best is trial 18 with value: 1.311147048968072.\n",
            "[I 2024-06-08 17:34:43,808] Trial 29 finished with value: 1.632169021859417 and parameters: {'n_estimators': 91, 'learning_rate': 0.4798156216545931, 'loss': 'exponential'}. Best is trial 18 with value: 1.311147048968072.\n",
            "[I 2024-06-08 17:34:44,384] Trial 30 finished with value: 1.3465618511302408 and parameters: {'n_estimators': 137, 'learning_rate': 0.03456216367623013, 'loss': 'exponential'}. Best is trial 18 with value: 1.311147048968072.\n",
            "[I 2024-06-08 17:34:44,896] Trial 31 finished with value: 1.3137578990113072 and parameters: {'n_estimators': 117, 'learning_rate': 0.01362581211071209, 'loss': 'exponential'}. Best is trial 18 with value: 1.311147048968072.\n",
            "[I 2024-06-08 17:34:45,382] Trial 32 finished with value: 1.3160332718817749 and parameters: {'n_estimators': 112, 'learning_rate': 0.013421025896840024, 'loss': 'exponential'}. Best is trial 18 with value: 1.311147048968072.\n",
            "[I 2024-06-08 17:34:46,204] Trial 33 finished with value: 1.3141865359130938 and parameters: {'n_estimators': 176, 'learning_rate': 0.01371117442092049, 'loss': 'exponential'}. Best is trial 18 with value: 1.311147048968072.\n",
            "[I 2024-06-08 17:34:47,030] Trial 34 finished with value: 1.314014679665905 and parameters: {'n_estimators': 182, 'learning_rate': 0.012257320112370435, 'loss': 'exponential'}. Best is trial 18 with value: 1.311147048968072.\n",
            "[I 2024-06-08 17:34:47,265] Trial 35 finished with value: 1.320032024680946 and parameters: {'n_estimators': 50, 'learning_rate': 0.021068079467666433, 'loss': 'exponential'}. Best is trial 18 with value: 1.311147048968072.\n",
            "[I 2024-06-08 17:34:47,839] Trial 36 finished with value: 1.353332414973354 and parameters: {'n_estimators': 134, 'learning_rate': 0.051087225024198706, 'loss': 'exponential'}. Best is trial 18 with value: 1.311147048968072.\n",
            "[I 2024-06-08 17:34:48,627] Trial 37 finished with value: 1.3278376835447743 and parameters: {'n_estimators': 187, 'learning_rate': 0.019368110107619716, 'loss': 'exponential'}. Best is trial 18 with value: 1.311147048968072.\n",
            "[I 2024-06-08 17:34:49,026] Trial 38 finished with value: 1.317397076841781 and parameters: {'n_estimators': 85, 'learning_rate': 0.02628177363270927, 'loss': 'square'}. Best is trial 18 with value: 1.311147048968072.\n",
            "[I 2024-06-08 17:34:50,033] Trial 39 finished with value: 1.3174856925606533 and parameters: {'n_estimators': 234, 'learning_rate': 0.012100937452524068, 'loss': 'exponential'}. Best is trial 18 with value: 1.311147048968072.\n",
            "[I 2024-06-08 17:34:50,620] Trial 40 finished with value: 1.3088049182931951 and parameters: {'n_estimators': 141, 'learning_rate': 0.01889470610175821, 'loss': 'square'}. Best is trial 40 with value: 1.3088049182931951.\n",
            "[I 2024-06-08 17:34:51,169] Trial 41 finished with value: 1.3099098153598538 and parameters: {'n_estimators': 131, 'learning_rate': 0.019484432258779532, 'loss': 'square'}. Best is trial 40 with value: 1.3088049182931951.\n",
            "[I 2024-06-08 17:34:51,752] Trial 42 finished with value: 1.3075261066511483 and parameters: {'n_estimators': 141, 'learning_rate': 0.018718027255593333, 'loss': 'square'}. Best is trial 42 with value: 1.3075261066511483.\n",
            "[I 2024-06-08 17:34:52,432] Trial 43 finished with value: 1.3071165979534436 and parameters: {'n_estimators': 135, 'learning_rate': 0.03519003524268592, 'loss': 'square'}. Best is trial 43 with value: 1.3071165979534436.\n",
            "[I 2024-06-08 17:34:53,295] Trial 44 finished with value: 1.319924429807255 and parameters: {'n_estimators': 145, 'learning_rate': 0.03351277765369013, 'loss': 'square'}. Best is trial 43 with value: 1.3071165979534436.\n",
            "[I 2024-06-08 17:34:55,005] Trial 45 finished with value: 1.3436072796706051 and parameters: {'n_estimators': 295, 'learning_rate': 0.02414055824560928, 'loss': 'square'}. Best is trial 43 with value: 1.3071165979534436.\n",
            "[I 2024-06-08 17:34:55,553] Trial 46 finished with value: 1.3080909474122455 and parameters: {'n_estimators': 88, 'learning_rate': 0.04329108153454853, 'loss': 'square'}. Best is trial 43 with value: 1.3071165979534436.\n",
            "[I 2024-06-08 17:34:56,253] Trial 47 finished with value: 1.3436474367596938 and parameters: {'n_estimators': 394, 'learning_rate': 0.04433514886139315, 'loss': 'square'}. Best is trial 43 with value: 1.3071165979534436.\n",
            "[I 2024-06-08 17:34:56,609] Trial 48 finished with value: 1.3436071980394266 and parameters: {'n_estimators': 79, 'learning_rate': 0.07347540906119701, 'loss': 'square'}. Best is trial 43 with value: 1.3071165979534436.\n",
            "[I 2024-06-08 17:34:56,994] Trial 49 finished with value: 1.4700244153549276 and parameters: {'n_estimators': 202, 'learning_rate': 0.13344796520124455, 'loss': 'square'}. Best is trial 43 with value: 1.3071165979534436.\n",
            "[I 2024-06-08 17:34:57,846] Trial 50 finished with value: 1.3400782007963075 and parameters: {'n_estimators': 226, 'learning_rate': 0.03542745270938966, 'loss': 'square'}. Best is trial 43 with value: 1.3071165979534436.\n",
            "[I 2024-06-08 17:34:58,266] Trial 51 finished with value: 1.3134852694710415 and parameters: {'n_estimators': 97, 'learning_rate': 0.019740852805023124, 'loss': 'square'}. Best is trial 43 with value: 1.3071165979534436.\n",
            "[I 2024-06-08 17:34:58,552] Trial 52 finished with value: 1.3218965770218067 and parameters: {'n_estimators': 67, 'learning_rate': 0.02498029924457994, 'loss': 'square'}. Best is trial 43 with value: 1.3071165979534436.\n",
            "[I 2024-06-08 17:34:59,102] Trial 53 finished with value: 1.311570563722622 and parameters: {'n_estimators': 131, 'learning_rate': 0.017479460668545103, 'loss': 'square'}. Best is trial 43 with value: 1.3071165979534436.\n",
            "[I 2024-06-08 17:34:59,762] Trial 54 finished with value: 1.3413891126889286 and parameters: {'n_estimators': 168, 'learning_rate': 0.05002472347898946, 'loss': 'square'}. Best is trial 43 with value: 1.3071165979534436.\n",
            "[I 2024-06-08 17:35:00,375] Trial 55 finished with value: 1.3136243547634616 and parameters: {'n_estimators': 146, 'learning_rate': 0.03884473918764479, 'loss': 'square'}. Best is trial 43 with value: 1.3071165979534436.\n",
            "[I 2024-06-08 17:35:00,782] Trial 56 finished with value: 1.3136782545040768 and parameters: {'n_estimators': 96, 'learning_rate': 0.029233676816750057, 'loss': 'square'}. Best is trial 43 with value: 1.3071165979534436.\n",
            "[I 2024-06-08 17:35:01,300] Trial 57 finished with value: 1.3141803153078728 and parameters: {'n_estimators': 119, 'learning_rate': 0.018026733879496253, 'loss': 'square'}. Best is trial 43 with value: 1.3071165979534436.\n",
            "[I 2024-06-08 17:35:01,726] Trial 58 finished with value: 1.3278450417106085 and parameters: {'n_estimators': 64, 'learning_rate': 0.010022431313970761, 'loss': 'square'}. Best is trial 43 with value: 1.3071165979534436.\n",
            "[I 2024-06-08 17:35:01,794] Trial 59 finished with value: 1.5281847402715498 and parameters: {'n_estimators': 193, 'learning_rate': 0.7210639779225905, 'loss': 'square'}. Best is trial 43 with value: 1.3071165979534436.\n",
            "[I 2024-06-08 17:35:02,473] Trial 60 finished with value: 1.3137544195626027 and parameters: {'n_estimators': 160, 'learning_rate': 0.02265960617994907, 'loss': 'square'}. Best is trial 43 with value: 1.3071165979534436.\n",
            "[I 2024-06-08 17:35:03,011] Trial 61 finished with value: 1.3067086144528919 and parameters: {'n_estimators': 128, 'learning_rate': 0.01733956870791962, 'loss': 'square'}. Best is trial 61 with value: 1.3067086144528919.\n",
            "[I 2024-06-08 17:35:03,455] Trial 62 finished with value: 1.3129222879447835 and parameters: {'n_estimators': 103, 'learning_rate': 0.02690185549526202, 'loss': 'square'}. Best is trial 61 with value: 1.3067086144528919.\n",
            "[I 2024-06-08 17:35:04,001] Trial 63 finished with value: 1.3092869656038364 and parameters: {'n_estimators': 127, 'learning_rate': 0.017012929517319586, 'loss': 'square'}. Best is trial 61 with value: 1.3067086144528919.\n",
            "[I 2024-06-08 17:35:04,706] Trial 64 finished with value: 1.312346648117356 and parameters: {'n_estimators': 151, 'learning_rate': 0.015965352033777348, 'loss': 'square'}. Best is trial 61 with value: 1.3067086144528919.\n",
            "[I 2024-06-08 17:35:05,251] Trial 65 finished with value: 1.3227091557841224 and parameters: {'n_estimators': 126, 'learning_rate': 0.011746154448988577, 'loss': 'square'}. Best is trial 61 with value: 1.3067086144528919.\n",
            "[I 2024-06-08 17:35:05,630] Trial 66 finished with value: 1.3228007226314171 and parameters: {'n_estimators': 75, 'learning_rate': 0.022295571184768614, 'loss': 'square'}. Best is trial 61 with value: 1.3067086144528919.\n",
            "[I 2024-06-08 17:35:06,643] Trial 67 finished with value: 1.331963676601697 and parameters: {'n_estimators': 169, 'learning_rate': 0.02964552447129275, 'loss': 'linear'}. Best is trial 61 with value: 1.3067086144528919.\n",
            "[I 2024-06-08 17:35:07,547] Trial 68 finished with value: 1.315007244875519 and parameters: {'n_estimators': 143, 'learning_rate': 0.014912008925756852, 'loss': 'square'}. Best is trial 61 with value: 1.3067086144528919.\n",
            "[I 2024-06-08 17:35:08,237] Trial 69 finished with value: 1.3877438678725855 and parameters: {'n_estimators': 111, 'learning_rate': 0.06462483129116024, 'loss': 'square'}. Best is trial 61 with value: 1.3067086144528919.\n",
            "[I 2024-06-08 17:35:08,708] Trial 70 finished with value: 1.367902675829789 and parameters: {'n_estimators': 217, 'learning_rate': 0.11978784288265823, 'loss': 'square'}. Best is trial 61 with value: 1.3067086144528919.\n",
            "[I 2024-06-08 17:35:09,154] Trial 71 finished with value: 1.3131059595560746 and parameters: {'n_estimators': 93, 'learning_rate': 0.01929526685279198, 'loss': 'square'}. Best is trial 61 with value: 1.3067086144528919.\n",
            "[I 2024-06-08 17:35:09,705] Trial 72 finished with value: 1.318434483639207 and parameters: {'n_estimators': 125, 'learning_rate': 0.01564562359031137, 'loss': 'square'}. Best is trial 61 with value: 1.3067086144528919.\n",
            "[I 2024-06-08 17:35:10,312] Trial 73 finished with value: 1.329069724557949 and parameters: {'n_estimators': 137, 'learning_rate': 0.01788081795539899, 'loss': 'linear'}. Best is trial 61 with value: 1.3067086144528919.\n",
            "[I 2024-06-08 17:35:10,833] Trial 74 finished with value: 1.3109721754964487 and parameters: {'n_estimators': 107, 'learning_rate': 0.020659950833188494, 'loss': 'square'}. Best is trial 61 with value: 1.3067086144528919.\n",
            "[I 2024-06-08 17:35:11,493] Trial 75 finished with value: 1.3283638715787094 and parameters: {'n_estimators': 157, 'learning_rate': 0.045597354003152415, 'loss': 'square'}. Best is trial 61 with value: 1.3067086144528919.\n",
            "[I 2024-06-08 17:35:11,988] Trial 76 finished with value: 1.3074295299128997 and parameters: {'n_estimators': 113, 'learning_rate': 0.03737125713069431, 'loss': 'square'}. Best is trial 61 with value: 1.3067086144528919.\n",
            "[I 2024-06-08 17:35:12,532] Trial 77 finished with value: 1.3121471564237963 and parameters: {'n_estimators': 119, 'learning_rate': 0.03803502434251623, 'loss': 'square'}. Best is trial 61 with value: 1.3067086144528919.\n",
            "[I 2024-06-08 17:35:12,931] Trial 78 finished with value: 1.3280447293393332 and parameters: {'n_estimators': 84, 'learning_rate': 0.05545637776052907, 'loss': 'square'}. Best is trial 61 with value: 1.3067086144528919.\n",
            "[I 2024-06-08 17:35:13,919] Trial 79 finished with value: 1.3596097626566044 and parameters: {'n_estimators': 338, 'learning_rate': 0.03172701418962845, 'loss': 'square'}. Best is trial 61 with value: 1.3067086144528919.\n",
            "[I 2024-06-08 17:35:14,669] Trial 80 finished with value: 1.321175867748407 and parameters: {'n_estimators': 171, 'learning_rate': 0.025427389396175906, 'loss': 'square'}. Best is trial 61 with value: 1.3067086144528919.\n",
            "[I 2024-06-08 17:35:15,149] Trial 81 finished with value: 1.313275413776919 and parameters: {'n_estimators': 105, 'learning_rate': 0.020174180170616982, 'loss': 'square'}. Best is trial 61 with value: 1.3067086144528919.\n",
            "[I 2024-06-08 17:35:15,748] Trial 82 finished with value: 1.3172519465333004 and parameters: {'n_estimators': 133, 'learning_rate': 0.021851437588194106, 'loss': 'square'}. Best is trial 61 with value: 1.3067086144528919.\n",
            "[I 2024-06-08 17:35:16,049] Trial 83 finished with value: 1.3236098112172505 and parameters: {'n_estimators': 60, 'learning_rate': 0.011894346288609399, 'loss': 'square'}. Best is trial 61 with value: 1.3067086144528919.\n",
            "[I 2024-06-08 17:35:17,850] Trial 84 finished with value: 1.3315311156562595 and parameters: {'n_estimators': 445, 'learning_rate': 0.014353317907524582, 'loss': 'square'}. Best is trial 61 with value: 1.3067086144528919.\n",
            "[I 2024-06-08 17:35:18,367] Trial 85 finished with value: 1.309298470651775 and parameters: {'n_estimators': 114, 'learning_rate': 0.033078479259589, 'loss': 'square'}. Best is trial 61 with value: 1.3067086144528919.\n",
            "[I 2024-06-08 17:35:19,118] Trial 86 finished with value: 1.3391353210428252 and parameters: {'n_estimators': 149, 'learning_rate': 0.04201687583956299, 'loss': 'square'}. Best is trial 61 with value: 1.3067086144528919.\n",
            "[I 2024-06-08 17:35:19,633] Trial 87 finished with value: 1.3448769712797728 and parameters: {'n_estimators': 86, 'learning_rate': 0.07681972001536594, 'loss': 'linear'}. Best is trial 61 with value: 1.3067086144528919.\n",
            "[I 2024-06-08 17:35:20,329] Trial 88 finished with value: 1.3279281847227082 and parameters: {'n_estimators': 116, 'learning_rate': 0.03554368038963789, 'loss': 'square'}. Best is trial 61 with value: 1.3067086144528919.\n",
            "[I 2024-06-08 17:35:21,178] Trial 89 finished with value: 1.3199200895023255 and parameters: {'n_estimators': 137, 'learning_rate': 0.0284570657190875, 'loss': 'square'}. Best is trial 61 with value: 1.3067086144528919.\n",
            "[I 2024-06-08 17:35:21,781] Trial 90 finished with value: 1.3241596573753194 and parameters: {'n_estimators': 96, 'learning_rate': 0.05053360001638098, 'loss': 'square'}. Best is trial 61 with value: 1.3067086144528919.\n",
            "[I 2024-06-08 17:35:22,447] Trial 91 finished with value: 1.3126258339463017 and parameters: {'n_estimators': 107, 'learning_rate': 0.023644760856339982, 'loss': 'square'}. Best is trial 61 with value: 1.3067086144528919.\n",
            "[I 2024-06-08 17:35:22,788] Trial 92 finished with value: 1.321912610876163 and parameters: {'n_estimators': 76, 'learning_rate': 0.017695396525092055, 'loss': 'square'}. Best is trial 61 with value: 1.3067086144528919.\n",
            "[I 2024-06-08 17:35:23,315] Trial 93 finished with value: 1.3126836397423316 and parameters: {'n_estimators': 124, 'learning_rate': 0.0202235427496401, 'loss': 'square'}. Best is trial 61 with value: 1.3067086144528919.\n",
            "[I 2024-06-08 17:35:23,813] Trial 94 finished with value: 1.3104285602313215 and parameters: {'n_estimators': 113, 'learning_rate': 0.030610181280174797, 'loss': 'square'}. Best is trial 61 with value: 1.3067086144528919.\n",
            "[I 2024-06-08 17:35:24,641] Trial 95 finished with value: 1.3477411162359458 and parameters: {'n_estimators': 195, 'learning_rate': 0.03395852475679457, 'loss': 'square'}. Best is trial 61 with value: 1.3067086144528919.\n",
            "[I 2024-06-08 17:35:25,323] Trial 96 finished with value: 1.3465873268948647 and parameters: {'n_estimators': 155, 'learning_rate': 0.04628099522665527, 'loss': 'square'}. Best is trial 61 with value: 1.3067086144528919.\n",
            "[I 2024-06-08 17:35:25,955] Trial 97 finished with value: 1.3268074547626982 and parameters: {'n_estimators': 143, 'learning_rate': 0.03147744436573926, 'loss': 'square'}. Best is trial 61 with value: 1.3067086144528919.\n",
            "[I 2024-06-08 17:35:26,747] Trial 98 finished with value: 1.3200393327600932 and parameters: {'n_estimators': 178, 'learning_rate': 0.02614133294098764, 'loss': 'square'}. Best is trial 61 with value: 1.3067086144528919.\n",
            "[I 2024-06-08 17:35:27,318] Trial 99 finished with value: 1.3211986002158005 and parameters: {'n_estimators': 127, 'learning_rate': 0.03703557005825398, 'loss': 'square'}. Best is trial 61 with value: 1.3067086144528919.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'n_estimators': 128, 'learning_rate': 0.01733956870791962, 'loss': 'square'}\n",
            "Mean Absolute Error: 1.3067086144528919\n",
            "Mean Squared Error: 3.7386592926945976\n",
            "R2 Score: -2.04742209228053\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Voting regressor\n",
        "\n",
        "앙상블 기법 중 하나로, 서로 다른 회귀 모델을 결합하여 예측 성능을 향상시키는 방법이다.\n",
        "\n",
        "이를 통해 개별 모델의 약점을 보완하고, 예측 성능을 향상 시킬 수 있다."
      ],
      "metadata": {
        "id": "EPb7aGgUsvT8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 모델에서 얻은 최적의 하이퍼파라미터\n",
        "best_params_dt = {'max_depth': 186, 'min_samples_split': 8, 'min_samples_leaf': 2}\n",
        "best_params_rf = {'max_depth': 192, 'min_samples_split': 20, 'min_samples_leaf': 2}\n",
        "best_params_cb = {'iterations': 900, 'depth': 8, 'learning_rate': 0.2, 'min_data_in_leaf': 17, 'l2_leaf_reg': 0.04}\n",
        "best_params_ab = {'n_estimators': 128, 'learning_rate': 0.02, 'loss': 'square'}\n",
        "\n",
        "# RandomForestRegressor 생성\n",
        "dt_model = DecisionTreeRegressor(**best_params_dt, random_state=42)\n",
        "\n",
        "# DecisionTreeRegressor 생성\n",
        "rf_model = RandomForestRegressor(**best_params_rf, random_state=42)\n",
        "\n",
        "# AdaBoostRegressor 생성\n",
        "cb_model = CatBoostRegressor(**best_params_cb, random_state=42)\n",
        "\n",
        "# CatBoostRegressor 생성\n",
        "ab_model = AdaBoostRegressor(**best_params_ab, random_state=42)\n",
        "\n",
        "# VotingRegressor 생성\n",
        "voting_model = VotingRegressor(estimators=[\n",
        "    ('dt', dt_model),\n",
        "    ('rf', rf_model),\n",
        "    ('cb', cb_model),\n",
        "    ('ab', ab_model)\n",
        "])\n",
        "\n",
        "# VotingRegressor 학습\n",
        "voting_model.fit(X_train, Y_train)\n",
        "\n",
        "# VotingRegressor 평가\n",
        "pred = voting_model.predict(x_test)\n",
        "mae = mean_absolute_error(y_test, pred)\n",
        "mse = mean_squared_error(y_test, pred)\n",
        "r2 = r2_score(y_test, pred)\n",
        "print(f'Mean Absolute Error: {mae}')\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "print(f'R2 Score: {r2}')"
      ],
      "metadata": {
        "id": "lh5rshiMbZhk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "690b16c0-8719-4109-ab21-dafef865ce92"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 0.9108894\ttotal: 1.37ms\tremaining: 1.24s\n",
            "1:\tlearn: 0.7434909\ttotal: 6.83ms\tremaining: 3.07s\n",
            "2:\tlearn: 0.6129783\ttotal: 8.97ms\tremaining: 2.68s\n",
            "3:\tlearn: 0.5210275\ttotal: 12.7ms\tremaining: 2.84s\n",
            "4:\tlearn: 0.4401652\ttotal: 15.5ms\tremaining: 2.78s\n",
            "5:\tlearn: 0.3779391\ttotal: 18.3ms\tremaining: 2.73s\n",
            "6:\tlearn: 0.3353524\ttotal: 20.8ms\tremaining: 2.65s\n",
            "7:\tlearn: 0.3011591\ttotal: 23.7ms\tremaining: 2.64s\n",
            "8:\tlearn: 0.2792434\ttotal: 26.9ms\tremaining: 2.66s\n",
            "9:\tlearn: 0.2566009\ttotal: 29.7ms\tremaining: 2.64s\n",
            "10:\tlearn: 0.2407643\ttotal: 32.7ms\tremaining: 2.64s\n",
            "11:\tlearn: 0.2294617\ttotal: 36.3ms\tremaining: 2.69s\n",
            "12:\tlearn: 0.2217652\ttotal: 41.9ms\tremaining: 2.86s\n",
            "13:\tlearn: 0.2138549\ttotal: 46.2ms\tremaining: 2.92s\n",
            "14:\tlearn: 0.2094166\ttotal: 54.1ms\tremaining: 3.19s\n",
            "15:\tlearn: 0.2050723\ttotal: 61.8ms\tremaining: 3.41s\n",
            "16:\tlearn: 0.2009220\ttotal: 69.4ms\tremaining: 3.6s\n",
            "17:\tlearn: 0.1977736\ttotal: 76.7ms\tremaining: 3.76s\n",
            "18:\tlearn: 0.1969825\ttotal: 81.8ms\tremaining: 3.79s\n",
            "19:\tlearn: 0.1944538\ttotal: 86.5ms\tremaining: 3.81s\n",
            "20:\tlearn: 0.1917305\ttotal: 94.8ms\tremaining: 3.97s\n",
            "21:\tlearn: 0.1907948\ttotal: 101ms\tremaining: 4.03s\n",
            "22:\tlearn: 0.1889900\ttotal: 109ms\tremaining: 4.15s\n",
            "23:\tlearn: 0.1854599\ttotal: 114ms\tremaining: 4.15s\n",
            "24:\tlearn: 0.1845296\ttotal: 123ms\tremaining: 4.31s\n",
            "25:\tlearn: 0.1813540\ttotal: 133ms\tremaining: 4.48s\n",
            "26:\tlearn: 0.1793778\ttotal: 142ms\tremaining: 4.59s\n",
            "27:\tlearn: 0.1778484\ttotal: 148ms\tremaining: 4.62s\n",
            "28:\tlearn: 0.1759760\ttotal: 157ms\tremaining: 4.71s\n",
            "29:\tlearn: 0.1745107\ttotal: 164ms\tremaining: 4.77s\n",
            "30:\tlearn: 0.1730393\ttotal: 172ms\tremaining: 4.82s\n",
            "31:\tlearn: 0.1712583\ttotal: 188ms\tremaining: 5.11s\n",
            "32:\tlearn: 0.1706182\ttotal: 192ms\tremaining: 5.05s\n",
            "33:\tlearn: 0.1697306\ttotal: 200ms\tremaining: 5.1s\n",
            "34:\tlearn: 0.1677543\ttotal: 210ms\tremaining: 5.18s\n",
            "35:\tlearn: 0.1636752\ttotal: 216ms\tremaining: 5.17s\n",
            "36:\tlearn: 0.1623101\ttotal: 225ms\tremaining: 5.25s\n",
            "37:\tlearn: 0.1615924\ttotal: 229ms\tremaining: 5.19s\n",
            "38:\tlearn: 0.1600357\ttotal: 237ms\tremaining: 5.23s\n",
            "39:\tlearn: 0.1574594\ttotal: 245ms\tremaining: 5.26s\n",
            "40:\tlearn: 0.1564769\ttotal: 252ms\tremaining: 5.29s\n",
            "41:\tlearn: 0.1550175\ttotal: 260ms\tremaining: 5.3s\n",
            "42:\tlearn: 0.1538946\ttotal: 269ms\tremaining: 5.36s\n",
            "43:\tlearn: 0.1529669\ttotal: 273ms\tremaining: 5.32s\n",
            "44:\tlearn: 0.1514956\ttotal: 281ms\tremaining: 5.35s\n",
            "45:\tlearn: 0.1505326\ttotal: 289ms\tremaining: 5.36s\n",
            "46:\tlearn: 0.1471675\ttotal: 296ms\tremaining: 5.37s\n",
            "47:\tlearn: 0.1431121\ttotal: 309ms\tremaining: 5.49s\n",
            "48:\tlearn: 0.1422811\ttotal: 320ms\tremaining: 5.55s\n",
            "49:\tlearn: 0.1397526\ttotal: 326ms\tremaining: 5.54s\n",
            "50:\tlearn: 0.1387407\ttotal: 334ms\tremaining: 5.57s\n",
            "51:\tlearn: 0.1370383\ttotal: 343ms\tremaining: 5.6s\n",
            "52:\tlearn: 0.1363022\ttotal: 351ms\tremaining: 5.62s\n",
            "53:\tlearn: 0.1333708\ttotal: 357ms\tremaining: 5.6s\n",
            "54:\tlearn: 0.1322505\ttotal: 366ms\tremaining: 5.62s\n",
            "55:\tlearn: 0.1300015\ttotal: 380ms\tremaining: 5.73s\n",
            "56:\tlearn: 0.1265559\ttotal: 385ms\tremaining: 5.7s\n",
            "57:\tlearn: 0.1236480\ttotal: 395ms\tremaining: 5.74s\n",
            "58:\tlearn: 0.1212385\ttotal: 400ms\tremaining: 5.7s\n",
            "59:\tlearn: 0.1203956\ttotal: 408ms\tremaining: 5.71s\n",
            "60:\tlearn: 0.1200061\ttotal: 415ms\tremaining: 5.71s\n",
            "61:\tlearn: 0.1193650\ttotal: 423ms\tremaining: 5.72s\n",
            "62:\tlearn: 0.1166126\ttotal: 431ms\tremaining: 5.73s\n",
            "63:\tlearn: 0.1163347\ttotal: 440ms\tremaining: 5.74s\n",
            "64:\tlearn: 0.1134548\ttotal: 446ms\tremaining: 5.73s\n",
            "65:\tlearn: 0.1098423\ttotal: 454ms\tremaining: 5.74s\n",
            "66:\tlearn: 0.1072239\ttotal: 462ms\tremaining: 5.74s\n",
            "67:\tlearn: 0.1058841\ttotal: 469ms\tremaining: 5.74s\n",
            "68:\tlearn: 0.1027396\ttotal: 484ms\tremaining: 5.83s\n",
            "69:\tlearn: 0.1008186\ttotal: 493ms\tremaining: 5.84s\n",
            "70:\tlearn: 0.0966318\ttotal: 499ms\tremaining: 5.83s\n",
            "71:\tlearn: 0.0949765\ttotal: 503ms\tremaining: 5.78s\n",
            "72:\tlearn: 0.0935742\ttotal: 506ms\tremaining: 5.74s\n",
            "73:\tlearn: 0.0919095\ttotal: 510ms\tremaining: 5.69s\n",
            "74:\tlearn: 0.0909843\ttotal: 515ms\tremaining: 5.66s\n",
            "75:\tlearn: 0.0881875\ttotal: 523ms\tremaining: 5.67s\n",
            "76:\tlearn: 0.0869564\ttotal: 530ms\tremaining: 5.67s\n",
            "77:\tlearn: 0.0852331\ttotal: 538ms\tremaining: 5.66s\n",
            "78:\tlearn: 0.0842871\ttotal: 548ms\tremaining: 5.69s\n",
            "79:\tlearn: 0.0827929\ttotal: 552ms\tremaining: 5.66s\n",
            "80:\tlearn: 0.0811561\ttotal: 560ms\tremaining: 5.67s\n",
            "81:\tlearn: 0.0804719\ttotal: 576ms\tremaining: 5.75s\n",
            "82:\tlearn: 0.0788316\ttotal: 582ms\tremaining: 5.72s\n",
            "83:\tlearn: 0.0783037\ttotal: 590ms\tremaining: 5.73s\n",
            "84:\tlearn: 0.0776352\ttotal: 597ms\tremaining: 5.72s\n",
            "85:\tlearn: 0.0772213\ttotal: 604ms\tremaining: 5.72s\n",
            "86:\tlearn: 0.0768464\ttotal: 614ms\tremaining: 5.73s\n",
            "87:\tlearn: 0.0761345\ttotal: 619ms\tremaining: 5.71s\n",
            "88:\tlearn: 0.0743197\ttotal: 627ms\tremaining: 5.71s\n",
            "89:\tlearn: 0.0732759\ttotal: 635ms\tremaining: 5.71s\n",
            "90:\tlearn: 0.0726576\ttotal: 642ms\tremaining: 5.71s\n",
            "91:\tlearn: 0.0723924\ttotal: 649ms\tremaining: 5.7s\n",
            "92:\tlearn: 0.0721837\ttotal: 657ms\tremaining: 5.7s\n",
            "93:\tlearn: 0.0702339\ttotal: 664ms\tremaining: 5.69s\n",
            "94:\tlearn: 0.0699725\ttotal: 671ms\tremaining: 5.69s\n",
            "95:\tlearn: 0.0689265\ttotal: 681ms\tremaining: 5.7s\n",
            "96:\tlearn: 0.0681891\ttotal: 687ms\tremaining: 5.69s\n",
            "97:\tlearn: 0.0666565\ttotal: 695ms\tremaining: 5.68s\n",
            "98:\tlearn: 0.0652920\ttotal: 703ms\tremaining: 5.68s\n",
            "99:\tlearn: 0.0641169\ttotal: 712ms\tremaining: 5.69s\n",
            "100:\tlearn: 0.0637811\ttotal: 719ms\tremaining: 5.69s\n",
            "101:\tlearn: 0.0630331\ttotal: 726ms\tremaining: 5.68s\n",
            "102:\tlearn: 0.0622182\ttotal: 733ms\tremaining: 5.67s\n",
            "103:\tlearn: 0.0620344\ttotal: 741ms\tremaining: 5.67s\n",
            "104:\tlearn: 0.0612359\ttotal: 749ms\tremaining: 5.67s\n",
            "105:\tlearn: 0.0602492\ttotal: 757ms\tremaining: 5.67s\n",
            "106:\tlearn: 0.0593482\ttotal: 770ms\tremaining: 5.71s\n",
            "107:\tlearn: 0.0591351\ttotal: 778ms\tremaining: 5.7s\n",
            "108:\tlearn: 0.0589508\ttotal: 785ms\tremaining: 5.7s\n",
            "109:\tlearn: 0.0579964\ttotal: 793ms\tremaining: 5.69s\n",
            "110:\tlearn: 0.0572566\ttotal: 800ms\tremaining: 5.69s\n",
            "111:\tlearn: 0.0552835\ttotal: 808ms\tremaining: 5.68s\n",
            "112:\tlearn: 0.0544827\ttotal: 817ms\tremaining: 5.69s\n",
            "113:\tlearn: 0.0536141\ttotal: 823ms\tremaining: 5.67s\n",
            "114:\tlearn: 0.0530864\ttotal: 830ms\tremaining: 5.67s\n",
            "115:\tlearn: 0.0528331\ttotal: 838ms\tremaining: 5.66s\n",
            "116:\tlearn: 0.0523921\ttotal: 848ms\tremaining: 5.68s\n",
            "117:\tlearn: 0.0522484\ttotal: 854ms\tremaining: 5.66s\n",
            "118:\tlearn: 0.0519230\ttotal: 862ms\tremaining: 5.66s\n",
            "119:\tlearn: 0.0507013\ttotal: 867ms\tremaining: 5.63s\n",
            "120:\tlearn: 0.0500983\ttotal: 875ms\tremaining: 5.63s\n",
            "121:\tlearn: 0.0499443\ttotal: 882ms\tremaining: 5.63s\n",
            "122:\tlearn: 0.0496118\ttotal: 890ms\tremaining: 5.62s\n",
            "123:\tlearn: 0.0492756\ttotal: 897ms\tremaining: 5.62s\n",
            "124:\tlearn: 0.0488502\ttotal: 905ms\tremaining: 5.61s\n",
            "125:\tlearn: 0.0483863\ttotal: 912ms\tremaining: 5.6s\n",
            "126:\tlearn: 0.0477111\ttotal: 920ms\tremaining: 5.6s\n",
            "127:\tlearn: 0.0474849\ttotal: 927ms\tremaining: 5.59s\n",
            "128:\tlearn: 0.0473706\ttotal: 936ms\tremaining: 5.6s\n",
            "129:\tlearn: 0.0471153\ttotal: 942ms\tremaining: 5.58s\n",
            "130:\tlearn: 0.0470306\ttotal: 950ms\tremaining: 5.57s\n",
            "131:\tlearn: 0.0456666\ttotal: 964ms\tremaining: 5.61s\n",
            "132:\tlearn: 0.0449083\ttotal: 971ms\tremaining: 5.6s\n",
            "133:\tlearn: 0.0447272\ttotal: 981ms\tremaining: 5.61s\n",
            "134:\tlearn: 0.0444216\ttotal: 987ms\tremaining: 5.59s\n",
            "135:\tlearn: 0.0443332\ttotal: 997ms\tremaining: 5.6s\n",
            "136:\tlearn: 0.0441990\ttotal: 1s\tremaining: 5.59s\n",
            "137:\tlearn: 0.0439356\ttotal: 1.01s\tremaining: 5.59s\n",
            "138:\tlearn: 0.0433469\ttotal: 1.02s\tremaining: 5.58s\n",
            "139:\tlearn: 0.0432075\ttotal: 1.03s\tremaining: 5.58s\n",
            "140:\tlearn: 0.0428877\ttotal: 1.03s\tremaining: 5.57s\n",
            "141:\tlearn: 0.0427283\ttotal: 1.04s\tremaining: 5.57s\n",
            "142:\tlearn: 0.0425699\ttotal: 1.05s\tremaining: 5.56s\n",
            "143:\tlearn: 0.0423939\ttotal: 1.06s\tremaining: 5.56s\n",
            "144:\tlearn: 0.0422300\ttotal: 1.07s\tremaining: 5.55s\n",
            "145:\tlearn: 0.0418116\ttotal: 1.07s\tremaining: 5.55s\n",
            "146:\tlearn: 0.0417368\ttotal: 1.08s\tremaining: 5.54s\n",
            "147:\tlearn: 0.0416856\ttotal: 1.08s\tremaining: 5.51s\n",
            "148:\tlearn: 0.0415529\ttotal: 1.09s\tremaining: 5.49s\n",
            "149:\tlearn: 0.0413168\ttotal: 1.1s\tremaining: 5.48s\n",
            "150:\tlearn: 0.0412417\ttotal: 1.1s\tremaining: 5.47s\n",
            "151:\tlearn: 0.0411926\ttotal: 1.11s\tremaining: 5.47s\n",
            "152:\tlearn: 0.0411118\ttotal: 1.12s\tremaining: 5.46s\n",
            "153:\tlearn: 0.0408675\ttotal: 1.13s\tremaining: 5.46s\n",
            "154:\tlearn: 0.0404667\ttotal: 1.14s\tremaining: 5.46s\n",
            "155:\tlearn: 0.0402651\ttotal: 1.14s\tremaining: 5.45s\n",
            "156:\tlearn: 0.0401983\ttotal: 1.15s\tremaining: 5.46s\n",
            "157:\tlearn: 0.0401117\ttotal: 1.16s\tremaining: 5.45s\n",
            "158:\tlearn: 0.0392286\ttotal: 1.17s\tremaining: 5.45s\n",
            "159:\tlearn: 0.0387906\ttotal: 1.18s\tremaining: 5.45s\n",
            "160:\tlearn: 0.0379117\ttotal: 1.18s\tremaining: 5.42s\n",
            "161:\tlearn: 0.0377855\ttotal: 1.18s\tremaining: 5.4s\n",
            "162:\tlearn: 0.0375467\ttotal: 1.19s\tremaining: 5.37s\n",
            "163:\tlearn: 0.0374212\ttotal: 1.19s\tremaining: 5.35s\n",
            "164:\tlearn: 0.0368815\ttotal: 1.2s\tremaining: 5.33s\n",
            "165:\tlearn: 0.0365389\ttotal: 1.2s\tremaining: 5.3s\n",
            "166:\tlearn: 0.0364743\ttotal: 1.2s\tremaining: 5.28s\n",
            "167:\tlearn: 0.0364181\ttotal: 1.21s\tremaining: 5.25s\n",
            "168:\tlearn: 0.0363886\ttotal: 1.21s\tremaining: 5.23s\n",
            "169:\tlearn: 0.0363099\ttotal: 1.21s\tremaining: 5.21s\n",
            "170:\tlearn: 0.0361215\ttotal: 1.22s\tremaining: 5.2s\n",
            "171:\tlearn: 0.0354146\ttotal: 1.23s\tremaining: 5.18s\n",
            "172:\tlearn: 0.0353821\ttotal: 1.23s\tremaining: 5.19s\n",
            "173:\tlearn: 0.0352517\ttotal: 1.24s\tremaining: 5.17s\n",
            "174:\tlearn: 0.0350202\ttotal: 1.24s\tremaining: 5.14s\n",
            "175:\tlearn: 0.0349052\ttotal: 1.25s\tremaining: 5.12s\n",
            "176:\tlearn: 0.0347061\ttotal: 1.25s\tremaining: 5.12s\n",
            "177:\tlearn: 0.0343487\ttotal: 1.26s\tremaining: 5.11s\n",
            "178:\tlearn: 0.0343250\ttotal: 1.26s\tremaining: 5.09s\n",
            "179:\tlearn: 0.0342358\ttotal: 1.27s\tremaining: 5.07s\n",
            "180:\tlearn: 0.0341543\ttotal: 1.27s\tremaining: 5.05s\n",
            "181:\tlearn: 0.0339820\ttotal: 1.27s\tremaining: 5.03s\n",
            "182:\tlearn: 0.0335674\ttotal: 1.28s\tremaining: 5.01s\n",
            "183:\tlearn: 0.0334803\ttotal: 1.28s\tremaining: 4.98s\n",
            "184:\tlearn: 0.0334492\ttotal: 1.28s\tremaining: 4.96s\n",
            "185:\tlearn: 0.0333884\ttotal: 1.29s\tremaining: 4.94s\n",
            "186:\tlearn: 0.0332935\ttotal: 1.29s\tremaining: 4.94s\n",
            "187:\tlearn: 0.0327432\ttotal: 1.3s\tremaining: 4.92s\n",
            "188:\tlearn: 0.0326466\ttotal: 1.3s\tremaining: 4.9s\n",
            "189:\tlearn: 0.0326254\ttotal: 1.3s\tremaining: 4.88s\n",
            "190:\tlearn: 0.0326014\ttotal: 1.31s\tremaining: 4.86s\n",
            "191:\tlearn: 0.0325587\ttotal: 1.32s\tremaining: 4.85s\n",
            "192:\tlearn: 0.0322931\ttotal: 1.32s\tremaining: 4.83s\n",
            "193:\tlearn: 0.0322632\ttotal: 1.32s\tremaining: 4.82s\n",
            "194:\tlearn: 0.0322436\ttotal: 1.33s\tremaining: 4.8s\n",
            "195:\tlearn: 0.0321035\ttotal: 1.34s\tremaining: 4.8s\n",
            "196:\tlearn: 0.0317909\ttotal: 1.34s\tremaining: 4.78s\n",
            "197:\tlearn: 0.0317257\ttotal: 1.34s\tremaining: 4.76s\n",
            "198:\tlearn: 0.0316993\ttotal: 1.35s\tremaining: 4.74s\n",
            "199:\tlearn: 0.0315731\ttotal: 1.35s\tremaining: 4.72s\n",
            "200:\tlearn: 0.0310575\ttotal: 1.35s\tremaining: 4.7s\n",
            "201:\tlearn: 0.0308901\ttotal: 1.36s\tremaining: 4.69s\n",
            "202:\tlearn: 0.0308419\ttotal: 1.36s\tremaining: 4.67s\n",
            "203:\tlearn: 0.0307982\ttotal: 1.36s\tremaining: 4.65s\n",
            "204:\tlearn: 0.0305735\ttotal: 1.37s\tremaining: 4.63s\n",
            "205:\tlearn: 0.0305342\ttotal: 1.37s\tremaining: 4.61s\n",
            "206:\tlearn: 0.0305119\ttotal: 1.37s\tremaining: 4.6s\n",
            "207:\tlearn: 0.0304721\ttotal: 1.38s\tremaining: 4.58s\n",
            "208:\tlearn: 0.0304249\ttotal: 1.38s\tremaining: 4.57s\n",
            "209:\tlearn: 0.0303826\ttotal: 1.39s\tremaining: 4.55s\n",
            "210:\tlearn: 0.0302909\ttotal: 1.39s\tremaining: 4.54s\n",
            "211:\tlearn: 0.0302773\ttotal: 1.39s\tremaining: 4.52s\n",
            "212:\tlearn: 0.0302406\ttotal: 1.4s\tremaining: 4.5s\n",
            "213:\tlearn: 0.0302028\ttotal: 1.4s\tremaining: 4.48s\n",
            "214:\tlearn: 0.0300367\ttotal: 1.4s\tremaining: 4.47s\n",
            "215:\tlearn: 0.0298968\ttotal: 1.4s\tremaining: 4.45s\n",
            "216:\tlearn: 0.0298724\ttotal: 1.41s\tremaining: 4.43s\n",
            "217:\tlearn: 0.0298109\ttotal: 1.41s\tremaining: 4.41s\n",
            "218:\tlearn: 0.0297058\ttotal: 1.41s\tremaining: 4.4s\n",
            "219:\tlearn: 0.0296884\ttotal: 1.42s\tremaining: 4.38s\n",
            "220:\tlearn: 0.0295689\ttotal: 1.42s\tremaining: 4.36s\n",
            "221:\tlearn: 0.0294334\ttotal: 1.42s\tremaining: 4.34s\n",
            "222:\tlearn: 0.0294000\ttotal: 1.43s\tremaining: 4.33s\n",
            "223:\tlearn: 0.0293690\ttotal: 1.43s\tremaining: 4.31s\n",
            "224:\tlearn: 0.0293324\ttotal: 1.43s\tremaining: 4.3s\n",
            "225:\tlearn: 0.0293142\ttotal: 1.44s\tremaining: 4.28s\n",
            "226:\tlearn: 0.0292905\ttotal: 1.44s\tremaining: 4.26s\n",
            "227:\tlearn: 0.0290381\ttotal: 1.44s\tremaining: 4.25s\n",
            "228:\tlearn: 0.0289647\ttotal: 1.45s\tremaining: 4.24s\n",
            "229:\tlearn: 0.0289467\ttotal: 1.45s\tremaining: 4.22s\n",
            "230:\tlearn: 0.0289297\ttotal: 1.45s\tremaining: 4.21s\n",
            "231:\tlearn: 0.0289194\ttotal: 1.46s\tremaining: 4.19s\n",
            "232:\tlearn: 0.0288422\ttotal: 1.46s\tremaining: 4.17s\n",
            "233:\tlearn: 0.0288051\ttotal: 1.46s\tremaining: 4.16s\n",
            "234:\tlearn: 0.0287027\ttotal: 1.46s\tremaining: 4.14s\n",
            "235:\tlearn: 0.0286180\ttotal: 1.47s\tremaining: 4.13s\n",
            "236:\tlearn: 0.0286109\ttotal: 1.47s\tremaining: 4.12s\n",
            "237:\tlearn: 0.0285854\ttotal: 1.47s\tremaining: 4.1s\n",
            "238:\tlearn: 0.0285767\ttotal: 1.48s\tremaining: 4.09s\n",
            "239:\tlearn: 0.0285051\ttotal: 1.48s\tremaining: 4.08s\n",
            "240:\tlearn: 0.0284787\ttotal: 1.49s\tremaining: 4.07s\n",
            "241:\tlearn: 0.0284614\ttotal: 1.5s\tremaining: 4.07s\n",
            "242:\tlearn: 0.0284561\ttotal: 1.5s\tremaining: 4.06s\n",
            "243:\tlearn: 0.0284080\ttotal: 1.51s\tremaining: 4.07s\n",
            "244:\tlearn: 0.0282788\ttotal: 1.52s\tremaining: 4.05s\n",
            "245:\tlearn: 0.0282582\ttotal: 1.52s\tremaining: 4.04s\n",
            "246:\tlearn: 0.0282470\ttotal: 1.52s\tremaining: 4.03s\n",
            "247:\tlearn: 0.0282237\ttotal: 1.52s\tremaining: 4.01s\n",
            "248:\tlearn: 0.0281791\ttotal: 1.53s\tremaining: 3.99s\n",
            "249:\tlearn: 0.0281530\ttotal: 1.53s\tremaining: 3.98s\n",
            "250:\tlearn: 0.0281238\ttotal: 1.53s\tremaining: 3.97s\n",
            "251:\tlearn: 0.0281068\ttotal: 1.54s\tremaining: 3.96s\n",
            "252:\tlearn: 0.0280971\ttotal: 1.54s\tremaining: 3.94s\n",
            "253:\tlearn: 0.0279852\ttotal: 1.54s\tremaining: 3.93s\n",
            "254:\tlearn: 0.0279647\ttotal: 1.55s\tremaining: 3.92s\n",
            "255:\tlearn: 0.0279469\ttotal: 1.55s\tremaining: 3.9s\n",
            "256:\tlearn: 0.0279248\ttotal: 1.55s\tremaining: 3.89s\n",
            "257:\tlearn: 0.0278371\ttotal: 1.56s\tremaining: 3.88s\n",
            "258:\tlearn: 0.0277810\ttotal: 1.57s\tremaining: 3.89s\n",
            "259:\tlearn: 0.0277655\ttotal: 1.58s\tremaining: 3.89s\n",
            "260:\tlearn: 0.0277499\ttotal: 1.59s\tremaining: 3.88s\n",
            "261:\tlearn: 0.0276632\ttotal: 1.59s\tremaining: 3.88s\n",
            "262:\tlearn: 0.0275996\ttotal: 1.6s\tremaining: 3.88s\n",
            "263:\tlearn: 0.0275782\ttotal: 1.61s\tremaining: 3.88s\n",
            "264:\tlearn: 0.0275554\ttotal: 1.62s\tremaining: 3.88s\n",
            "265:\tlearn: 0.0275409\ttotal: 1.63s\tremaining: 3.88s\n",
            "266:\tlearn: 0.0273625\ttotal: 1.63s\tremaining: 3.88s\n",
            "267:\tlearn: 0.0273188\ttotal: 1.64s\tremaining: 3.87s\n",
            "268:\tlearn: 0.0273126\ttotal: 1.65s\tremaining: 3.87s\n",
            "269:\tlearn: 0.0273037\ttotal: 1.66s\tremaining: 3.87s\n",
            "270:\tlearn: 0.0272943\ttotal: 1.66s\tremaining: 3.85s\n",
            "271:\tlearn: 0.0272603\ttotal: 1.67s\tremaining: 3.85s\n",
            "272:\tlearn: 0.0272547\ttotal: 1.67s\tremaining: 3.84s\n",
            "273:\tlearn: 0.0272315\ttotal: 1.68s\tremaining: 3.84s\n",
            "274:\tlearn: 0.0272201\ttotal: 1.69s\tremaining: 3.83s\n",
            "275:\tlearn: 0.0272040\ttotal: 1.69s\tremaining: 3.83s\n",
            "276:\tlearn: 0.0271960\ttotal: 1.7s\tremaining: 3.83s\n",
            "277:\tlearn: 0.0271685\ttotal: 1.71s\tremaining: 3.83s\n",
            "278:\tlearn: 0.0271597\ttotal: 1.72s\tremaining: 3.82s\n",
            "279:\tlearn: 0.0271499\ttotal: 1.73s\tremaining: 3.82s\n",
            "280:\tlearn: 0.0271403\ttotal: 1.73s\tremaining: 3.82s\n",
            "281:\tlearn: 0.0271222\ttotal: 1.74s\tremaining: 3.81s\n",
            "282:\tlearn: 0.0270957\ttotal: 1.75s\tremaining: 3.81s\n",
            "283:\tlearn: 0.0270788\ttotal: 1.75s\tremaining: 3.8s\n",
            "284:\tlearn: 0.0270283\ttotal: 1.75s\tremaining: 3.79s\n",
            "285:\tlearn: 0.0270089\ttotal: 1.76s\tremaining: 3.77s\n",
            "286:\tlearn: 0.0269847\ttotal: 1.76s\tremaining: 3.76s\n",
            "287:\tlearn: 0.0269698\ttotal: 1.76s\tremaining: 3.75s\n",
            "288:\tlearn: 0.0269569\ttotal: 1.77s\tremaining: 3.74s\n",
            "289:\tlearn: 0.0269434\ttotal: 1.77s\tremaining: 3.72s\n",
            "290:\tlearn: 0.0269003\ttotal: 1.77s\tremaining: 3.71s\n",
            "291:\tlearn: 0.0267859\ttotal: 1.78s\tremaining: 3.71s\n",
            "292:\tlearn: 0.0267780\ttotal: 1.78s\tremaining: 3.69s\n",
            "293:\tlearn: 0.0267703\ttotal: 1.79s\tremaining: 3.68s\n",
            "294:\tlearn: 0.0267467\ttotal: 1.79s\tremaining: 3.67s\n",
            "295:\tlearn: 0.0267345\ttotal: 1.8s\tremaining: 3.67s\n",
            "296:\tlearn: 0.0267129\ttotal: 1.8s\tremaining: 3.66s\n",
            "297:\tlearn: 0.0267070\ttotal: 1.81s\tremaining: 3.66s\n",
            "298:\tlearn: 0.0266998\ttotal: 1.82s\tremaining: 3.66s\n",
            "299:\tlearn: 0.0266901\ttotal: 1.83s\tremaining: 3.65s\n",
            "300:\tlearn: 0.0266822\ttotal: 1.84s\tremaining: 3.66s\n",
            "301:\tlearn: 0.0266622\ttotal: 1.84s\tremaining: 3.65s\n",
            "302:\tlearn: 0.0266463\ttotal: 1.85s\tremaining: 3.64s\n",
            "303:\tlearn: 0.0266377\ttotal: 1.86s\tremaining: 3.64s\n",
            "304:\tlearn: 0.0266240\ttotal: 1.86s\tremaining: 3.63s\n",
            "305:\tlearn: 0.0266137\ttotal: 1.87s\tremaining: 3.63s\n",
            "306:\tlearn: 0.0266083\ttotal: 1.89s\tremaining: 3.64s\n",
            "307:\tlearn: 0.0266028\ttotal: 1.89s\tremaining: 3.64s\n",
            "308:\tlearn: 0.0265929\ttotal: 1.9s\tremaining: 3.63s\n",
            "309:\tlearn: 0.0265860\ttotal: 1.91s\tremaining: 3.63s\n",
            "310:\tlearn: 0.0265774\ttotal: 1.92s\tremaining: 3.63s\n",
            "311:\tlearn: 0.0265498\ttotal: 1.92s\tremaining: 3.62s\n",
            "312:\tlearn: 0.0265049\ttotal: 1.93s\tremaining: 3.62s\n",
            "313:\tlearn: 0.0264973\ttotal: 1.94s\tremaining: 3.62s\n",
            "314:\tlearn: 0.0264903\ttotal: 1.95s\tremaining: 3.61s\n",
            "315:\tlearn: 0.0264647\ttotal: 1.95s\tremaining: 3.61s\n",
            "316:\tlearn: 0.0264616\ttotal: 1.96s\tremaining: 3.61s\n",
            "317:\tlearn: 0.0263788\ttotal: 1.97s\tremaining: 3.6s\n",
            "318:\tlearn: 0.0263738\ttotal: 1.98s\tremaining: 3.6s\n",
            "319:\tlearn: 0.0263546\ttotal: 1.98s\tremaining: 3.6s\n",
            "320:\tlearn: 0.0263455\ttotal: 1.99s\tremaining: 3.6s\n",
            "321:\tlearn: 0.0263429\ttotal: 2s\tremaining: 3.59s\n",
            "322:\tlearn: 0.0263348\ttotal: 2.01s\tremaining: 3.59s\n",
            "323:\tlearn: 0.0263013\ttotal: 2.02s\tremaining: 3.58s\n",
            "324:\tlearn: 0.0262873\ttotal: 2.03s\tremaining: 3.59s\n",
            "325:\tlearn: 0.0262595\ttotal: 2.04s\tremaining: 3.59s\n",
            "326:\tlearn: 0.0262484\ttotal: 2.04s\tremaining: 3.58s\n",
            "327:\tlearn: 0.0262440\ttotal: 2.05s\tremaining: 3.58s\n",
            "328:\tlearn: 0.0262379\ttotal: 2.06s\tremaining: 3.58s\n",
            "329:\tlearn: 0.0262322\ttotal: 2.07s\tremaining: 3.57s\n",
            "330:\tlearn: 0.0262271\ttotal: 2.08s\tremaining: 3.57s\n",
            "331:\tlearn: 0.0261782\ttotal: 2.08s\tremaining: 3.57s\n",
            "332:\tlearn: 0.0261695\ttotal: 2.09s\tremaining: 3.56s\n",
            "333:\tlearn: 0.0261640\ttotal: 2.1s\tremaining: 3.56s\n",
            "334:\tlearn: 0.0261602\ttotal: 2.11s\tremaining: 3.55s\n",
            "335:\tlearn: 0.0261560\ttotal: 2.11s\tremaining: 3.55s\n",
            "336:\tlearn: 0.0261529\ttotal: 2.12s\tremaining: 3.54s\n",
            "337:\tlearn: 0.0261092\ttotal: 2.13s\tremaining: 3.54s\n",
            "338:\tlearn: 0.0261025\ttotal: 2.14s\tremaining: 3.54s\n",
            "339:\tlearn: 0.0260904\ttotal: 2.14s\tremaining: 3.53s\n",
            "340:\tlearn: 0.0260825\ttotal: 2.15s\tremaining: 3.53s\n",
            "341:\tlearn: 0.0260722\ttotal: 2.16s\tremaining: 3.52s\n",
            "342:\tlearn: 0.0260642\ttotal: 2.17s\tremaining: 3.52s\n",
            "343:\tlearn: 0.0260351\ttotal: 2.18s\tremaining: 3.52s\n",
            "344:\tlearn: 0.0260280\ttotal: 2.18s\tremaining: 3.51s\n",
            "345:\tlearn: 0.0260201\ttotal: 2.19s\tremaining: 3.51s\n",
            "346:\tlearn: 0.0260146\ttotal: 2.2s\tremaining: 3.5s\n",
            "347:\tlearn: 0.0259955\ttotal: 2.21s\tremaining: 3.51s\n",
            "348:\tlearn: 0.0259870\ttotal: 2.22s\tremaining: 3.51s\n",
            "349:\tlearn: 0.0259830\ttotal: 2.23s\tremaining: 3.5s\n",
            "350:\tlearn: 0.0259693\ttotal: 2.24s\tremaining: 3.5s\n",
            "351:\tlearn: 0.0259587\ttotal: 2.24s\tremaining: 3.49s\n",
            "352:\tlearn: 0.0259541\ttotal: 2.25s\tremaining: 3.49s\n",
            "353:\tlearn: 0.0259470\ttotal: 2.26s\tremaining: 3.48s\n",
            "354:\tlearn: 0.0259257\ttotal: 2.26s\tremaining: 3.48s\n",
            "355:\tlearn: 0.0259177\ttotal: 2.27s\tremaining: 3.47s\n",
            "356:\tlearn: 0.0259151\ttotal: 2.28s\tremaining: 3.47s\n",
            "357:\tlearn: 0.0259114\ttotal: 2.29s\tremaining: 3.46s\n",
            "358:\tlearn: 0.0259066\ttotal: 2.29s\tremaining: 3.46s\n",
            "359:\tlearn: 0.0258977\ttotal: 2.3s\tremaining: 3.45s\n",
            "360:\tlearn: 0.0258937\ttotal: 2.31s\tremaining: 3.45s\n",
            "361:\tlearn: 0.0258899\ttotal: 2.32s\tremaining: 3.44s\n",
            "362:\tlearn: 0.0258854\ttotal: 2.32s\tremaining: 3.44s\n",
            "363:\tlearn: 0.0258830\ttotal: 2.33s\tremaining: 3.43s\n",
            "364:\tlearn: 0.0258797\ttotal: 2.34s\tremaining: 3.43s\n",
            "365:\tlearn: 0.0258743\ttotal: 2.35s\tremaining: 3.42s\n",
            "366:\tlearn: 0.0258684\ttotal: 2.35s\tremaining: 3.42s\n",
            "367:\tlearn: 0.0258318\ttotal: 2.36s\tremaining: 3.41s\n",
            "368:\tlearn: 0.0258302\ttotal: 2.37s\tremaining: 3.41s\n",
            "369:\tlearn: 0.0258274\ttotal: 2.38s\tremaining: 3.4s\n",
            "370:\tlearn: 0.0258229\ttotal: 2.38s\tremaining: 3.4s\n",
            "371:\tlearn: 0.0258127\ttotal: 2.39s\tremaining: 3.4s\n",
            "372:\tlearn: 0.0258062\ttotal: 2.4s\tremaining: 3.39s\n",
            "373:\tlearn: 0.0257735\ttotal: 2.41s\tremaining: 3.38s\n",
            "374:\tlearn: 0.0257458\ttotal: 2.41s\tremaining: 3.38s\n",
            "375:\tlearn: 0.0257432\ttotal: 2.42s\tremaining: 3.38s\n",
            "376:\tlearn: 0.0257411\ttotal: 2.43s\tremaining: 3.37s\n",
            "377:\tlearn: 0.0257360\ttotal: 2.44s\tremaining: 3.37s\n",
            "378:\tlearn: 0.0257252\ttotal: 2.45s\tremaining: 3.37s\n",
            "379:\tlearn: 0.0257186\ttotal: 2.46s\tremaining: 3.37s\n",
            "380:\tlearn: 0.0257157\ttotal: 2.47s\tremaining: 3.37s\n",
            "381:\tlearn: 0.0257138\ttotal: 2.48s\tremaining: 3.36s\n",
            "382:\tlearn: 0.0257109\ttotal: 2.48s\tremaining: 3.35s\n",
            "383:\tlearn: 0.0256930\ttotal: 2.49s\tremaining: 3.35s\n",
            "384:\tlearn: 0.0256866\ttotal: 2.5s\tremaining: 3.34s\n",
            "385:\tlearn: 0.0256818\ttotal: 2.5s\tremaining: 3.34s\n",
            "386:\tlearn: 0.0256798\ttotal: 2.51s\tremaining: 3.33s\n",
            "387:\tlearn: 0.0256769\ttotal: 2.52s\tremaining: 3.33s\n",
            "388:\tlearn: 0.0256750\ttotal: 2.53s\tremaining: 3.32s\n",
            "389:\tlearn: 0.0256643\ttotal: 2.54s\tremaining: 3.32s\n",
            "390:\tlearn: 0.0256621\ttotal: 2.54s\tremaining: 3.31s\n",
            "391:\tlearn: 0.0256596\ttotal: 2.55s\tremaining: 3.31s\n",
            "392:\tlearn: 0.0256550\ttotal: 2.56s\tremaining: 3.3s\n",
            "393:\tlearn: 0.0256515\ttotal: 2.57s\tremaining: 3.3s\n",
            "394:\tlearn: 0.0256477\ttotal: 2.58s\tremaining: 3.29s\n",
            "395:\tlearn: 0.0256430\ttotal: 2.58s\tremaining: 3.29s\n",
            "396:\tlearn: 0.0256350\ttotal: 2.59s\tremaining: 3.29s\n",
            "397:\tlearn: 0.0256327\ttotal: 2.6s\tremaining: 3.28s\n",
            "398:\tlearn: 0.0256230\ttotal: 2.61s\tremaining: 3.27s\n",
            "399:\tlearn: 0.0256223\ttotal: 2.62s\tremaining: 3.27s\n",
            "400:\tlearn: 0.0256122\ttotal: 2.64s\tremaining: 3.28s\n",
            "401:\tlearn: 0.0256080\ttotal: 2.64s\tremaining: 3.27s\n",
            "402:\tlearn: 0.0256057\ttotal: 2.65s\tremaining: 3.27s\n",
            "403:\tlearn: 0.0256047\ttotal: 2.66s\tremaining: 3.26s\n",
            "404:\tlearn: 0.0256008\ttotal: 2.67s\tremaining: 3.26s\n",
            "405:\tlearn: 0.0255985\ttotal: 2.67s\tremaining: 3.25s\n",
            "406:\tlearn: 0.0255868\ttotal: 2.68s\tremaining: 3.25s\n",
            "407:\tlearn: 0.0255850\ttotal: 2.69s\tremaining: 3.24s\n",
            "408:\tlearn: 0.0255821\ttotal: 2.7s\tremaining: 3.24s\n",
            "409:\tlearn: 0.0255797\ttotal: 2.7s\tremaining: 3.23s\n",
            "410:\tlearn: 0.0255749\ttotal: 2.71s\tremaining: 3.23s\n",
            "411:\tlearn: 0.0255675\ttotal: 2.72s\tremaining: 3.22s\n",
            "412:\tlearn: 0.0255647\ttotal: 2.73s\tremaining: 3.22s\n",
            "413:\tlearn: 0.0255569\ttotal: 2.74s\tremaining: 3.22s\n",
            "414:\tlearn: 0.0255549\ttotal: 2.75s\tremaining: 3.21s\n",
            "415:\tlearn: 0.0255533\ttotal: 2.76s\tremaining: 3.21s\n",
            "416:\tlearn: 0.0255397\ttotal: 2.77s\tremaining: 3.21s\n",
            "417:\tlearn: 0.0255357\ttotal: 2.77s\tremaining: 3.2s\n",
            "418:\tlearn: 0.0255345\ttotal: 2.78s\tremaining: 3.2s\n",
            "419:\tlearn: 0.0255247\ttotal: 2.79s\tremaining: 3.19s\n",
            "420:\tlearn: 0.0255150\ttotal: 2.8s\tremaining: 3.19s\n",
            "421:\tlearn: 0.0255132\ttotal: 2.81s\tremaining: 3.18s\n",
            "422:\tlearn: 0.0255108\ttotal: 2.82s\tremaining: 3.18s\n",
            "423:\tlearn: 0.0255093\ttotal: 2.82s\tremaining: 3.17s\n",
            "424:\tlearn: 0.0255079\ttotal: 2.83s\tremaining: 3.16s\n",
            "425:\tlearn: 0.0255049\ttotal: 2.83s\tremaining: 3.15s\n",
            "426:\tlearn: 0.0255024\ttotal: 2.83s\tremaining: 3.14s\n",
            "427:\tlearn: 0.0254981\ttotal: 2.83s\tremaining: 3.13s\n",
            "428:\tlearn: 0.0254956\ttotal: 2.84s\tremaining: 3.12s\n",
            "429:\tlearn: 0.0254929\ttotal: 2.84s\tremaining: 3.1s\n",
            "430:\tlearn: 0.0254910\ttotal: 2.84s\tremaining: 3.09s\n",
            "431:\tlearn: 0.0254886\ttotal: 2.85s\tremaining: 3.08s\n",
            "432:\tlearn: 0.0254844\ttotal: 2.85s\tremaining: 3.07s\n",
            "433:\tlearn: 0.0254804\ttotal: 2.85s\tremaining: 3.06s\n",
            "434:\tlearn: 0.0254784\ttotal: 2.85s\tremaining: 3.05s\n",
            "435:\tlearn: 0.0254765\ttotal: 2.85s\tremaining: 3.04s\n",
            "436:\tlearn: 0.0254750\ttotal: 2.86s\tremaining: 3.03s\n",
            "437:\tlearn: 0.0254734\ttotal: 2.86s\tremaining: 3.02s\n",
            "438:\tlearn: 0.0254723\ttotal: 2.86s\tremaining: 3.01s\n",
            "439:\tlearn: 0.0254701\ttotal: 2.87s\tremaining: 3s\n",
            "440:\tlearn: 0.0254690\ttotal: 2.87s\tremaining: 2.98s\n",
            "441:\tlearn: 0.0254683\ttotal: 2.87s\tremaining: 2.97s\n",
            "442:\tlearn: 0.0254659\ttotal: 2.87s\tremaining: 2.96s\n",
            "443:\tlearn: 0.0254648\ttotal: 2.88s\tremaining: 2.95s\n",
            "444:\tlearn: 0.0254631\ttotal: 2.88s\tremaining: 2.94s\n",
            "445:\tlearn: 0.0254618\ttotal: 2.88s\tremaining: 2.93s\n",
            "446:\tlearn: 0.0254597\ttotal: 2.88s\tremaining: 2.92s\n",
            "447:\tlearn: 0.0254585\ttotal: 2.88s\tremaining: 2.91s\n",
            "448:\tlearn: 0.0254556\ttotal: 2.89s\tremaining: 2.9s\n",
            "449:\tlearn: 0.0254521\ttotal: 2.89s\tremaining: 2.89s\n",
            "450:\tlearn: 0.0254500\ttotal: 2.89s\tremaining: 2.88s\n",
            "451:\tlearn: 0.0254479\ttotal: 2.89s\tremaining: 2.87s\n",
            "452:\tlearn: 0.0254412\ttotal: 2.9s\tremaining: 2.86s\n",
            "453:\tlearn: 0.0254321\ttotal: 2.9s\tremaining: 2.85s\n",
            "454:\tlearn: 0.0254293\ttotal: 2.9s\tremaining: 2.84s\n",
            "455:\tlearn: 0.0254284\ttotal: 2.9s\tremaining: 2.83s\n",
            "456:\tlearn: 0.0254277\ttotal: 2.91s\tremaining: 2.82s\n",
            "457:\tlearn: 0.0254265\ttotal: 2.91s\tremaining: 2.81s\n",
            "458:\tlearn: 0.0254239\ttotal: 2.91s\tremaining: 2.8s\n",
            "459:\tlearn: 0.0254227\ttotal: 2.91s\tremaining: 2.79s\n",
            "460:\tlearn: 0.0254208\ttotal: 2.92s\tremaining: 2.78s\n",
            "461:\tlearn: 0.0254188\ttotal: 2.92s\tremaining: 2.77s\n",
            "462:\tlearn: 0.0254157\ttotal: 2.92s\tremaining: 2.76s\n",
            "463:\tlearn: 0.0254152\ttotal: 2.92s\tremaining: 2.75s\n",
            "464:\tlearn: 0.0254045\ttotal: 2.93s\tremaining: 2.74s\n",
            "465:\tlearn: 0.0253938\ttotal: 2.93s\tremaining: 2.73s\n",
            "466:\tlearn: 0.0253931\ttotal: 2.93s\tremaining: 2.72s\n",
            "467:\tlearn: 0.0253890\ttotal: 2.93s\tremaining: 2.71s\n",
            "468:\tlearn: 0.0253873\ttotal: 2.94s\tremaining: 2.7s\n",
            "469:\tlearn: 0.0253837\ttotal: 2.94s\tremaining: 2.69s\n",
            "470:\tlearn: 0.0253823\ttotal: 2.94s\tremaining: 2.68s\n",
            "471:\tlearn: 0.0253806\ttotal: 2.94s\tremaining: 2.67s\n",
            "472:\tlearn: 0.0253787\ttotal: 2.95s\tremaining: 2.66s\n",
            "473:\tlearn: 0.0253762\ttotal: 2.95s\tremaining: 2.65s\n",
            "474:\tlearn: 0.0253745\ttotal: 2.95s\tremaining: 2.64s\n",
            "475:\tlearn: 0.0253732\ttotal: 2.95s\tremaining: 2.63s\n",
            "476:\tlearn: 0.0253684\ttotal: 2.96s\tremaining: 2.62s\n",
            "477:\tlearn: 0.0253665\ttotal: 2.96s\tremaining: 2.61s\n",
            "478:\tlearn: 0.0253656\ttotal: 2.96s\tremaining: 2.6s\n",
            "479:\tlearn: 0.0253643\ttotal: 2.96s\tremaining: 2.59s\n",
            "480:\tlearn: 0.0253609\ttotal: 2.97s\tremaining: 2.58s\n",
            "481:\tlearn: 0.0253598\ttotal: 2.97s\tremaining: 2.57s\n",
            "482:\tlearn: 0.0253589\ttotal: 2.97s\tremaining: 2.56s\n",
            "483:\tlearn: 0.0253558\ttotal: 2.97s\tremaining: 2.56s\n",
            "484:\tlearn: 0.0253538\ttotal: 2.98s\tremaining: 2.55s\n",
            "485:\tlearn: 0.0253518\ttotal: 2.98s\tremaining: 2.54s\n",
            "486:\tlearn: 0.0253468\ttotal: 2.98s\tremaining: 2.53s\n",
            "487:\tlearn: 0.0253464\ttotal: 2.98s\tremaining: 2.52s\n",
            "488:\tlearn: 0.0253441\ttotal: 2.99s\tremaining: 2.51s\n",
            "489:\tlearn: 0.0253436\ttotal: 2.99s\tremaining: 2.5s\n",
            "490:\tlearn: 0.0253423\ttotal: 2.99s\tremaining: 2.49s\n",
            "491:\tlearn: 0.0253404\ttotal: 2.99s\tremaining: 2.48s\n",
            "492:\tlearn: 0.0253394\ttotal: 3s\tremaining: 2.47s\n",
            "493:\tlearn: 0.0253375\ttotal: 3s\tremaining: 2.46s\n",
            "494:\tlearn: 0.0253356\ttotal: 3s\tremaining: 2.46s\n",
            "495:\tlearn: 0.0253324\ttotal: 3s\tremaining: 2.45s\n",
            "496:\tlearn: 0.0253312\ttotal: 3s\tremaining: 2.44s\n",
            "497:\tlearn: 0.0253287\ttotal: 3.01s\tremaining: 2.43s\n",
            "498:\tlearn: 0.0253275\ttotal: 3.01s\tremaining: 2.42s\n",
            "499:\tlearn: 0.0253259\ttotal: 3.01s\tremaining: 2.41s\n",
            "500:\tlearn: 0.0253251\ttotal: 3.02s\tremaining: 2.4s\n",
            "501:\tlearn: 0.0253240\ttotal: 3.02s\tremaining: 2.4s\n",
            "502:\tlearn: 0.0253232\ttotal: 3.02s\tremaining: 2.39s\n",
            "503:\tlearn: 0.0253204\ttotal: 3.03s\tremaining: 2.38s\n",
            "504:\tlearn: 0.0253183\ttotal: 3.03s\tremaining: 2.37s\n",
            "505:\tlearn: 0.0253175\ttotal: 3.03s\tremaining: 2.36s\n",
            "506:\tlearn: 0.0253172\ttotal: 3.04s\tremaining: 2.35s\n",
            "507:\tlearn: 0.0253151\ttotal: 3.04s\tremaining: 2.34s\n",
            "508:\tlearn: 0.0253128\ttotal: 3.04s\tremaining: 2.33s\n",
            "509:\tlearn: 0.0253081\ttotal: 3.04s\tremaining: 2.33s\n",
            "510:\tlearn: 0.0253068\ttotal: 3.04s\tremaining: 2.32s\n",
            "511:\tlearn: 0.0253047\ttotal: 3.05s\tremaining: 2.31s\n",
            "512:\tlearn: 0.0253038\ttotal: 3.05s\tremaining: 2.3s\n",
            "513:\tlearn: 0.0253024\ttotal: 3.05s\tremaining: 2.29s\n",
            "514:\tlearn: 0.0253015\ttotal: 3.06s\tremaining: 2.28s\n",
            "515:\tlearn: 0.0253012\ttotal: 3.06s\tremaining: 2.27s\n",
            "516:\tlearn: 0.0252964\ttotal: 3.06s\tremaining: 2.27s\n",
            "517:\tlearn: 0.0252957\ttotal: 3.06s\tremaining: 2.26s\n",
            "518:\tlearn: 0.0252947\ttotal: 3.06s\tremaining: 2.25s\n",
            "519:\tlearn: 0.0252944\ttotal: 3.07s\tremaining: 2.24s\n",
            "520:\tlearn: 0.0252932\ttotal: 3.07s\tremaining: 2.23s\n",
            "521:\tlearn: 0.0252911\ttotal: 3.07s\tremaining: 2.22s\n",
            "522:\tlearn: 0.0252907\ttotal: 3.07s\tremaining: 2.22s\n",
            "523:\tlearn: 0.0252896\ttotal: 3.08s\tremaining: 2.21s\n",
            "524:\tlearn: 0.0252881\ttotal: 3.08s\tremaining: 2.2s\n",
            "525:\tlearn: 0.0252876\ttotal: 3.08s\tremaining: 2.19s\n",
            "526:\tlearn: 0.0252868\ttotal: 3.08s\tremaining: 2.18s\n",
            "527:\tlearn: 0.0252865\ttotal: 3.09s\tremaining: 2.17s\n",
            "528:\tlearn: 0.0252856\ttotal: 3.09s\tremaining: 2.17s\n",
            "529:\tlearn: 0.0252846\ttotal: 3.09s\tremaining: 2.16s\n",
            "530:\tlearn: 0.0252838\ttotal: 3.1s\tremaining: 2.15s\n",
            "531:\tlearn: 0.0252812\ttotal: 3.1s\tremaining: 2.14s\n",
            "532:\tlearn: 0.0252808\ttotal: 3.1s\tremaining: 2.13s\n",
            "533:\tlearn: 0.0252794\ttotal: 3.1s\tremaining: 2.13s\n",
            "534:\tlearn: 0.0252787\ttotal: 3.1s\tremaining: 2.12s\n",
            "535:\tlearn: 0.0252774\ttotal: 3.11s\tremaining: 2.11s\n",
            "536:\tlearn: 0.0252765\ttotal: 3.11s\tremaining: 2.1s\n",
            "537:\tlearn: 0.0252755\ttotal: 3.11s\tremaining: 2.1s\n",
            "538:\tlearn: 0.0252753\ttotal: 3.12s\tremaining: 2.09s\n",
            "539:\tlearn: 0.0252737\ttotal: 3.12s\tremaining: 2.08s\n",
            "540:\tlearn: 0.0252724\ttotal: 3.12s\tremaining: 2.07s\n",
            "541:\tlearn: 0.0252713\ttotal: 3.12s\tremaining: 2.06s\n",
            "542:\tlearn: 0.0252700\ttotal: 3.13s\tremaining: 2.06s\n",
            "543:\tlearn: 0.0252688\ttotal: 3.13s\tremaining: 2.05s\n",
            "544:\tlearn: 0.0252683\ttotal: 3.13s\tremaining: 2.04s\n",
            "545:\tlearn: 0.0252668\ttotal: 3.13s\tremaining: 2.03s\n",
            "546:\tlearn: 0.0252658\ttotal: 3.14s\tremaining: 2.02s\n",
            "547:\tlearn: 0.0252650\ttotal: 3.14s\tremaining: 2.02s\n",
            "548:\tlearn: 0.0252644\ttotal: 3.14s\tremaining: 2.01s\n",
            "549:\tlearn: 0.0252641\ttotal: 3.14s\tremaining: 2s\n",
            "550:\tlearn: 0.0252631\ttotal: 3.15s\tremaining: 1.99s\n",
            "551:\tlearn: 0.0252598\ttotal: 3.15s\tremaining: 1.99s\n",
            "552:\tlearn: 0.0252592\ttotal: 3.15s\tremaining: 1.98s\n",
            "553:\tlearn: 0.0252585\ttotal: 3.15s\tremaining: 1.97s\n",
            "554:\tlearn: 0.0252573\ttotal: 3.16s\tremaining: 1.96s\n",
            "555:\tlearn: 0.0252562\ttotal: 3.16s\tremaining: 1.96s\n",
            "556:\tlearn: 0.0252558\ttotal: 3.17s\tremaining: 1.95s\n",
            "557:\tlearn: 0.0252553\ttotal: 3.18s\tremaining: 1.95s\n",
            "558:\tlearn: 0.0252547\ttotal: 3.18s\tremaining: 1.94s\n",
            "559:\tlearn: 0.0252537\ttotal: 3.19s\tremaining: 1.93s\n",
            "560:\tlearn: 0.0252531\ttotal: 3.19s\tremaining: 1.93s\n",
            "561:\tlearn: 0.0252499\ttotal: 3.19s\tremaining: 1.92s\n",
            "562:\tlearn: 0.0252494\ttotal: 3.19s\tremaining: 1.91s\n",
            "563:\tlearn: 0.0252477\ttotal: 3.19s\tremaining: 1.9s\n",
            "564:\tlearn: 0.0252469\ttotal: 3.2s\tremaining: 1.9s\n",
            "565:\tlearn: 0.0252449\ttotal: 3.2s\tremaining: 1.89s\n",
            "566:\tlearn: 0.0252440\ttotal: 3.2s\tremaining: 1.88s\n",
            "567:\tlearn: 0.0252414\ttotal: 3.21s\tremaining: 1.87s\n",
            "568:\tlearn: 0.0252405\ttotal: 3.21s\tremaining: 1.87s\n",
            "569:\tlearn: 0.0252396\ttotal: 3.21s\tremaining: 1.86s\n",
            "570:\tlearn: 0.0252390\ttotal: 3.22s\tremaining: 1.85s\n",
            "571:\tlearn: 0.0252384\ttotal: 3.22s\tremaining: 1.84s\n",
            "572:\tlearn: 0.0252380\ttotal: 3.22s\tremaining: 1.84s\n",
            "573:\tlearn: 0.0252372\ttotal: 3.22s\tremaining: 1.83s\n",
            "574:\tlearn: 0.0252363\ttotal: 3.23s\tremaining: 1.82s\n",
            "575:\tlearn: 0.0252351\ttotal: 3.23s\tremaining: 1.82s\n",
            "576:\tlearn: 0.0252342\ttotal: 3.23s\tremaining: 1.81s\n",
            "577:\tlearn: 0.0252317\ttotal: 3.23s\tremaining: 1.8s\n",
            "578:\tlearn: 0.0252312\ttotal: 3.24s\tremaining: 1.79s\n",
            "579:\tlearn: 0.0252301\ttotal: 3.24s\tremaining: 1.79s\n",
            "580:\tlearn: 0.0252295\ttotal: 3.24s\tremaining: 1.78s\n",
            "581:\tlearn: 0.0252271\ttotal: 3.24s\tremaining: 1.77s\n",
            "582:\tlearn: 0.0252248\ttotal: 3.25s\tremaining: 1.76s\n",
            "583:\tlearn: 0.0252239\ttotal: 3.25s\tremaining: 1.76s\n",
            "584:\tlearn: 0.0252232\ttotal: 3.25s\tremaining: 1.75s\n",
            "585:\tlearn: 0.0252228\ttotal: 3.25s\tremaining: 1.74s\n",
            "586:\tlearn: 0.0252222\ttotal: 3.26s\tremaining: 1.74s\n",
            "587:\tlearn: 0.0252209\ttotal: 3.26s\tremaining: 1.73s\n",
            "588:\tlearn: 0.0252203\ttotal: 3.26s\tremaining: 1.72s\n",
            "589:\tlearn: 0.0252189\ttotal: 3.27s\tremaining: 1.72s\n",
            "590:\tlearn: 0.0252184\ttotal: 3.27s\tremaining: 1.71s\n",
            "591:\tlearn: 0.0252178\ttotal: 3.27s\tremaining: 1.7s\n",
            "592:\tlearn: 0.0252176\ttotal: 3.27s\tremaining: 1.69s\n",
            "593:\tlearn: 0.0252164\ttotal: 3.27s\tremaining: 1.69s\n",
            "594:\tlearn: 0.0252158\ttotal: 3.28s\tremaining: 1.68s\n",
            "595:\tlearn: 0.0252153\ttotal: 3.28s\tremaining: 1.67s\n",
            "596:\tlearn: 0.0252149\ttotal: 3.28s\tremaining: 1.67s\n",
            "597:\tlearn: 0.0252143\ttotal: 3.29s\tremaining: 1.66s\n",
            "598:\tlearn: 0.0252136\ttotal: 3.29s\tremaining: 1.65s\n",
            "599:\tlearn: 0.0252133\ttotal: 3.29s\tremaining: 1.65s\n",
            "600:\tlearn: 0.0252127\ttotal: 3.29s\tremaining: 1.64s\n",
            "601:\tlearn: 0.0252123\ttotal: 3.3s\tremaining: 1.63s\n",
            "602:\tlearn: 0.0252109\ttotal: 3.3s\tremaining: 1.63s\n",
            "603:\tlearn: 0.0252105\ttotal: 3.3s\tremaining: 1.62s\n",
            "604:\tlearn: 0.0252103\ttotal: 3.3s\tremaining: 1.61s\n",
            "605:\tlearn: 0.0252100\ttotal: 3.31s\tremaining: 1.6s\n",
            "606:\tlearn: 0.0252096\ttotal: 3.31s\tremaining: 1.6s\n",
            "607:\tlearn: 0.0252094\ttotal: 3.31s\tremaining: 1.59s\n",
            "608:\tlearn: 0.0252091\ttotal: 3.31s\tremaining: 1.58s\n",
            "609:\tlearn: 0.0252081\ttotal: 3.32s\tremaining: 1.58s\n",
            "610:\tlearn: 0.0252075\ttotal: 3.32s\tremaining: 1.57s\n",
            "611:\tlearn: 0.0252071\ttotal: 3.32s\tremaining: 1.56s\n",
            "612:\tlearn: 0.0252066\ttotal: 3.32s\tremaining: 1.56s\n",
            "613:\tlearn: 0.0252063\ttotal: 3.33s\tremaining: 1.55s\n",
            "614:\tlearn: 0.0252055\ttotal: 3.33s\tremaining: 1.54s\n",
            "615:\tlearn: 0.0252052\ttotal: 3.33s\tremaining: 1.54s\n",
            "616:\tlearn: 0.0252049\ttotal: 3.33s\tremaining: 1.53s\n",
            "617:\tlearn: 0.0252044\ttotal: 3.34s\tremaining: 1.52s\n",
            "618:\tlearn: 0.0252042\ttotal: 3.34s\tremaining: 1.51s\n",
            "619:\tlearn: 0.0252037\ttotal: 3.34s\tremaining: 1.51s\n",
            "620:\tlearn: 0.0252033\ttotal: 3.34s\tremaining: 1.5s\n",
            "621:\tlearn: 0.0252028\ttotal: 3.35s\tremaining: 1.5s\n",
            "622:\tlearn: 0.0252019\ttotal: 3.35s\tremaining: 1.49s\n",
            "623:\tlearn: 0.0252012\ttotal: 3.35s\tremaining: 1.48s\n",
            "624:\tlearn: 0.0252010\ttotal: 3.35s\tremaining: 1.48s\n",
            "625:\tlearn: 0.0252006\ttotal: 3.36s\tremaining: 1.47s\n",
            "626:\tlearn: 0.0251991\ttotal: 3.36s\tremaining: 1.46s\n",
            "627:\tlearn: 0.0251987\ttotal: 3.36s\tremaining: 1.46s\n",
            "628:\tlearn: 0.0251985\ttotal: 3.36s\tremaining: 1.45s\n",
            "629:\tlearn: 0.0251975\ttotal: 3.37s\tremaining: 1.44s\n",
            "630:\tlearn: 0.0251973\ttotal: 3.37s\tremaining: 1.44s\n",
            "631:\tlearn: 0.0251970\ttotal: 3.37s\tremaining: 1.43s\n",
            "632:\tlearn: 0.0251966\ttotal: 3.38s\tremaining: 1.42s\n",
            "633:\tlearn: 0.0251961\ttotal: 3.38s\tremaining: 1.42s\n",
            "634:\tlearn: 0.0251954\ttotal: 3.38s\tremaining: 1.41s\n",
            "635:\tlearn: 0.0251949\ttotal: 3.38s\tremaining: 1.4s\n",
            "636:\tlearn: 0.0251945\ttotal: 3.38s\tremaining: 1.4s\n",
            "637:\tlearn: 0.0251943\ttotal: 3.39s\tremaining: 1.39s\n",
            "638:\tlearn: 0.0251941\ttotal: 3.39s\tremaining: 1.38s\n",
            "639:\tlearn: 0.0251934\ttotal: 3.4s\tremaining: 1.38s\n",
            "640:\tlearn: 0.0251929\ttotal: 3.4s\tremaining: 1.37s\n",
            "641:\tlearn: 0.0251915\ttotal: 3.4s\tremaining: 1.37s\n",
            "642:\tlearn: 0.0251911\ttotal: 3.4s\tremaining: 1.36s\n",
            "643:\tlearn: 0.0251909\ttotal: 3.41s\tremaining: 1.35s\n",
            "644:\tlearn: 0.0251903\ttotal: 3.41s\tremaining: 1.35s\n",
            "645:\tlearn: 0.0251900\ttotal: 3.41s\tremaining: 1.34s\n",
            "646:\tlearn: 0.0251895\ttotal: 3.41s\tremaining: 1.33s\n",
            "647:\tlearn: 0.0251893\ttotal: 3.42s\tremaining: 1.33s\n",
            "648:\tlearn: 0.0251889\ttotal: 3.42s\tremaining: 1.32s\n",
            "649:\tlearn: 0.0251885\ttotal: 3.42s\tremaining: 1.32s\n",
            "650:\tlearn: 0.0251872\ttotal: 3.42s\tremaining: 1.31s\n",
            "651:\tlearn: 0.0251865\ttotal: 3.43s\tremaining: 1.3s\n",
            "652:\tlearn: 0.0251862\ttotal: 3.43s\tremaining: 1.3s\n",
            "653:\tlearn: 0.0251858\ttotal: 3.43s\tremaining: 1.29s\n",
            "654:\tlearn: 0.0251855\ttotal: 3.43s\tremaining: 1.28s\n",
            "655:\tlearn: 0.0251849\ttotal: 3.44s\tremaining: 1.28s\n",
            "656:\tlearn: 0.0251846\ttotal: 3.44s\tremaining: 1.27s\n",
            "657:\tlearn: 0.0251840\ttotal: 3.44s\tremaining: 1.26s\n",
            "658:\tlearn: 0.0251836\ttotal: 3.44s\tremaining: 1.26s\n",
            "659:\tlearn: 0.0251832\ttotal: 3.45s\tremaining: 1.25s\n",
            "660:\tlearn: 0.0251829\ttotal: 3.45s\tremaining: 1.25s\n",
            "661:\tlearn: 0.0251827\ttotal: 3.45s\tremaining: 1.24s\n",
            "662:\tlearn: 0.0251821\ttotal: 3.45s\tremaining: 1.23s\n",
            "663:\tlearn: 0.0251818\ttotal: 3.46s\tremaining: 1.23s\n",
            "664:\tlearn: 0.0251817\ttotal: 3.46s\tremaining: 1.22s\n",
            "665:\tlearn: 0.0251812\ttotal: 3.46s\tremaining: 1.22s\n",
            "666:\tlearn: 0.0251809\ttotal: 3.46s\tremaining: 1.21s\n",
            "667:\tlearn: 0.0251806\ttotal: 3.47s\tremaining: 1.2s\n",
            "668:\tlearn: 0.0251802\ttotal: 3.47s\tremaining: 1.2s\n",
            "669:\tlearn: 0.0251799\ttotal: 3.47s\tremaining: 1.19s\n",
            "670:\tlearn: 0.0251797\ttotal: 3.47s\tremaining: 1.19s\n",
            "671:\tlearn: 0.0251792\ttotal: 3.48s\tremaining: 1.18s\n",
            "672:\tlearn: 0.0251790\ttotal: 3.48s\tremaining: 1.17s\n",
            "673:\tlearn: 0.0251787\ttotal: 3.48s\tremaining: 1.17s\n",
            "674:\tlearn: 0.0251785\ttotal: 3.48s\tremaining: 1.16s\n",
            "675:\tlearn: 0.0251782\ttotal: 3.49s\tremaining: 1.16s\n",
            "676:\tlearn: 0.0251779\ttotal: 3.49s\tremaining: 1.15s\n",
            "677:\tlearn: 0.0251776\ttotal: 3.49s\tremaining: 1.14s\n",
            "678:\tlearn: 0.0251772\ttotal: 3.49s\tremaining: 1.14s\n",
            "679:\tlearn: 0.0251769\ttotal: 3.5s\tremaining: 1.13s\n",
            "680:\tlearn: 0.0251766\ttotal: 3.5s\tremaining: 1.13s\n",
            "681:\tlearn: 0.0251761\ttotal: 3.5s\tremaining: 1.12s\n",
            "682:\tlearn: 0.0251757\ttotal: 3.5s\tremaining: 1.11s\n",
            "683:\tlearn: 0.0251751\ttotal: 3.5s\tremaining: 1.11s\n",
            "684:\tlearn: 0.0251741\ttotal: 3.51s\tremaining: 1.1s\n",
            "685:\tlearn: 0.0251740\ttotal: 3.51s\tremaining: 1.09s\n",
            "686:\tlearn: 0.0251737\ttotal: 3.51s\tremaining: 1.09s\n",
            "687:\tlearn: 0.0251735\ttotal: 3.52s\tremaining: 1.08s\n",
            "688:\tlearn: 0.0251733\ttotal: 3.52s\tremaining: 1.08s\n",
            "689:\tlearn: 0.0251730\ttotal: 3.52s\tremaining: 1.07s\n",
            "690:\tlearn: 0.0251728\ttotal: 3.52s\tremaining: 1.06s\n",
            "691:\tlearn: 0.0251725\ttotal: 3.52s\tremaining: 1.06s\n",
            "692:\tlearn: 0.0251724\ttotal: 3.53s\tremaining: 1.05s\n",
            "693:\tlearn: 0.0251720\ttotal: 3.53s\tremaining: 1.05s\n",
            "694:\tlearn: 0.0251716\ttotal: 3.53s\tremaining: 1.04s\n",
            "695:\tlearn: 0.0251713\ttotal: 3.53s\tremaining: 1.04s\n",
            "696:\tlearn: 0.0251709\ttotal: 3.54s\tremaining: 1.03s\n",
            "697:\tlearn: 0.0251707\ttotal: 3.54s\tremaining: 1.02s\n",
            "698:\tlearn: 0.0251704\ttotal: 3.54s\tremaining: 1.02s\n",
            "699:\tlearn: 0.0251702\ttotal: 3.54s\tremaining: 1.01s\n",
            "700:\tlearn: 0.0251697\ttotal: 3.55s\tremaining: 1.01s\n",
            "701:\tlearn: 0.0251694\ttotal: 3.55s\tremaining: 1s\n",
            "702:\tlearn: 0.0251692\ttotal: 3.55s\tremaining: 995ms\n",
            "703:\tlearn: 0.0251687\ttotal: 3.55s\tremaining: 990ms\n",
            "704:\tlearn: 0.0251686\ttotal: 3.56s\tremaining: 984ms\n",
            "705:\tlearn: 0.0251685\ttotal: 3.56s\tremaining: 978ms\n",
            "706:\tlearn: 0.0251682\ttotal: 3.56s\tremaining: 973ms\n",
            "707:\tlearn: 0.0251680\ttotal: 3.56s\tremaining: 967ms\n",
            "708:\tlearn: 0.0251679\ttotal: 3.57s\tremaining: 961ms\n",
            "709:\tlearn: 0.0251677\ttotal: 3.57s\tremaining: 955ms\n",
            "710:\tlearn: 0.0251676\ttotal: 3.57s\tremaining: 950ms\n",
            "711:\tlearn: 0.0251670\ttotal: 3.57s\tremaining: 944ms\n",
            "712:\tlearn: 0.0251665\ttotal: 3.58s\tremaining: 938ms\n",
            "713:\tlearn: 0.0251661\ttotal: 3.58s\tremaining: 933ms\n",
            "714:\tlearn: 0.0251658\ttotal: 3.58s\tremaining: 927ms\n",
            "715:\tlearn: 0.0251657\ttotal: 3.59s\tremaining: 922ms\n",
            "716:\tlearn: 0.0251655\ttotal: 3.59s\tremaining: 917ms\n",
            "717:\tlearn: 0.0251653\ttotal: 3.59s\tremaining: 911ms\n",
            "718:\tlearn: 0.0251650\ttotal: 3.6s\tremaining: 905ms\n",
            "719:\tlearn: 0.0251645\ttotal: 3.6s\tremaining: 900ms\n",
            "720:\tlearn: 0.0251644\ttotal: 3.6s\tremaining: 894ms\n",
            "721:\tlearn: 0.0251642\ttotal: 3.6s\tremaining: 888ms\n",
            "722:\tlearn: 0.0251641\ttotal: 3.6s\tremaining: 883ms\n",
            "723:\tlearn: 0.0251638\ttotal: 3.61s\tremaining: 878ms\n",
            "724:\tlearn: 0.0251636\ttotal: 3.61s\tremaining: 872ms\n",
            "725:\tlearn: 0.0251634\ttotal: 3.61s\tremaining: 866ms\n",
            "726:\tlearn: 0.0251633\ttotal: 3.62s\tremaining: 861ms\n",
            "727:\tlearn: 0.0251629\ttotal: 3.62s\tremaining: 855ms\n",
            "728:\tlearn: 0.0251627\ttotal: 3.62s\tremaining: 850ms\n",
            "729:\tlearn: 0.0251626\ttotal: 3.63s\tremaining: 844ms\n",
            "730:\tlearn: 0.0251623\ttotal: 3.63s\tremaining: 839ms\n",
            "731:\tlearn: 0.0251622\ttotal: 3.63s\tremaining: 833ms\n",
            "732:\tlearn: 0.0251621\ttotal: 3.63s\tremaining: 828ms\n",
            "733:\tlearn: 0.0251620\ttotal: 3.63s\tremaining: 822ms\n",
            "734:\tlearn: 0.0251618\ttotal: 3.64s\tremaining: 817ms\n",
            "735:\tlearn: 0.0251616\ttotal: 3.64s\tremaining: 811ms\n",
            "736:\tlearn: 0.0251613\ttotal: 3.64s\tremaining: 806ms\n",
            "737:\tlearn: 0.0251612\ttotal: 3.65s\tremaining: 800ms\n",
            "738:\tlearn: 0.0251611\ttotal: 3.65s\tremaining: 795ms\n",
            "739:\tlearn: 0.0251607\ttotal: 3.65s\tremaining: 789ms\n",
            "740:\tlearn: 0.0251602\ttotal: 3.65s\tremaining: 784ms\n",
            "741:\tlearn: 0.0251601\ttotal: 3.65s\tremaining: 778ms\n",
            "742:\tlearn: 0.0251593\ttotal: 3.66s\tremaining: 773ms\n",
            "743:\tlearn: 0.0251590\ttotal: 3.66s\tremaining: 767ms\n",
            "744:\tlearn: 0.0251589\ttotal: 3.66s\tremaining: 762ms\n",
            "745:\tlearn: 0.0251588\ttotal: 3.66s\tremaining: 757ms\n",
            "746:\tlearn: 0.0251585\ttotal: 3.67s\tremaining: 751ms\n",
            "747:\tlearn: 0.0251583\ttotal: 3.67s\tremaining: 746ms\n",
            "748:\tlearn: 0.0251580\ttotal: 3.67s\tremaining: 740ms\n",
            "749:\tlearn: 0.0251579\ttotal: 3.67s\tremaining: 735ms\n",
            "750:\tlearn: 0.0251577\ttotal: 3.68s\tremaining: 730ms\n",
            "751:\tlearn: 0.0251576\ttotal: 3.68s\tremaining: 724ms\n",
            "752:\tlearn: 0.0251575\ttotal: 3.68s\tremaining: 719ms\n",
            "753:\tlearn: 0.0251573\ttotal: 3.68s\tremaining: 713ms\n",
            "754:\tlearn: 0.0251571\ttotal: 3.69s\tremaining: 708ms\n",
            "755:\tlearn: 0.0251570\ttotal: 3.69s\tremaining: 703ms\n",
            "756:\tlearn: 0.0251569\ttotal: 3.69s\tremaining: 697ms\n",
            "757:\tlearn: 0.0251568\ttotal: 3.69s\tremaining: 692ms\n",
            "758:\tlearn: 0.0251560\ttotal: 3.7s\tremaining: 687ms\n",
            "759:\tlearn: 0.0251559\ttotal: 3.7s\tremaining: 681ms\n",
            "760:\tlearn: 0.0251555\ttotal: 3.7s\tremaining: 676ms\n",
            "761:\tlearn: 0.0251553\ttotal: 3.7s\tremaining: 671ms\n",
            "762:\tlearn: 0.0251551\ttotal: 3.71s\tremaining: 666ms\n",
            "763:\tlearn: 0.0251551\ttotal: 3.71s\tremaining: 660ms\n",
            "764:\tlearn: 0.0251548\ttotal: 3.71s\tremaining: 655ms\n",
            "765:\tlearn: 0.0251547\ttotal: 3.71s\tremaining: 650ms\n",
            "766:\tlearn: 0.0251542\ttotal: 3.72s\tremaining: 645ms\n",
            "767:\tlearn: 0.0251538\ttotal: 3.72s\tremaining: 639ms\n",
            "768:\tlearn: 0.0251537\ttotal: 3.72s\tremaining: 634ms\n",
            "769:\tlearn: 0.0251529\ttotal: 3.72s\tremaining: 629ms\n",
            "770:\tlearn: 0.0251528\ttotal: 3.73s\tremaining: 624ms\n",
            "771:\tlearn: 0.0251524\ttotal: 3.73s\tremaining: 618ms\n",
            "772:\tlearn: 0.0251523\ttotal: 3.73s\tremaining: 613ms\n",
            "773:\tlearn: 0.0251522\ttotal: 3.73s\tremaining: 608ms\n",
            "774:\tlearn: 0.0251520\ttotal: 3.74s\tremaining: 603ms\n",
            "775:\tlearn: 0.0251517\ttotal: 3.74s\tremaining: 598ms\n",
            "776:\tlearn: 0.0251515\ttotal: 3.74s\tremaining: 592ms\n",
            "777:\tlearn: 0.0251514\ttotal: 3.74s\tremaining: 587ms\n",
            "778:\tlearn: 0.0251512\ttotal: 3.75s\tremaining: 582ms\n",
            "779:\tlearn: 0.0251512\ttotal: 3.75s\tremaining: 577ms\n",
            "780:\tlearn: 0.0251511\ttotal: 3.75s\tremaining: 572ms\n",
            "781:\tlearn: 0.0251511\ttotal: 3.75s\tremaining: 567ms\n",
            "782:\tlearn: 0.0251506\ttotal: 3.76s\tremaining: 561ms\n",
            "783:\tlearn: 0.0251503\ttotal: 3.76s\tremaining: 556ms\n",
            "784:\tlearn: 0.0251501\ttotal: 3.76s\tremaining: 551ms\n",
            "785:\tlearn: 0.0251500\ttotal: 3.76s\tremaining: 546ms\n",
            "786:\tlearn: 0.0251497\ttotal: 3.77s\tremaining: 541ms\n",
            "787:\tlearn: 0.0251495\ttotal: 3.77s\tremaining: 536ms\n",
            "788:\tlearn: 0.0251494\ttotal: 3.78s\tremaining: 531ms\n",
            "789:\tlearn: 0.0251493\ttotal: 3.78s\tremaining: 526ms\n",
            "790:\tlearn: 0.0251491\ttotal: 3.78s\tremaining: 521ms\n",
            "791:\tlearn: 0.0251488\ttotal: 3.78s\tremaining: 516ms\n",
            "792:\tlearn: 0.0251486\ttotal: 3.79s\tremaining: 511ms\n",
            "793:\tlearn: 0.0251484\ttotal: 3.79s\tremaining: 506ms\n",
            "794:\tlearn: 0.0251482\ttotal: 3.79s\tremaining: 501ms\n",
            "795:\tlearn: 0.0251479\ttotal: 3.79s\tremaining: 496ms\n",
            "796:\tlearn: 0.0251477\ttotal: 3.8s\tremaining: 491ms\n",
            "797:\tlearn: 0.0251475\ttotal: 3.8s\tremaining: 486ms\n",
            "798:\tlearn: 0.0251474\ttotal: 3.8s\tremaining: 480ms\n",
            "799:\tlearn: 0.0251471\ttotal: 3.8s\tremaining: 476ms\n",
            "800:\tlearn: 0.0251469\ttotal: 3.81s\tremaining: 470ms\n",
            "801:\tlearn: 0.0251468\ttotal: 3.81s\tremaining: 465ms\n",
            "802:\tlearn: 0.0251467\ttotal: 3.81s\tremaining: 460ms\n",
            "803:\tlearn: 0.0251465\ttotal: 3.81s\tremaining: 455ms\n",
            "804:\tlearn: 0.0251464\ttotal: 3.82s\tremaining: 450ms\n",
            "805:\tlearn: 0.0251462\ttotal: 3.82s\tremaining: 445ms\n",
            "806:\tlearn: 0.0251461\ttotal: 3.82s\tremaining: 440ms\n",
            "807:\tlearn: 0.0251461\ttotal: 3.82s\tremaining: 435ms\n",
            "808:\tlearn: 0.0251460\ttotal: 3.83s\tremaining: 430ms\n",
            "809:\tlearn: 0.0251457\ttotal: 3.83s\tremaining: 425ms\n",
            "810:\tlearn: 0.0251457\ttotal: 3.83s\tremaining: 421ms\n",
            "811:\tlearn: 0.0251455\ttotal: 3.83s\tremaining: 416ms\n",
            "812:\tlearn: 0.0251452\ttotal: 3.84s\tremaining: 411ms\n",
            "813:\tlearn: 0.0251451\ttotal: 3.84s\tremaining: 406ms\n",
            "814:\tlearn: 0.0251446\ttotal: 3.84s\tremaining: 401ms\n",
            "815:\tlearn: 0.0251443\ttotal: 3.84s\tremaining: 396ms\n",
            "816:\tlearn: 0.0251442\ttotal: 3.85s\tremaining: 391ms\n",
            "817:\tlearn: 0.0251441\ttotal: 3.85s\tremaining: 386ms\n",
            "818:\tlearn: 0.0251439\ttotal: 3.85s\tremaining: 381ms\n",
            "819:\tlearn: 0.0251437\ttotal: 3.85s\tremaining: 376ms\n",
            "820:\tlearn: 0.0251433\ttotal: 3.86s\tremaining: 371ms\n",
            "821:\tlearn: 0.0251433\ttotal: 3.86s\tremaining: 366ms\n",
            "822:\tlearn: 0.0251431\ttotal: 3.86s\tremaining: 361ms\n",
            "823:\tlearn: 0.0251430\ttotal: 3.86s\tremaining: 356ms\n",
            "824:\tlearn: 0.0251427\ttotal: 3.87s\tremaining: 352ms\n",
            "825:\tlearn: 0.0251425\ttotal: 3.87s\tremaining: 347ms\n",
            "826:\tlearn: 0.0251423\ttotal: 3.87s\tremaining: 342ms\n",
            "827:\tlearn: 0.0251422\ttotal: 3.87s\tremaining: 337ms\n",
            "828:\tlearn: 0.0251421\ttotal: 3.88s\tremaining: 332ms\n",
            "829:\tlearn: 0.0251420\ttotal: 3.88s\tremaining: 327ms\n",
            "830:\tlearn: 0.0251419\ttotal: 3.88s\tremaining: 322ms\n",
            "831:\tlearn: 0.0251418\ttotal: 3.88s\tremaining: 318ms\n",
            "832:\tlearn: 0.0251417\ttotal: 3.89s\tremaining: 313ms\n",
            "833:\tlearn: 0.0251416\ttotal: 3.9s\tremaining: 308ms\n",
            "834:\tlearn: 0.0251416\ttotal: 3.9s\tremaining: 304ms\n",
            "835:\tlearn: 0.0251414\ttotal: 3.9s\tremaining: 299ms\n",
            "836:\tlearn: 0.0251413\ttotal: 3.91s\tremaining: 294ms\n",
            "837:\tlearn: 0.0251411\ttotal: 3.91s\tremaining: 289ms\n",
            "838:\tlearn: 0.0251410\ttotal: 3.91s\tremaining: 284ms\n",
            "839:\tlearn: 0.0251409\ttotal: 3.91s\tremaining: 280ms\n",
            "840:\tlearn: 0.0251408\ttotal: 3.92s\tremaining: 275ms\n",
            "841:\tlearn: 0.0251407\ttotal: 3.92s\tremaining: 270ms\n",
            "842:\tlearn: 0.0251405\ttotal: 3.92s\tremaining: 265ms\n",
            "843:\tlearn: 0.0251405\ttotal: 3.92s\tremaining: 260ms\n",
            "844:\tlearn: 0.0251404\ttotal: 3.92s\tremaining: 256ms\n",
            "845:\tlearn: 0.0251402\ttotal: 3.93s\tremaining: 251ms\n",
            "846:\tlearn: 0.0251400\ttotal: 3.93s\tremaining: 246ms\n",
            "847:\tlearn: 0.0251398\ttotal: 3.93s\tremaining: 241ms\n",
            "848:\tlearn: 0.0251396\ttotal: 3.94s\tremaining: 236ms\n",
            "849:\tlearn: 0.0251394\ttotal: 3.94s\tremaining: 232ms\n",
            "850:\tlearn: 0.0251393\ttotal: 3.94s\tremaining: 227ms\n",
            "851:\tlearn: 0.0251392\ttotal: 3.94s\tremaining: 222ms\n",
            "852:\tlearn: 0.0251391\ttotal: 3.95s\tremaining: 217ms\n",
            "853:\tlearn: 0.0251390\ttotal: 3.95s\tremaining: 213ms\n",
            "854:\tlearn: 0.0251389\ttotal: 3.95s\tremaining: 208ms\n",
            "855:\tlearn: 0.0251389\ttotal: 3.95s\tremaining: 203ms\n",
            "856:\tlearn: 0.0251387\ttotal: 3.96s\tremaining: 199ms\n",
            "857:\tlearn: 0.0251386\ttotal: 3.96s\tremaining: 194ms\n",
            "858:\tlearn: 0.0251385\ttotal: 3.97s\tremaining: 189ms\n",
            "859:\tlearn: 0.0251384\ttotal: 3.97s\tremaining: 185ms\n",
            "860:\tlearn: 0.0251382\ttotal: 3.97s\tremaining: 180ms\n",
            "861:\tlearn: 0.0251382\ttotal: 3.97s\tremaining: 175ms\n",
            "862:\tlearn: 0.0251381\ttotal: 3.98s\tremaining: 171ms\n",
            "863:\tlearn: 0.0251381\ttotal: 3.98s\tremaining: 166ms\n",
            "864:\tlearn: 0.0251379\ttotal: 3.98s\tremaining: 161ms\n",
            "865:\tlearn: 0.0251378\ttotal: 3.98s\tremaining: 156ms\n",
            "866:\tlearn: 0.0251377\ttotal: 3.99s\tremaining: 152ms\n",
            "867:\tlearn: 0.0251376\ttotal: 3.99s\tremaining: 147ms\n",
            "868:\tlearn: 0.0251375\ttotal: 3.99s\tremaining: 142ms\n",
            "869:\tlearn: 0.0251375\ttotal: 4s\tremaining: 138ms\n",
            "870:\tlearn: 0.0251374\ttotal: 4s\tremaining: 133ms\n",
            "871:\tlearn: 0.0251373\ttotal: 4s\tremaining: 128ms\n",
            "872:\tlearn: 0.0251373\ttotal: 4s\tremaining: 124ms\n",
            "873:\tlearn: 0.0251371\ttotal: 4s\tremaining: 119ms\n",
            "874:\tlearn: 0.0251370\ttotal: 4.01s\tremaining: 115ms\n",
            "875:\tlearn: 0.0251369\ttotal: 4.01s\tremaining: 110ms\n",
            "876:\tlearn: 0.0251368\ttotal: 4.01s\tremaining: 105ms\n",
            "877:\tlearn: 0.0251367\ttotal: 4.01s\tremaining: 101ms\n",
            "878:\tlearn: 0.0251366\ttotal: 4.02s\tremaining: 96ms\n",
            "879:\tlearn: 0.0251363\ttotal: 4.02s\tremaining: 91.4ms\n",
            "880:\tlearn: 0.0251363\ttotal: 4.02s\tremaining: 86.8ms\n",
            "881:\tlearn: 0.0251362\ttotal: 4.03s\tremaining: 82.2ms\n",
            "882:\tlearn: 0.0251362\ttotal: 4.03s\tremaining: 77.6ms\n",
            "883:\tlearn: 0.0251361\ttotal: 4.03s\tremaining: 73ms\n",
            "884:\tlearn: 0.0251359\ttotal: 4.03s\tremaining: 68.4ms\n",
            "885:\tlearn: 0.0251359\ttotal: 4.04s\tremaining: 63.8ms\n",
            "886:\tlearn: 0.0251357\ttotal: 4.04s\tremaining: 59.2ms\n",
            "887:\tlearn: 0.0251357\ttotal: 4.04s\tremaining: 54.7ms\n",
            "888:\tlearn: 0.0251356\ttotal: 4.05s\tremaining: 50.1ms\n",
            "889:\tlearn: 0.0251355\ttotal: 4.05s\tremaining: 45.5ms\n",
            "890:\tlearn: 0.0251355\ttotal: 4.05s\tremaining: 40.9ms\n",
            "891:\tlearn: 0.0251354\ttotal: 4.05s\tremaining: 36.4ms\n",
            "892:\tlearn: 0.0251353\ttotal: 4.06s\tremaining: 31.8ms\n",
            "893:\tlearn: 0.0251353\ttotal: 4.06s\tremaining: 27.2ms\n",
            "894:\tlearn: 0.0251351\ttotal: 4.06s\tremaining: 22.7ms\n",
            "895:\tlearn: 0.0251351\ttotal: 4.07s\tremaining: 18.1ms\n",
            "896:\tlearn: 0.0251348\ttotal: 4.07s\tremaining: 13.6ms\n",
            "897:\tlearn: 0.0251347\ttotal: 4.07s\tremaining: 9.06ms\n",
            "898:\tlearn: 0.0251346\ttotal: 4.07s\tremaining: 4.53ms\n",
            "899:\tlearn: 0.0251345\ttotal: 4.08s\tremaining: 0us\n",
            "Mean Absolute Error: 1.2620895066796338\n",
            "Mean Squared Error: 3.5009980153707265\n",
            "R2 Score: -1.8537017850004363\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. 시각화\n",
        "\n",
        "Voting rehressor의 결과를 시각화하여 모델 성능을 평가 하였다."
      ],
      "metadata": {
        "id": "luZnMlxWtfig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 시각화(잔차 플롯, 산점도)\n",
        "# 잔차 플롯을 위한 잔차 계산(예측값-실제값)\n",
        "y_test_fit = np.array(y_test).flatten()\n",
        "pred_fit = np.array(pred).flatten()\n",
        "residuals = y_test_fit - pred_fit\n",
        "\n",
        "# 잔차 플롯 그리기\n",
        "plt.scatter(pred_fit, residuals)\n",
        "plt.axhline(y=-3, color='r', linestyle='--') # 잔차가 -3인 수평선 추가\n",
        "plt.xlabel('Predicted Values')\n",
        "plt.ylabel('Residuals')\n",
        "plt.title('Residual Plot')\n",
        "plt.show()\n",
        "\n",
        "# 산점도 그리기\n",
        "plt.scatter(y_test_fit, pred_fit)\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.title('Scatter Plot')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Y5JMfdgY4AOw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        },
        "outputId": "26accc3e-5889-477f-879e-02f74a3c1e43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjUAAAHHCAYAAABHp6kXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABFAUlEQVR4nO3deXyM5/7/8fckkU0WQkJoROzSWIpyokUUtR2tOo5ulBZt9TiWLqfxPW3RLfR0Pactjp6i9JwutGqr0qqtKG2kai1pLK0gaLOITMjcvz/8DCGJyWSSydx5PR+PeTwy91z3NZ87NzPvXPd137fFMAxDAAAAHs7L3QUAAAC4AqEGAACYAqEGAACYAqEGAACYAqEGAACYAqEGAACYAqEGAACYAqEGAACYAqEGAACYAqEGQIWaMmWKLBaLQ20tFoumTJlSrvUkJCQoISGh0vYHwHGEGqCKmjt3riwWi/3h4+Oj+vXra8SIEfr111/dXV6l07Bhw0K/r4iICHXp0kWffvqpS/rPzc3VlClTtHbtWpf0B1RFhBqginv22Wc1f/58zZw5U3379tWCBQvUrVs35eXllcv7PfXUUzp79my59F3e2rZtq/nz52v+/Pl6/PHHdfToUQ0aNEgzZ84sc9+5ubmaOnUqoQYoAx93FwDAvfr27asOHTpIkkaNGqXatWtr+vTpWrJkiYYMGeLy9/Px8ZGPj2d+9NSvX19Dhw61P7/vvvvUpEkTvfbaa3r44YfdWBkAiZEaAFfo0qWLJCk1NbXQ8r1792rw4MEKCwuTv7+/OnTooCVLlhRqc+7cOU2dOlVNmzaVv7+/atWqpZtvvlmrV6+2tylqTo3VatXEiRMVHh6u4OBg3Xbbbfrll1+uqm3EiBFq2LDhVcuL6nPOnDm65ZZbFBERIT8/P8XGxmrGjBml+l1cS926ddWyZUulpaWV2O7EiRMaOXKk6tSpI39/f7Vp00bz5s2zv37w4EGFh4dLkqZOnWo/xFXe84kAs/HMP5cAlJuDBw9KkmrWrGlftmvXLt10002qX7++EhMTVb16dX300UcaOHCgFi1apDvuuEPShXCRlJSkUaNGqWPHjsrKytJ3332n5ORk9erVq9j3HDVqlBYsWKB77rlHnTt31po1a9S/f/8ybceMGTN0/fXX67bbbpOPj4+WLl2qRx55RDabTX/5y1/K1PdF586d05EjR1SrVq1i25w9e1YJCQk6cOCAxo4dq5iYGH388ccaMWKEfv/9d40fP17h4eGaMWOGxowZozvuuEODBg2SJLVu3doldQJVhgGgSpozZ44hyfjyyy+NjIwM48iRI8bChQuN8PBww8/Pzzhy5Ii9bY8ePYxWrVoZeXl59mU2m83o3Lmz0bRpU/uyNm3aGP379y/xfSdPnmxc/tGTkpJiSDIeeeSRQu3uueceQ5IxefJk+7Lhw4cb0dHR1+zTMAwjNzf3qna9e/c2GjVqVGhZt27djG7dupVYs2EYRnR0tHHrrbcaGRkZRkZGhvHDDz8Yd911lyHJ+Otf/1psf6+//rohyViwYIF9WX5+vhEfH28EBQUZWVlZhmEYRkZGxlXbC6B0OPwEVHE9e/ZUeHi4oqKiNHjwYFWvXl1LlizRddddJ0k6ffq01qxZoyFDhig7O1snT57UyZMnderUKfXu3Vv79++3ny1Vo0YN7dq1S/v373f4/VesWCFJGjduXKHlEyZMKNN2BQQE2H/OzMzUyZMn1a1bN/3888/KzMx0qs9Vq1YpPDxc4eHhatOmjT7++GMNGzZM06dPL3adFStWqG7durr77rvty6pVq6Zx48YpJydH69atc6oWAFfj8BNQxb311ltq1qyZMjMz9e6772r9+vXy8/Ozv37gwAEZhqGnn35aTz/9dJF9nDhxQvXr19ezzz6r22+/Xc2aNVNcXJz69OmjYcOGlXgY5dChQ/Ly8lLjxo0LLW/evHmZtuubb77R5MmTtXnzZuXm5hZ6LTMzU6GhoaXus1OnTnr++edlsVgUGBioli1bqkaNGiWuc+jQITVt2lReXoX/hmzZsqX9dQCuQagBqriOHTvaz34aOHCgbr75Zt1zzz3at2+fgoKCZLPZJEmPP/64evfuXWQfTZo0kSR17dpVqamp+uyzz7Rq1Sq98847eu211zRz5kyNGjWqzLUWd9G+goKCQs9TU1PVo0cPtWjRQq+++qqioqLk6+urFStW6LXXXrNvU2nVrl1bPXv2dGpdAOWPUAPAztvbW0lJSerevbvefPNNJSYmqlGjRpIuHDJx5As9LCxM999/v+6//37l5OSoa9eumjJlSrGhJjo6WjabTampqYVGZ/bt23dV25o1a+r333+/avmVox1Lly6V1WrVkiVL1KBBA/vyr7/++pr1u1p0dLR27Nghm81WaLRm79699tel4gMbAMcxpwZAIQkJCerYsaNef/115eXlKSIiQgkJCZo1a5bS09Ovap+RkWH/+dSpU4VeCwoKUpMmTWS1Wot9v759+0qS/vnPfxZa/vrrr1/VtnHjxsrMzNSOHTvsy9LT06+6qq+3t7ckyTAM+7LMzEzNmTOn2DrKS79+/XTs2DF9+OGH9mXnz5/Xv/71LwUFBalbt26SpMDAQEkqMrQBcAwjNQCu8sQTT+jPf/6z5s6dq4cfflhvvfWWbr75ZrVq1UqjR49Wo0aNdPz4cW3evFm//PKLfvjhB0lSbGysEhIS1L59e4WFhem7777TwoULNXbs2GLfq23btrr77rv19ttvKzMzU507d9ZXX32lAwcOXNX2rrvu0pNPPqk77rhD48aNU25urmbMmKFmzZopOTnZ3u7WW2+Vr6+vBgwYoIceekg5OTmaPXu2IiIiigxm5enBBx/UrFmzNGLECH3//fdq2LChFi5cqG+++Uavv/66goODJV2Y2BwbG6sPP/xQzZo1U1hYmOLi4hQXF1eh9QIezd2nXwFwj4undG/btu2q1woKCozGjRsbjRs3Ns6fP28YhmGkpqYa9913n1G3bl2jWrVqRv369Y0//vGPxsKFC+3rPf/880bHjh2NGjVqGAEBAUaLFi2MF154wcjPz7e3Ker067Nnzxrjxo0zatWqZVSvXt0YMGCAceTIkSJPcV61apURFxdn+Pr6Gs2bNzcWLFhQZJ9LliwxWrdubfj7+xsNGzY0pk+fbrz77ruGJCMtLc3erjSndF/rdPXi+jt+/Lhx//33G7Vr1zZ8fX2NVq1aGXPmzLlq3U2bNhnt27c3fH19Ob0bcILFMC4bnwUAAPBQzKkBAACmQKgBAACmQKgBAACmQKgBAACmQKgBAACmQKgBAACmUKUuvmez2XT06FEFBwdzSXIAADyEYRjKzs5WvXr1rro57OWqVKg5evSooqKi3F0GAABwwpEjR3TdddcV+3qVCjUXL0d+5MgRhYSEuLkaAADgiKysLEVFRdm/x4tTpULNxUNOISEhhBoAADzMtaaOMFEYAACYAqEGAACYAqEGAACYAqEGAACYAqEGAACYAqEGAACYAqEGAACYAqEGAACYAqEGAACYQpW6onB5yD9v0/zNB3XodK6iwwI1LL6hfH3IigAAVDRCTRkkrdit2RvSZDMuLXt++R71bx2pN+66Qd5e3AkcAICKwpCCk5JW7Nas9YUDjSQZkpbtSFerKV9o5c50t9QGAEBVRKhxQv55m2ZvSCuxTW5+gR5ekEywAQCgghBqnDB/88GrRmiKM3XpbhU42hgAADiNUOOEQ6dzHW6bnpmnrWmny7EaAAAgEWqcEh0WWKr2J7LzyqkSAABwkUeFmvXr12vAgAGqV6+eLBaLFi9e7JY6hsU3VGlObIoI9i+/YgAAgCQPCzVnzpxRmzZt9NZbb7m1Dl8fL43uEnPNdhZJkaH+6hgTVv5FAQBQxXnUdWr69u2rvn37ursMSdKkfrGSpH9vSJNRxDzgiwM5kwfEcr0aAAAqgEeN1JSW1WpVVlZWoYcrTeoXq33P9dXgdvUVWM270Gt1Q/01Y2g79YmLdOl7AgCAonnUSE1pJSUlaerUqeX6Hr4+Xnp5SFtNH2xoa9ppncjOU0TwhUNOjNAAAFBxLIZR1MGTys9isejTTz/VwIEDi21jtVpltVrtz7OyshQVFaXMzEyFhIRUQJUAAKCssrKyFBoaes3vb1OP1Pj5+cnPz8/dZQAAgApg6jk1AACg6vCokZqcnBwdOHDA/jwtLU0pKSkKCwtTgwYN3FgZAABwN48KNd999526d+9uf/7oo49KkoYPH665c+e6qSoAAFAZeFSoSUhIkIfOawYAAOWMOTUAAMAUCDUAAMAUCDUAAMAUCDUAAMAUCDUAAMAUCDUAAMAUCDUAAMAUCDUAAMAUCDUAAMAUCDUAAMAUCDUAAMAUCDUAAMAUCDUAAMAUCDUAAMAUCDUAAMAUCDUAAMAUCDUAAMAUCDUAAMAUCDUAAMAUCDUAAMAUCDUAAMAUCDUAAMAUCDUAAMAUCDUAAMAUCDUAAMAUCDUAAMAUCDUAAMAUfNxdAADzK7AZ2pp2Wiey8xQR7K+OMWHy9rK4uywAJkOoAVCuVu5M19Slu5WemWdf5udj0R9bRyppUBv5+jBgDMA1+DQBUG5W7kzXmAXJhQKNJFnPG1qUfFTNnvpcY/+brAKb4aYKAZgJoQZAuSiwGZq6dLeuFVeW7UhX7DMrtWLH0QqpC4B5EWoAlIutaaevGqEpjvW8TY/8d7uSVuwu56oAmBmhBkC5OJHtWKC53Kz1aVqxI70cqgFQFRBqAJSLiGB/p9Z7+rOdzLEB4BRCDYBy0TEmTGHVq5V6vVNn8rU17XQ5VATA7Ag1AMqFt5dFz98e59S6zhy6AgBCDYBy0691PT3UNabU6zl76ApA1UaoAVCuJvWL1dv3tJO/gxfZiwy9cMVhACgtQg2ActevdaR2PdtH8+/vqCbh1YttZ5E0eUAst1AA4BRukwCgQnh7WdSlebi+bJ6gFTvS9dRnO3X6TL799chQf00eEKs+cZGl7pt7SwGQCDUA3KBf60j1jqvrkiBS1L2lyhKQAHgui2EYVeaCEFlZWQoNDVVmZqZCQkLcXQ6AMrp4b6krP8QuRqMZQ9sRbAATcPT7mzk1ADxSSfeWurhs6tLdXMgPqEI4/ATAI13r3lKGpPTMPI2euVJrDtsKvbbt/3oqPMSvnCsEUNE8bqTmrbfeUsOGDeXv769OnTpp69at7i4JgBs4eoG+KwONJN344pdqmLhcd7683NVlAXAjjwo1H374oR599FFNnjxZycnJatOmjXr37q0TJ064uzQAFcwVF+j79qTUMJFgA5iFR4WaV199VaNHj9b999+v2NhYzZw5U4GBgXr33XfdXRqACtYxJkyRof5yxYnbDROXE24AE/CYUJOfn6/vv/9ePXv2tC/z8vJSz549tXnz5iLXsVqtysrKKvQAYA7eXhZNHhArSS4JNtKlcLPqu6Mu6hFARfKYUHPy5EkVFBSoTp06hZbXqVNHx44dK3KdpKQkhYaG2h9RUVEVUSqACtInLlIzhrZT3VDX3ivqwYXbGbkBPJDHhBpnTJo0SZmZmfbHkSNH3F0SABfrExepjU/eov+N/oPeuKutnu7f0mV9E2wAz+Ixp3TXrl1b3t7eOn78eKHlx48fV926dYtcx8/PT35+nLYJmJ23l0XxjWtJunD9mueW73FZ36u+O6pbO9RzWX8Ayo/HjNT4+vqqffv2+uqrr+zLbDabvvrqK8XHx7uxMgCVibeXRTOHtnNZfw8u3O6yvgCUL48JNZL06KOPavbs2Zo3b5727NmjMWPG6MyZM7r//vvdXRqASqRPXKRLgw0Az+Axh58k6c4771RGRoaeeeYZHTt2TG3bttXKlSuvmjwMAH3iIpX6Yj89vnCzPk3+zd3lAKgA3NASQJXhzMTffw++gTk1gJtxQ0sAuMLBaf21/vHupVqHQAN4DkINgCqlQe1AHZzW36G2jrYDUDl41JwaAHCVi4GlwGbozVX79NraVPtrHHICPBNzagAAQKXGnBoAAFClEGoAAIApEGoAAIApEGoAAIApEGoAAIApEGoAAIApEGoAAIApEGoAAIApEGoAAIApEGoAAIApEGoAAIApEGoAAIApEGoAAIApEGoAAIApEGoAAIApEGoAAIApEGoAAIApEGoAAIApEGoAAIApEGoAAIApEGoAAIApEGoAAIApEGoAAIApEGoAAIApEGoAAIApEGoAAIApEGoAAIApEGoAAIApEGoAAIApEGoAAIApEGoAAIApEGoAAIApEGoAAIApEGoAAIApEGoAAIApEGoAAIApEGoAAIApEGoAAIAp+Li7AAAoD/nnbZq/+aAOnc5VdFighsU3lK8Pf8cBZkaoAWA6SSt2a/aGNNmMS8ueW75Hf2pXX68Maeu2ugCUL4/5s+WFF15Q586dFRgYqBo1ari7HACVVNKK3Zq1vnCguWhR8q9qmLi84osCUCE8JtTk5+frz3/+s8aMGePuUgBUUvnnbZq9Ie2a7Qg2gDl5zOGnqVOnSpLmzp3r3kIAVFrzNx8scoSmKLt/yVLsdSHlWxCACuUxIzUAcC2HTuc63PaPb24ox0oAuIPHjNQ4w2q1ymq12p9nZWW5sRoA5S06LNDhtrZyrAOAe7h1pCYxMVEWi6XEx969e53uPykpSaGhofZHVFSUC6sHUNkMi2/ocFuGqQHzsRiG4eARaNfLyMjQqVOnSmzTqFEj+fr62p/PnTtXEyZM0O+//37N/osaqYmKilJmZqZCQjiWDpjRYx+laFHyr9dst2JsF+bUAB4iKytLoaGh1/z+duvhp/DwcIWHh5db/35+fvLz8yu3/gFUPq8MaetQqCHQAObjMSOwhw8fVkpKig4fPqyCggKlpKQoJSVFOTk57i4NQCVzcFr/Mr0OwDO59fBTaYwYMULz5s27avnXX3+thIQEh/pwdPgKgDns/iVLf3xzg2y68BfcMg45AR7J0e9vjwk1rkCoAQDA8zj6/e0xh58AAABKQqgBAACmQKgBAACmQKgBAACmQKgBAACmQKgBAACmQKgBAACmYOq7dANmV2AztDXttE5k5yki2F8dY8Lk7WVxd1kA4BaEGsBDrdyZrqlLdys9M8++LDLUX5MHxKpPXKQbKwMA9yDUAB5o5c50jVmQrCsvB34sM08PL0jW4Hb1Fejno+iwQA2LbyhfH440AzA/bpMAeJgCm6Gbp68pNEJzLQ91jdGkfrHlWBUAlB9ukwCY1Na006UKNJI0a32aOr3wpf69LlX5523lVBkAuBehBvAwJ7JLF2guOp5t1Yuf71Wzpz7X2P8mq8BWZQZpAVQRzKkBPExEsH+Z+1i2I13LdqRLkt4Z0k492zGxGIDnY6QG8DAdY8IUGeovV524PeqjZDVMXO6i3gDAfVwWan7//XdXdQWgBN5eFk0ecGHSryuvSNMwcTnzbQB4NKdCzfTp0/Xhhx/anw8ZMkS1atVS/fr19cMPP7isOABF6xMXqRlD26luaNkPRV2u2VOfK2nFbpf2CQAVxalTumNiYvT++++rc+fOWr16tYYMGaIPP/xQH330kQ4fPqxVq1aVR61lxindMJuLVxQ+eCpHkz7Z6bJ+q/t6q0XdYL07oqNCA6u5rF8AcIaj399OhZqAgAD99NNPioqK0vjx45WXl6dZs2bpp59+UqdOnfTbb7+VqfjyQqiBmXX7xxodOnXW5f3WCfHVpsSe3H4BgNuU63VqatasqSNHjkiSVq5cqZ49e0qSDMNQQUGBM10CKKN1T9yi6FoBLu/3eFa+mv59hVbuTHd53wDgSk6FmkGDBumee+5Rr169dOrUKfXt21eStH37djVp0sSlBQJw3LonbtEPz9yq9g1qyJUDKzZDenhBMsEGQKXmVKh57bXXNHbsWMXGxmr16tUKCgqSJKWnp+uRRx5xaYEASic0sJoWPXKTfk7qrx4twl3a99Slu7loH4BKi3s/ASZ3Nr9AL67YrU+Tf1VOftkPD/9v9B8U37iWCyoDAMc4+v3t8BWFlyxZ4vCb33bbbQ63BVC+Any99dzAVnpuYCvl5J1X3JQvytSfs7dpAIDy5nCoGThwoEPtLBYLk4WBSirI30cHp/XXjLX7NX3lT0714YrbNABAeXA41NhsXGkUMIsxCU31YNcm2rT/pBZt/0Vf7Dqms+dK/j9ukVQ31F8dY8IqpkgAKCVuaAlUUd5eFnVpHq4uzS9MJi7pOjcXT6SaPCCW69UAqLScDjVnzpzRunXrdPjwYeXn5xd6bdy4cWUuDEDFWvfELcrMPac73t6otJO5uvwMgrqh/po8IFZ94ribN4DKy6mzn7Zv365+/fopNzdXZ86cUVhYmE6ePKnAwEBFRETo559/Lo9ay4yznwDHXLz9wonsPEUEXzjkxAgNAHcp1ysKT5w4UQMGDNBvv/2mgIAAbdmyRYcOHVL79u318ssvO100gMrB28ui+Ma1dHvb+opvXItAA8AjOHX4KSUlRbNmzZKXl5e8vb1ltVrVqFEjvfTSSxo+fLgGDRrk6joBmEj+eZvmbz6oQ6dzFR0WqGHxDeXr49TfWABg51SoqVatmry8LnwARURE6PDhw2rZsqVCQ0Pt94QCgKIkrdit2RvSdPmFiV9YsUeju8RoUr9Y9xUGwOM5FWpuuOEGbdu2TU2bNlW3bt30zDPP6OTJk5o/f77i4uJcXSMAk0hasVuz1qddtdxmyL6cYAPAWU6N97744ouKjLxwFsQLL7ygmjVrasyYMcrIyNC///1vlxYIwBzyz9s0e8PVgeZyszekKTP3nJ5e/KOG/edbPb34R511wa0dAFQN3PsJQIX4z4af9dzyPU6t2ys2QrPvu9HFFQHwFOV69hMAlNah07lOr7t69wmNfm+bC6sBYEZOzamJiYmRxVL8KZ6V9To1ANwnOiywTOuv3n1CZ/MLFODr7aKKAJiNU6FmwoQJhZ6fO3dO27dv18qVK/XEE0+4oi4AJjMsvqFeWLGn0FlPpfXC8l16/o7WrisKgKk4FWrGjx9f5PK33npL3333XZkKAmBOvj5eGt0lpsiznxz1wy+ZLqwIgNm4dE5N3759tWjRIld2CcBEJvWL1UNdY+TsBYpD/au5tiAApuLSu3QvXLhQYWFhruwSgMlM6herx25tUeiKwtFh1TVq/rVHeUd3aVTk8gKboU37T2rR9l+Um1+gGxuGaXhnrlIMVDVOX3zv8onChmHo2LFjysjI0Ntvv+2y4gCYk6+Pl0ZeFlAKbIb8fLxkPW8rdh0/Hy/d3Cz8quUrd6br0Y9+UO5l17NZtfu4XlixRy0jg/XJmJuYXAxUEU6FmoEDBxZ67uXlpfDwcCUkJKhFixauqAtAFeLtZdEbd7XVwwuSi23zxl1tr7qx5sqd6SWusyc9Wy2fWSkfi7TxyR6qW8PfZTUDqHy4+B6ASmPlznRN/myXjmdb7cvqhvhpym3Xq09cZKG2BTZDnZO+1PHsfIf79/WSfnqxv8vqBVAxHP3+dnikJisry+E3JzAAcEafuEj1iq2rrWmndSI7TxHB/uoYE3bVCI0kbU07XapAI0n5Nqlh4nL5eklfTEhQTER1V5UOoBJwONTUqFGjxAvuXa6gwLX3ajl48KCee+45rVmzRseOHVO9evU0dOhQ/f3vf5evr69L3wuAe3l7WRTfuNY1253IznP6PfJtUvdX10qStv1fT4WH+DndF4DKw+FQ8/XXX9t/PnjwoBITEzVixAjFx8dLkjZv3qx58+YpKSnJ5UXu3btXNptNs2bNUpMmTbRz506NHj1aZ86c0csvv+zy9wNQ+UUEu2Z+zI0vfilJWvrIzWrVINQlfQJwD6fm1PTo0UOjRo3S3XffXWj5f//7X/373//W2rVrXVVfsf7xj39oxowZpbolA3NqAPMosBlqPWWlzuQXf8aUM356vi+nggOVTLne0HLz5s3q0KHDVcs7dOigrVu3OtNlqWVmZl7zmjhWq1VZWVmFHgDMwdvLoumDXH/LhGZPfa4/PPe5cvLOu7xvAOXLqVATFRWl2bNnX7X8nXfeUVRUVJmLupYDBw7oX//6lx566KES2yUlJSk0NNT+qIjaAFScP7atr16xES7v99gZm+KmfKHOL6xUQVluVgWgQjl1+GnFihX605/+pCZNmqhTp06SpK1bt2r//v1atGiR+vXr51A/iYmJmj59eolt9uzZU+jaN7/++qu6deumhIQEvfPOOyWua7VaZbVeOjU0KytLUVFRHH4CTOaF5bs1e4Pz95S6lnrVLVr1xK0K8nfpRdgBOMjRw09OX6fmyJEjmjFjhvbu3StJatmypR5++OFSjYZkZGTo1KlTJbZp1KiR/Qyno0ePKiEhQX/4wx80d+5ceXmVbqCJOTWAeeWft6n5U5+rPMdVwgJ99E1iT65QDFSwcg81Fe3XX39V9+7d1b59ey1YsEDe3qX/UCHUAOZ3+GSuer+xVmfPld9HW6/YCM2+78Zy6x9AYS4PNTt27FBcXJy8vLy0Y8eOEtu2bu3ayXu//vqrEhISFB0drXnz5hUKNHXr1nW4H0INULXk5J1X3JQvyqVvgg1QcVweary8vHTs2DFFRETIy8tLFotFRa1qsVhcfvG9uXPn6v777y/ytdIMNBFqgKqpYeLycul3z7N9OBQFVACXh5pDhw6pQYMGslgsOnToUIlto6OjS1dtBSHUAFXX9z//pj/9e5NL+xzaKUrP3+H608oBFObyez9dHlQqa2gBgOK0b1RTB6f1V9qJM/ZbJJTVD79kuqQfAK7h1HVq5s2bp+XLLw3n/u1vf1ONGjXUuXPna47iAIA7xURU18Fp/fX1owll7ivUv1rZCwLgMk6FmhdffFEBAQGSLlxd+M0339RLL72k2rVra+LEiS4tEADKw8Vws+C+jk73MbpLIxdWBKCsnLqS1JEjR9SkSRNJ0uLFizV48GA9+OCDuummm5SQkODK+gCgXN0cG66D0/orJ++8EpK+0EnrtdeRJD8fL93cLLx8iwNQKk6N1AQFBdkvmrdq1Sr16tVLkuTv76+zZ8+6rjoAqCBB/j76bmp//fR8X7Wve+3DSm/c1VbeXpYKqAyAo5waqenVq5dGjRqlG264QT/99JP9tgi7du1Sw4YNXVkfAFQoXx8vLZpwqwpsht748ifNWpcqa8Glk0Trhvhpym3Xq09cpBurBFAUp0LNW2+9paeeekpHjhzRokWLVKtWLUnS999/r7vvvtulBQKAO3h7WfTorc01vmczbU07rRPZeYoI9lfHmLAyj9Dkn7dp/uaDOnQ6V9FhgRoW31C+Pk4NnAO4jMfcJsEVuE4NAHdLWnHh5puX3/zbyyKN7hKjSf1i3VcYUIk5+v3t9J8GGzZs0NChQ9W5c2f9+uuvkqT58+dr48aNznYJAKaWtGK3Zq0vHGgkyWZIs9anaex/k1Vw5YsAHOZUqFm0aJF69+6tgIAAJScny2q9cLpAZmamXnzxRZcWCABmkH/eptkb0kpss2xHujonfaWVO9MrqCrAXJwKNc8//7xmzpyp2bNnq1q1S2cJ3HTTTUpOTnZZcQBgFvM3H7xqhKYox7OtGrMgmWADOMGpicL79u1T165dr1oeGhqq33//vaw1AYDpHDqdW6r2k5fs0itf7FVGzjlFBPvqgwc7KyzIt5yqA8zBqZGaunXr6sCBA1ct37hxoxo14gqbAHCl6LBAh9sako5nWbU/I1e/nz2nn06cUbvnV+vG51eXX4GACTgVakaPHq3x48fr22+/lcVi0dGjR/X+++/rscce05gxY1xdIwB4vGHxDVXWa/Vl5OQTbIASOHX4KTExUTabTT169FBubq66du0qPz8/PfHEExo1apSrawQAj+fr46XRXWI0a33Jk4WvJSMnX6dz8jkUBRTBqZEai8Wiv//97zp9+rR27typLVu2KCMjQ6GhoYqJiXF1jQBgCpP6xeqhrjFlHrG569+bXFMQYDKlCjVWq1WTJk1Shw4ddNNNN2nFihWKjY3Vrl271Lx5c73xxhvcpRsASjCpX6z2PtdXg9td53QfJ7LzXVgRYB6lOvz0zDPPaNasWerZs6c2bdqkP//5z7r//vu1ZcsWvfLKK/rzn/8sb2/v8qoVAEzB18dLLw9po56xEZq6dLfSM/NKtX5EMIeegKKUKtR8/PHHeu+993Tbbbdp586dat26tc6fP68ffvhBFgt3qwWA0ugTF6lesXXt95YK8PHWgwu+v+Z6HzzYuQKqAzxPqULNL7/8ovbt20uS4uLi5Ofnp4kTJxJoAMBJ3l4WxTeuZX8eHuSrjJziDy+FB/kySRgoRqnm1BQUFMjX99J/Jh8fHwUFBbm8KACoqrY91UvhxYSW8CBfbXuqVwVXBHiOUo3UGIahESNGyM/PT5KUl5enhx9+WNWrVy/U7pNPPnFdhQBQxWx7qpdO5+Trrn9v0onsfK4oDDioVKFm+PDhhZ4PHTrUpcUAAC4IC/LVqkcT3F0G4FFKFWrmzJlTXnUAAACUiVMX3wMAAKhsCDUAAMAUCDUAAMAUCDUAAMAUCDUAAMAUCDUAAMAUCDUAAMAUCDUAAMAUCDUAAMAUCDUAAMAUCDUAAMAUCDUAAMAUCDUAAMAUCDUAAMAUCDUAAMAUCDUAAMAUCDUAAMAUCDUAAMAUCDUAAMAUCDUAAMAUPCbU3HbbbWrQoIH8/f0VGRmpYcOG6ejRo+4uCwAAVBIeE2q6d++ujz76SPv27dOiRYuUmpqqwYMHu7ssAABQSVgMwzDcXYQzlixZooEDB8pqtapatWoOrZOVlaXQ0FBlHj2qkJCQqxt4e0v+/peenzlTfGdeXlJAgHNtc3Ol4n7tFosUGOhc27NnJZut+DqqV3eubV6eVFDgmraBgRfqliSrVTp/3jVtAwIu/J4lKT9fOnfONW39/S/8uyht23PnLrQvjp+f5ONT+rbnz1/4XRTH11e6+P+hNG0LCi7su+JUq3ahfWnb2mwX/q25oq2Pz4XfhXTh/0Rurmvalub/PZ8RRbflM6L0bfmMuPCzg58R9u/vzMyiv78vMjzQqVOnjCFDhhg33XRTie3y8vKMzMxM++PIkSOGJCPzwkfA1Y9+/Qp3EBhYdDvJMLp1K9y2du3i23boULhtdHTxbWNjC7eNjS2+bXR04bYdOhTftnbtwm27dSu+bWBg4bb9+hXf9sp/QoMHl9w2J+dS2+HDS2574sSlto88UnLbtLRLbR9/vOS2O3deajt5csltt2691Pall0pu+/XXl9q++WbJbZctu9R2zpyS23700aW2H31Ucts5cy61Xbas5LZvvnmp7ddfl9z2pZcutd26teS2kydfartzZ8ltH3/8Utu0tJLbPvLIpbYnTpTcdvjwS21zckpuO3iwUUhJbfmMuPDgM+LSg8+IC49y/ozIzMw0JBmZmZlGSTzm8JMkPfnkk6pevbpq1aqlw4cP67PPPiuxfVJSkkJDQ+2PqKioCqoUAABUNLcefkpMTNT06dNLbLNnzx61aNFCknTy5EmdPn1ahw4d0tSpUxUaGqply5bJcnH48QpWq1XWy4bWsrKyFBUVxeGn0rZlaLn0bRlavvAzh5+ca8tnxIWf+YwofVuTfkY4evjJraEmIyNDp06dKrFNo0aN5Htx4y/zyy+/KCoqSps2bVJ8fLxD7+fwMTkAAFBpOPr97VOBNV0lPDxc4eHhTq1r+/9/QVhLSpkAAKDKcGuocdS3336rbdu26eabb1bNmjWVmpqqp59+Wo0bN3Z4lAYAAJibR0wUDgwM1CeffKIePXqoefPmGjlypFq3bq1169bJ7+JxcwAAUKV5xEhNq1attGbNGneXAQAAKjGPGKkBAAC4FkINAAAwBUINAAAwBUINAAAwBUINAAAwBUINAAAwBUINAAAwBUINAAAwBUINAAAwBUINAAAwBUINAAAwBUINAAAwBUINAAAwBUINAAAwBUINAAAwBUINAAAwBUINAAAwBUINAAAwBUINAAAwBUINAAAwBUINAAAwBUINAAAwBUINAAAwBUINAAAwBUINAAAwBUINAAAwBUINAAAwBUINAAAwBUINAAAwBUINAAAwBUINAAAwBUINAAAwBUINAAAwBUINAAAwBUINAAAwBUINAAAwBR93FwAAMLcCm6Gtaad1IjtPEcH+6hgTJm8vi7vLggkRagAA5WblznRNXbpb6Zl59mX+1bz0YJcYje/ZnHADl+LwEwCgXKzcma4xC5ILBRpJyjtn0z/XpKr5U5/rjS9/UoHNcFOFMBtCDQDA5QpshqYu3a2S4sp5m6HXvtyv9s+v1sqd6RVWG8yLUAMAcLmtaaevGqEpzu+55/TwgmSCDcqMUAMAcLkT2Y4FmstN+uRHDkWhTAg1AACXiwj2L/U6v+We05afT5VDNagqCDUAAJfrGBOmYH/vUq+3OZVQA+d5XKixWq1q27atLBaLUlJS3F0OAKAI3l4WJQ1s5cSaHH6C8zwu1Pztb39TvXr13F0GAOAa/ti2vnrFRpRqnfhGtcupGlQFHhVqPv/8c61atUovv/yyu0sBADhg9n03anSXGDlyib0agdX0h8a1yr0mmJfHhJrjx49r9OjRmj9/vgIDA91dDgDAQX/vH6t9z/fVn9qVPMo+bVArrjCMMvGIUGMYhkaMGKGHH35YHTp0cHg9q9WqrKysQg8AQMXz9fHSK0Nu0Myh7VQ3xK/Qa3VD/DRzaDv1iYt0U3UwC7fe+ykxMVHTp08vsc2ePXu0atUqZWdna9KkSaXqPykpSVOnTi1LiQAAF+oTF6lesXW5wSXKhcUwDLdNNc/IyNCpUyWfvteoUSMNGTJES5culcVy6R99QUGBvL29de+992revHlFrmu1WmW1Wu3Ps7KyFBUVpczMTIWEhLhmIwAAQLnKyspSaGjoNb+/3RpqHHX48OFCh46OHj2q3r17a+HCherUqZOuu+46h/px9JcCAAAqD0e/v916+MlRDRo0KPQ8KChIktS4cWOHAw0AADA3j5goDAAAcC0eMVJzpYYNG8oDjpoBAIAKxEgNAAAwBUINAAAwBUINAAAwBUINAAAwBUINAAAwBUINAAAwBUINAAAwBUINAAAwBUINAAAwBY+8ojAAAJVBgc3Q1rTTOpGdp4hgf3WMCZO3l8XdZVVZhBoAAJywcme6pi7drfTMPPuyyFB/TR4Qqz5xkW6srOri8BMAAKW0cme6xixILhRoJOlYZp7GLEjWyp3pbqqsamOkBgCAUiiwGZq6dLeKuq2yIckiaerS3bq5Sbimr9yjg6dy1bBWoP6vX6wCfL0ruNqqxWJUodtdZ2VlKTQ0VJmZmQoJCXF3OQAAD7Q59ZTunr3FqXV7xUZo9n03urgi83P0+5vDTwAAlMKJ7LxrNyrG6t0n9KcZ36jAVmXGEyoUoQYAgFKICPYv0/rfH/pd8S+uZt5NOWBODQAApdAxJkyRof46lplX5LwaR5zIOaeHFyRrYs+mali7OqeDuwihBgCAUvD2smjygFiNWZAsi+R0sJGk177cb//Zz8eiP7aup6RBreXrw4EUZzBRGAAAJxR1nZpAX2/l5heUue+Aahatf6KHwkP8ytyXGTj6/U2oAQDASVdeUbhV/VDFTfnCZf17WaRdU/tU+VPBHf3+5vATAABO8vayKL5xrULLesVGaPXuEy7p32ZILZ9ZqZ4tw/XO8I4u6dPMOGgHAIALzb7vRvWKjXBpn1/uydAtr3zNqeDXQKgBAMDFZt93o/Y820ddm9Z2WZ8/Z+Tq+mc+1xtf/kS4KQZzagAAKEdFTSguKz8fL93SIkJD/xCtPzSqZfpTwZkoXARCDQDAHS6fUJyWcUavf7X/2is5KMjPRy/9qbX6tTbvncGZKAwAQCVx5YTiM/nnNHvDQZf0nWM9r0f+m6yQT3w0oHWknvrj9VX2bCnm1AAAUMH+3v96je4S49I+s/LO6/2tR9TymZUaNW+bS/v2FIQaAADc4O/9Y/X2Pe3Kpe8v95xQ15fWaHPqqSo1qZg5NQAAuFGBzdDYBd/pcxdd2+ZKYdWr6fnb49Svdb1y6b8iMFG4CIQaAEBllX/epnc3/Ky5m9N0LCvf5f1HhwVo+biuCvL3vOm0hJoiEGoAAJ6gwGbozTX7NWv9zy65l9TlGoUHavXEBI86DdzR72/m1AAAUMl4e1k0vmcz/Tiltyb2bKZAF57N9HNGrpo/9blW7kx3WZ+VBSM1AABUcgU2Q+M/2K5lO1wbRDo2rKkagb66sWFNDe8cI1+fyjnWweGnIhBqAACebMWOo3p84Q/KzbeVS//9W9XVP+9uV+kOTRFqikCoAQB4ugKboS0/n9IrX+xV8pFMl/fv5+OlN+5qqz5xlecKxYSaIhBqAABmkn/epic/TtGSHekqcPG3eYs6QZrUt6Vubhbu9pEbQk0RCDUAADO6eG+p2RtStWZvhkv79vXx0j/dPHJDqCkCoQYAYHYrdqTrrx8kq8DF0246Nqypv97SVJ2b1K7wkRtCTREINQCAqqDAZqjXa2v1c0auy/v2skg3N6mtWcM6VNiNMwk1RSDUAACqkpy887pn9mbtOprl8jk3ktSjRbj+M6Kj6zu+AqGmCIQaAEBVdHHOzerdx/TuNwdd2nd0rQCte+IWl/Z5Ja4oDAAAJF24QnF841p6ZsD1mjm0nfxceJG9Q6fOaurSXS7rrywINQAAVCF94iK1+9k+Gte9sap5u2bC75xvDmrDTxn6LOVXbU49pQKbew4CcfgJAIAqqsBmaEvqKT21+EelnXLdpOLIUH9NHhDrstPAOfwEAABK5O1l0U1Na+vrJ7qrV2yEy/o9lpmnMQuSK/ymmR4Taho2bCiLxVLoMW3aNHeXBQCAKcy+70btebaPhnZqoFrVq5Wpr4uHgKYu3V2hh6I8JtRI0rPPPqv09HT7469//au7SwIAwDQCfL31/B2t9P3Tt5Z55MaQlJ6Zp61pp11TnAN8KuydXCA4OFh169Z1dxkAAJje7Ptu1NIfjmrSJzuUYy1wup8T2XkurKpkHjVSM23aNNWqVUs33HCD/vGPf+j8+fMltrdarcrKyir0AAAAjhnQpp5+mNxb/xv9ByU0re1UHxHB/i6uqngeM1Izbtw4tWvXTmFhYdq0aZMmTZqk9PR0vfrqq8Wuk5SUpKlTp1ZglQAAmMvFa9zEN66l/PM2zd98UIdO5yqqZoD+s/GgjmflqahZMxZJdUP91TEmrMJqdesp3YmJiZo+fXqJbfbs2aMWLVpctfzdd9/VQw89pJycHPn5+RW5rtVqldVqtT/PyspSVFQUp3QDAOACK3ema8yCZEkqFGwuXv1mxtB2Ljmt2yNuk5CRkaFTp06V2KZRo0by9fW9avmuXbsUFxenvXv3qnnz5g69H9epAQDAtVbuTNfUpbuVnnlp7oy7rlPj1sNP4eHhCg8Pd2rdlJQUeXl5KSLCdefVAwCA0ukTF6lesXW1Ne20TmTnKSL4wiEnby/XXK24NDxiTs3mzZv17bffqnv37goODtbmzZs1ceJEDR06VDVr1nR3eQAAVGkX5924m0eEGj8/P33wwQeaMmWKrFarYmJiNHHiRD366KPuLg0AAFQSHhFq2rVrpy1btri7DAAAUIl51HVqAAAAikOoAQAApkCoAQAApkCoAQAApkCoAQAApkCoAQAApkCoAQAApuAR16lxlYu3ucrKynJzJQAAwFEXv7evdbvKKhVqsrOzJUlRUVFurgQAAJRWdna2QkNDi33drXfprmg2m01Hjx5VcHCwLJaKv9HWRVlZWYqKitKRI0dMebdwM28f2+a5zLx9bJvnMvP2uXLbDMNQdna26tWrJy+v4mfOVKmRGi8vL1133XXuLsMuJCTEdP+IL2fm7WPbPJeZt49t81xm3j5XbVtJIzQXMVEYAACYAqEGAACYAqHGDfz8/DR58mT5+fm5u5RyYebtY9s8l5m3j23zXGbePndsW5WaKAwAAMyLkRoAAGAKhBoAAGAKhBoAAGAKhBoAAGAKhJpysH79eg0YMED16tWTxWLR4sWLr7nO2rVr1a5dO/n5+alJkyaaO3duudfpjNJu29q1a2WxWK56HDt2rGIKLoWkpCTdeOONCg4OVkREhAYOHKh9+/Zdc72PP/5YLVq0kL+/v1q1aqUVK1ZUQLWl48y2zZ0796r95u/vX0EVl86MGTPUunVr+0W+4uPj9fnnn5e4jifsN6n02+ZJ++1K06ZNk8Vi0YQJE0ps5yn77kqObJ+n7L8pU6ZcVWeLFi1KXKci9huhphycOXNGbdq00VtvveVQ+7S0NPXv31/du3dXSkqKJkyYoFGjRumLL74o50pLr7TbdtG+ffuUnp5uf0RERJRThc5bt26d/vKXv2jLli1avXq1zp07p1tvvVVnzpwpdp1Nmzbp7rvv1siRI7V9+3YNHDhQAwcO1M6dOyuw8mtzZtukC1cCvXy/HTp0qIIqLp3rrrtO06ZN0/fff6/vvvtOt9xyi26//Xbt2rWryPaest+k0m+b5Dn77XLbtm3TrFmz1Lp16xLbedK+u5yj2yd5zv67/vrrC9W5cePGYttW2H4zUK4kGZ9++mmJbf72t78Z119/faFld955p9G7d+9yrKzsHNm2r7/+2pBk/PbbbxVSkyudOHHCkGSsW7eu2DZDhgwx+vfvX2hZp06djIceeqi8yysTR7Ztzpw5RmhoaMUV5WI1a9Y03nnnnSJf89T9dlFJ2+aJ+y07O9to2rSpsXr1aqNbt27G+PHji23rifuuNNvnKftv8uTJRps2bRxuX1H7jZGaSmDz5s3q2bNnoWW9e/fW5s2b3VSR67Vt21aRkZHq1auXvvnmG3eX45DMzExJUlhYWLFtPHXfObJtkpSTk6Po6GhFRUVdc3SgsigoKNAHH3ygM2fOKD4+vsg2nrrfHNk2yfP221/+8hf179//qn1SFE/cd6XZPslz9t/+/ftVr149NWrUSPfee68OHz5cbNuK2m9V6oaWldWxY8dUp06dQsvq1KmjrKwsnT17VgEBAW6qrOwiIyM1c+ZMdejQQVarVe+8844SEhL07bffql27du4ur1g2m00TJkzQTTfdpLi4uGLbFbfvKuOcoYsc3bbmzZvr3XffVevWrZWZmamXX35ZnTt31q5duyrVjWEv+vHHHxUfH6+8vDwFBQXp008/VWxsbJFtPW2/lWbbPG2/ffDBB0pOTta2bdscau9p+6602+cp+69Tp06aO3eumjdvrvT0dE2dOlVdunTRzp07FRwcfFX7itpvhBqUq+bNm6t58+b25507d1Zqaqpee+01zZ8/342Vlewvf/mLdu7cWeIxYk/l6LbFx8cXGg3o3LmzWrZsqVmzZum5554r7zJLrXnz5kpJSVFmZqYWLlyo4cOHa926dcV++XuS0mybJ+23I0eOaPz48Vq9enWlnAxbVs5sn6fsv759+9p/bt26tTp16qTo6Gh99NFHGjlypNvqItRUAnXr1tXx48cLLTt+/LhCQkI8epSmOB07dqzUYWHs2LFatmyZ1q9ff82/jIrbd3Xr1i3PEp1Wmm27UrVq1XTDDTfowIED5VRd2fj6+qpJkyaSpPbt22vbtm164403NGvWrKvaetp+K822Xaky77fvv/9eJ06cKDRqW1BQoPXr1+vNN9+U1WqVt7d3oXU8ad85s31Xqsz773I1atRQs2bNiq2zovYbc2oqgfj4eH311VeFlq1evbrEY+aeLCUlRZGRke4u4yqGYWjs2LH69NNPtWbNGsXExFxzHU/Zd85s25UKCgr0448/Vsp9VxSbzSar1Vrka56y34pT0rZdqTLvtx49eujHH39USkqK/dGhQwfde++9SklJKfIL35P2nTPbd6XKvP8ul5OTo9TU1GLrrLD95tJpxzAM48JM9+3btxvbt283JBmvvvqqsX37duPQoUOGYRhGYmKiMWzYMHv7n3/+2QgMDDSeeOIJY8+ePcZbb71leHt7GytXrnTXJhSrtNv22muvGYsXLzb2799v/Pjjj8b48eMNLy8v48svv3TXJhRrzJgxRmhoqLF27VojPT3d/sjNzbW3GTZsmJGYmGh//s033xg+Pj7Gyy+/bOzZs8eYPHmyUa1aNePHH390xyYUy5ltmzp1qvHFF18Yqampxvfff2/cddddhr+/v7Fr1y53bEKJEhMTjXXr1hlpaWnGjh07jMTERMNisRirVq0yDMNz95thlH7bPGm/FeXKs4M8ed8V5Vrb5yn777HHHjPWrl1rpKWlGd98843Rs2dPo3bt2saJEycMw3DffiPUlIOLpzFf+Rg+fLhhGIYxfPhwo1u3blet07ZtW8PX19do1KiRMWfOnAqv2xGl3bbp06cbjRs3Nvz9/Y2wsDAjISHBWLNmjXuKv4aitktSoX3RrVs3+7Ze9NFHHxnNmjUzfH19jeuvv95Yvnx5xRbuAGe2bcKECUaDBg0MX19fo06dOka/fv2M5OTkii/eAQ888IARHR1t+Pr6GuHh4UaPHj3sX/qG4bn7zTBKv22etN+KcuWXvifvu6Jca/s8Zf/deeedRmRkpOHr62vUr1/fuPPOO40DBw7YX3fXfrMYhmG4duwHAACg4jGnBgAAmAKhBgAAmAKhBgAAmAKhBgAAmAKhBgAAmAKhBgAAmAKhBgAAmAKhBoDLjRgxQgMHDrQ/T0hI0IQJEyq8jrVr18pisej3338v1/exWCxavHhxub4HgGsj1ABVxIgRI2SxWGSxWOw3SHz22Wd1/vz5cn/vTz75xOE7DFdUEMnPz1ft2rU1bdq0Il9/7rnnVKdOHZ07d65c6wDgOoQaoArp06eP0tPTtX//fj322GOaMmWK/vGPfxTZNj8/32XvGxYWpuDgYJf15wq+vr4aOnSo5syZc9VrhmFo7ty5uu+++1StWjU3VAfAGYQaoArx8/NT3bp1FR0drTFjxqhnz55asmSJpEuHjF544QXVq1dPzZs3lyQdOXJEQ4YMUY0aNRQWFqbbb79dBw8etPdZUFCgRx99VDVq1FCtWrX0t7/9TVfefeXKw09Wq1VPPvmkoqKi5OfnpyZNmug///mPDh48qO7du0uSatasKYvFohEjRki6cGfqpKQkxcTEKCAgQG3atNHChQsLvc+KFSvUrFkzBQQEqHv37oXqLMrIkSP1008/aePGjYWWr1u3Tj///LNGjhypbdu2qVevXqpdu7ZCQ0PVrVs3JScnF9tnUSNNKSkpslgsherZuHGjunTpooCAAEVFRWncuHE6c+aM/fW3335bTZs2lb+/v+rUqaPBgweXuC0ACDVAlRYQEFBoROarr77Svn37tHr1ai1btkznzp1T7969FRwcrA0bNuibb75RUFCQ+vTpY1/vlVde0dy5c/Xuu+9q48aNOn36tD799NMS3/e+++7T//73P/3zn//Unj17NGvWLAUFBSkqKkqLFi2SJO3bt0/p6el64403JElJSUl67733NHPmTO3atUsTJ07U0KFDtW7dOkkXwtegQYM0YMAApaSkaNSoUUpMTCyxjlatWunGG2/Uu+++W2j5nDlz1LlzZ7Vo0ULZ2dkaPny4Nm7cqC1btqhp06bq16+fsrOzS/fLvkxqaqr69OmjP/3pT9qxY4c+/PBDbdy4UWPHjpUkfffddxo3bpyeffZZ7du3TytXrlTXrl2dfj+gynD5LTIBVErDhw83br/9dsMwDMNmsxmrV682/Pz8jMcff9z+ep06dQyr1WpfZ/78+Ubz5s0Nm81mX2a1Wo2AgADjiy++MAzDMCIjI42XXnrJ/vq5c+eM6667zv5ehlH4zsT79u0zJBmrV68uss6Ld4L/7bff7Mvy8vKMwMBAY9OmTYXajhw50rj77rsNwzCMSZMmGbGxsYVef/LJJ6/q60ozZ840goKCjOzsbMMwDCMrK8sIDAw03nnnnSLbFxQUGMHBwcbSpUvtyyQZn376abH1b9++3ZBkpKWl2et+8MEHC/W7YcMGw8vLyzh79qyxaNEiIyQkxMjKyiq2bgBXY6QGqEKWLVumoKAg+fv7q2/fvrrzzjs1ZcoU++utWrWSr6+v/fkPP/ygAwcOKDg4WEFBQQoKClJYWJjy8vKUmpqqzMxMpaenq1OnTvZ1fHx81KFDh2JrSElJkbe3t7p16+Zw3QcOHFBubq569eplryMoKEjvvfeeUlNTJUl79uwpVIckxcfHX7Pvu+++WwUFBfroo48kSR9++KG8vLx05513SpKOHz+u0aNHq2nTpgoNDVVISIhycnJ0+PBhh+u/0g8//KC5c+cW2pbevXvLZrMpLS1NvXr1UnR0tBo1aqRhw4bp/fffV25urtPvB1QVPu4uAEDF6d69u2bMmCFfX1/Vq1dPPj6FPwKqV69e6HlOTo7at2+v999//6q+wsPDnaohICCg1Ovk5ORIkpYvX6769esXes3Pz8+pOi4KCQnR4MGDNWfOHD3wwAOaM2eOhgwZoqCgIEnS8OHDderUKb3xxhuKjo6Wn5+f4uPji51I7eV14W9F47J5RVeeQZWTk6OHHnpI48aNu2r9Bg0ayNfXV8nJyVq7dq1WrVqlZ555RlOmTNG2bdtUo0aNMm0vYGaEGqAKqV69upo0aeJw+3bt2unDDz9URESEQkJCimwTGRmpb7/91j7n4/z58/r+++/Vrl27Itu3atVKNptN69atU8+ePa96/eJIUUFBgX1ZbGys/Pz8dPjw4WJHeFq2bGmf9HzRli1brr2RujBhOCEhQcuWLdOmTZsKnRH2zTff6O2331a/fv0kXZi7c/LkyWL7uhj20tPTVbNmTUkXRqcu165dO+3evbvEfeHj46OePXuqZ8+emjx5smrUqKE1a9Zo0KBBDm0TUBVx+AlAse69917Vrl1bt99+uzZs2KC0tDStXbtW48aN0y+//CJJGj9+vKZNm6bFixdr7969euSRR0q8xkzDhg01fPhwPfDAA1q8eLG9z4uHf6Kjo2WxWLRs2TJlZGQoJydHwcHBevzxxzVx4kTNmzdPqampSk5O1r/+9S/NmzdPkvTwww9r//79euKJJ7Rv3z7997//1dy5cx3azq5du6pJkya677771KJFC3Xu3Nn+WtOmTTV//nzt2bNH3377re69994SR5uaNGmiqKgoTZkyRfv379fy5cv1yiuvFGrz5JNPatOmTRo7dqxSUlK0f/9+ffbZZ/aJwsuWLdM///lPpaSk6NChQ3rvvfdks9nsZ6QBKBqhBkCxAgMDtX79ejVo0ECDBg1Sy5YtNXLkSOXl5dlHbh577DENGzZMw4cPV3x8vIKDg3XHHXeU2O+MGTM0ePBgPfLII2rRooVGjx5tP525fv36mjp1qhITE1WnTh37F/1zzz2np59+WklJSWrZsqX69Omj5cuXKyYmRtKFwzaLFi3S4sWL1aZNG82cOVMvvviiQ9tpsVj0wAMP6LffftMDDzxQ6LX//Oc/+u2339SuXTsNGzZM48aNU0RERLF9VatWTf/73/+0d+9etW7dWtOnT9fzzz9fqE3r1q21bt06/fTTT+rSpYtuuOEGPfPMM6pXr54kqUaNGvrkk090yy23qGXLlpo5c6b+97//6frrr3doe4CqymIYV1xQAgAAwAMxUgMAAEyBUAMAAEyBUAMAAEyBUAMAAEyBUAMAAEyBUAMAAEyBUAMAAEyBUAMAAEyBUAMAAEyBUAMAAEyBUAMAAEyBUAMAAEzh/wFtBMAJkYQC4wAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bsQLJ4_dN0gK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}